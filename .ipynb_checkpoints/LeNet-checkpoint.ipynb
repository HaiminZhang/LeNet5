{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip, struct\n",
    "import numpy as np\n",
    "\n",
    "def _read(image,label):\n",
    "    minist_dir = './data/'\n",
    "    with gzip.open(minist_dir+label) as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        label = np.fromstring(flbl.read(), dtype=np.int8)\n",
    "    with gzip.open(minist_dir+image, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)\n",
    "    return image,label\n",
    "\n",
    "def get_data():\n",
    "    train_img,train_label = _read(\n",
    "            'train-images-idx3-ubyte.gz', \n",
    "            'train-labels-idx1-ubyte.gz')\n",
    "    test_img,test_label = _read(\n",
    "            't10k-images-idx3-ubyte.gz', \n",
    "            't10k-labels-idx1-ubyte.gz')\n",
    "    return [train_img,train_label,test_img,test_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X, y, Xt, yt = get_data()\n",
    "def imshow(img, label):\n",
    "    plt.imshow(img.reshape((28,28)))\n",
    "    plt.title(label)\n",
    "\n",
    "imshow(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#使用pytorch封装的dataloader进行训练和预测\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def custom_normlization(data, std, mean):\n",
    "    return (data - mean) / std\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "batch_size = 256\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if use_gpu else {}\n",
    "\n",
    "X, y, Xt, yt = get_data()\n",
    "#主要进行标准化处理\n",
    "mean, std = X.mean(), X.std()\n",
    "X = custom_normlization(X, mean, std)\n",
    "Xt = custom_normlization(Xt, mean, std)\n",
    "\n",
    "train_x, train_y = torch.from_numpy(X.reshape(-1, 1, 28, 28)).float(), torch.from_numpy(y.astype(int))\n",
    "test_x, test_y = [\n",
    "    torch.from_numpy(Xt.reshape(-1, 1, 28, 28)).float(),\n",
    "    torch.from_numpy(yt.astype(int))\n",
    "    ]\n",
    "\n",
    "train_dataset = TensorDataset(data_tensor=train_x, target_tensor=train_y)\n",
    "test_dataset = TensorDataset(data_tensor=test_x, target_tensor=test_y)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size, **kwargs)\n",
    "test_loader = DataLoader(dataset=test_dataset, shuffle=True, batch_size=batch_size, **kwargs)\n",
    "\n",
    "model = LeNet5()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    print('USE GPU')\n",
    "else:\n",
    "    print('USE CPU')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "def weight_init(m):\n",
    "# 使用isinstance来判断m属于什么类型\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        import math\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "# m中的weight，bias其实都是Variable，为了能学习参数以及后向传播\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "model.apply(weight_init)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, 501):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#自定义训练预测\n",
    "\n",
    "print('Loading data')\n",
    "X, y, Xt, yt = get_data()\n",
    "X, Xt = torch.from_numpy(X.reshape(-1, 1, 28, 28)), torch.from_numpy(Xt.reshape(-1, 1, 28, 28))\n",
    "y, yt = torch.from_numpy(y.astype(float)), torch.from_numpy(yt.astype(float))\n",
    "\n",
    "print(X.size(), y.size())\n",
    "\n",
    "model = LeNet5()\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    print('USE GPU')\n",
    "else:\n",
    "    print('USE CPU')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    batch_size = 256\n",
    "    \n",
    "    for inx in range(int(X.shape[0]/batch_size)):\n",
    "        start_inx = inx * batch_size\n",
    "        end_inx = min((inx+1)*batch_size, X.shape[0])\n",
    "        mini_data = Variable(X[start_inx:end_inx].clone())\n",
    "        mini_label = Variable(y[start_inx:end_inx].clone())\n",
    "        mini_data = mini_data.type(torch.FloatTensor)\n",
    "        mini_label = mini_label.type(torch.LongTensor)\n",
    "        if use_gpu:\n",
    "            mini_data = mini_data.cuda()\n",
    "            mini_label = mini_label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        mini_out = model(mini_data)\n",
    "        mini_label = mini_label.view(end_inx-start_inx)\n",
    "#         print(mini_out.size(), mini_label.size())\n",
    "        mini_loss = criterion(mini_out, mini_label)\n",
    "        mini_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if inx % 50 == 0:\n",
    "            print('Train Epoch: {}/{}*256 loss is {:.4f}'.format(epoch, inx, mini_loss.data[0]))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "\n",
    "    correct = 0.\n",
    "    nb_test = Xt.shape[0]\n",
    "    for each_sample in range(nb_test):\n",
    "        sample_data = Variable(Xt[each_sample:each_sample+1].clone(), volatile=True)\n",
    "        sample_data = sample_data.type(torch.FloatTensor)\n",
    "        sample_label = Variable(yt[each_sample:each_sample+1].clone())\n",
    "        sample_label = sample_label.type(torch.LongTensor)\n",
    "        if use_gpu:\n",
    "            sample_data = sample_data.cuda()\n",
    "            sample_label = sample_label.cuda()\n",
    "            \n",
    "        sample_out = model(sample_data)\n",
    "        \n",
    "        test_loss += criterion(sample_out, sample_label)\n",
    "        \n",
    "        pred = sample_out.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(sample_label.data.view_as(pred)).cpu().sum()\n",
    "    loss =  (test_loss / nb_test).data[0]\n",
    "    acc = 100. * correct / nb_test\n",
    "    print('Test set: Avg Loss: {:.4f}, Accuracy: {}/{}({:.2f}%)'.format(loss, correct, nb_test, acc))\n",
    "    \n",
    "for epoch in range(2):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.utils.data.DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
