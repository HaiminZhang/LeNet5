{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip, struct\n",
    "import numpy as np\n",
    "\n",
    "def _read(image,label):\n",
    "    minist_dir = './data/'\n",
    "    with gzip.open(minist_dir+label) as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        label = np.fromstring(flbl.read(), dtype=np.int8)\n",
    "    with gzip.open(minist_dir+image, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)\n",
    "    return image,label\n",
    "\n",
    "def get_data():\n",
    "    train_img,train_label = _read(\n",
    "            'train-images-idx3-ubyte.gz', \n",
    "            'train-labels-idx1-ubyte.gz')\n",
    "    test_img,test_label = _read(\n",
    "            't10k-images-idx3-ubyte.gz', \n",
    "            't10k-labels-idx1-ubyte.gz')\n",
    "    return [train_img,train_label,test_img,test_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFyCAYAAAAkvWviAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7af80946d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X, y, Xt, yt = get_data()\n",
    "def imshow(img, label):\n",
    "    plt.imshow(img.reshape((28,28)))\n",
    "    plt.title(label)\n",
    "\n",
    "imshow(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE GPU\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 595.124817\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 152.273407\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 28.779629\n",
      "\n",
      "Test set: Average loss: 0.0872, Accuracy: 9738/10000 (97.38%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 25.694176\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 23.661152\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 29.156540\n",
      "\n",
      "Test set: Average loss: 0.0595, Accuracy: 9814/10000 (98.14%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 16.024918\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 11.336308\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 17.372978\n",
      "\n",
      "Test set: Average loss: 0.0459, Accuracy: 9849/10000 (98.49%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 5.856915\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 10.274417\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 9.624058\n",
      "\n",
      "Test set: Average loss: 0.0430, Accuracy: 9876/10000 (98.76%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 6.784124\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 5.686603\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 8.853918\n",
      "\n",
      "Test set: Average loss: 0.0465, Accuracy: 9848/10000 (98.48%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 5.437205\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 1.898489\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 4.882582\n",
      "\n",
      "Test set: Average loss: 0.0397, Accuracy: 9879/10000 (98.79%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.699214\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 6.592043\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 2.498567\n",
      "\n",
      "Test set: Average loss: 0.0459, Accuracy: 9867/10000 (98.67%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 10.350894\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 7.865856\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 5.985416\n",
      "\n",
      "Test set: Average loss: 0.0364, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 3.723402\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 5.604825\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 8.627254\n",
      "\n",
      "Test set: Average loss: 0.0458, Accuracy: 9863/10000 (98.63%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.971656\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 2.713680\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 8.770008\n",
      "\n",
      "Test set: Average loss: 0.0441, Accuracy: 9873/10000 (98.73%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 4.691146\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 2.581950\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 7.806383\n",
      "\n",
      "Test set: Average loss: 0.0469, Accuracy: 9871/10000 (98.71%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 3.127139\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 1.117162\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 1.851399\n",
      "\n",
      "Test set: Average loss: 0.0518, Accuracy: 9879/10000 (98.79%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 4.092626\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.900461\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.993393\n",
      "\n",
      "Test set: Average loss: 0.0415, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 4.902327\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 5.736496\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 6.387536\n",
      "\n",
      "Test set: Average loss: 0.0433, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.628069\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 3.097495\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.356684\n",
      "\n",
      "Test set: Average loss: 0.0446, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 2.935832\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.990008\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 2.507928\n",
      "\n",
      "Test set: Average loss: 0.0444, Accuracy: 9902/10000 (99.02%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 5.109372\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 4955.082031\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 589.046570\n",
      "\n",
      "Test set: Average loss: 2.3015, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 588.548462\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 587.833191\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 591.281250\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 589.176392\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 587.211670\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 590.407776\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1140/10000 (11.40%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 588.473145\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 590.002380\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 588.277771\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 587.554626\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 589.349426\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 590.349670\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 590.573853\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 589.913696\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 588.783081\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 589.427612\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 590.171326\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 587.450439\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 589.242249\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 589.038330\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 588.406311\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 589.681824\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 590.108215\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 588.051025\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 589.346008\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 588.701416\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 588.629761\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 587.844543\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 590.059265\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 588.327942\n",
      "\n",
      "Test set: Average loss: 2.3016, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 589.584900\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 589.204712\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 591.069214\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 588.338745\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 589.120972\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 587.966370\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 588.519409\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 588.292236\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 588.508484\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 589.657593\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 588.269470\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 588.491516\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 589.350464\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 587.741272\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 589.525574\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 587.498962\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 588.394226\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 588.864014\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 589.973022\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 588.741821\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 588.037842\n",
      "\n",
      "Test set: Average loss: 2.3015, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 589.012756\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 588.163818\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 588.619324\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 589.590149\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 588.233398\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 589.341187\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 588.659851\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 586.961975\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 589.362549\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 589.707458\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 590.130066\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 590.487427\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 587.279419\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 588.101135\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 591.453003\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 589.103760\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 588.606323\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 589.107666\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 590.441101\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 588.356384\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 588.175537\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 589.062439\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 590.193542\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 589.193909\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 588.433899\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 589.624023\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 588.685425\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 589.999756\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 589.859375\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 588.889709\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 589.140869\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 589.880798\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 589.151794\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 588.682190\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 588.949463\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 589.297058\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 589.596802\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 589.619995\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 588.872803\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 587.900208\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 590.342590\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 590.731384\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 589.116455\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 589.540649\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 588.278931\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 590.530029\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 589.189209\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 590.281311\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 589.084900\n",
      "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 588.186035\n",
      "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 589.433777\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 587.591370\n",
      "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 589.030334\n",
      "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 588.981873\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 589.822815\n",
      "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 590.050659\n",
      "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 588.635742\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 589.761902\n",
      "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 588.974670\n",
      "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 590.005981\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 590.120911\n",
      "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 589.302368\n",
      "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 589.128052\n",
      "\n",
      "Test set: Average loss: 2.3015, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 588.867859\n",
      "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 587.985291\n",
      "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 588.900940\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 590.238220\n",
      "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 589.420471\n",
      "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 588.849365\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 588.550598\n",
      "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 588.754883\n",
      "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 589.315430\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 589.072571\n",
      "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 589.213501\n",
      "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 589.283691\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 589.929749\n",
      "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 588.128479\n",
      "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 588.339355\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 61 [0/60000 (0%)]\tLoss: 589.625366\n",
      "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 589.626465\n",
      "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 588.845703\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 62 [0/60000 (0%)]\tLoss: 589.484497\n",
      "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 589.130188\n",
      "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 590.245239\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 63 [0/60000 (0%)]\tLoss: 588.284790\n",
      "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 589.459778\n",
      "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 587.815247\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 64 [0/60000 (0%)]\tLoss: 588.648621\n",
      "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 589.222778\n",
      "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 590.791260\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 65 [0/60000 (0%)]\tLoss: 587.512573\n",
      "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 590.450867\n",
      "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 588.261108\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 66 [0/60000 (0%)]\tLoss: 590.036804\n",
      "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 589.767700\n",
      "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 589.988220\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 67 [0/60000 (0%)]\tLoss: 588.830139\n",
      "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 589.086304\n",
      "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 590.059631\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 68 [0/60000 (0%)]\tLoss: 589.291077\n",
      "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 587.954895\n",
      "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 591.392944\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 69 [0/60000 (0%)]\tLoss: 589.200989\n",
      "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 589.266479\n",
      "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 589.748169\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 70 [0/60000 (0%)]\tLoss: 588.180420\n",
      "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 588.375854\n",
      "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 589.111816\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 71 [0/60000 (0%)]\tLoss: 587.859924\n",
      "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 588.579346\n",
      "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 588.147583\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 72 [0/60000 (0%)]\tLoss: 589.345886\n",
      "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 589.952759\n",
      "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 589.700256\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 73 [0/60000 (0%)]\tLoss: 589.592407\n",
      "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 587.808594\n",
      "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 588.617737\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 74 [0/60000 (0%)]\tLoss: 588.691467\n",
      "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 588.040100\n",
      "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 589.411255\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 75 [0/60000 (0%)]\tLoss: 588.714539\n",
      "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 589.127441\n",
      "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 588.845520\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 76 [0/60000 (0%)]\tLoss: 589.134216\n",
      "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 589.309021\n",
      "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 589.223511\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 77 [0/60000 (0%)]\tLoss: 588.266479\n",
      "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 589.396973\n",
      "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 589.798584\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 78 [0/60000 (0%)]\tLoss: 588.289062\n",
      "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 589.765259\n",
      "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 588.452026\n",
      "\n",
      "Test set: Average loss: 2.3015, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 79 [0/60000 (0%)]\tLoss: 588.172729\n",
      "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 588.672485\n",
      "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 588.338989\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 80 [0/60000 (0%)]\tLoss: 589.237732\n",
      "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 590.465698\n",
      "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 588.958374\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 81 [0/60000 (0%)]\tLoss: 587.837769\n",
      "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 588.654053\n",
      "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 590.088440\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 82 [0/60000 (0%)]\tLoss: 590.960510\n",
      "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 590.166992\n",
      "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 590.185791\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 83 [0/60000 (0%)]\tLoss: 589.551514\n",
      "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 588.926758\n",
      "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 590.102600\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 84 [0/60000 (0%)]\tLoss: 589.414062\n",
      "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 587.228638\n",
      "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 590.341431\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 85 [0/60000 (0%)]\tLoss: 588.885010\n",
      "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 587.530396\n",
      "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 589.805786\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 86 [0/60000 (0%)]\tLoss: 589.182678\n",
      "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 588.680542\n",
      "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 589.047546\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 87 [0/60000 (0%)]\tLoss: 589.306946\n",
      "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 590.726196\n",
      "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 588.306274\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 88 [0/60000 (0%)]\tLoss: 588.925049\n",
      "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 587.523376\n",
      "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 590.127869\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 89 [0/60000 (0%)]\tLoss: 588.926941\n",
      "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 589.788025\n",
      "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 587.793884\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 90 [0/60000 (0%)]\tLoss: 590.803894\n",
      "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 590.128113\n",
      "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 588.323547\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 91 [0/60000 (0%)]\tLoss: 588.576416\n",
      "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 587.890259\n",
      "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 588.523132\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 92 [0/60000 (0%)]\tLoss: 589.474670\n",
      "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 589.831055\n",
      "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 588.146912\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 93 [0/60000 (0%)]\tLoss: 589.091248\n",
      "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 589.740723\n",
      "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 589.954895\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 94 [0/60000 (0%)]\tLoss: 589.064880\n",
      "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 587.688232\n",
      "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 588.994812\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 95 [0/60000 (0%)]\tLoss: 586.257751\n",
      "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 589.363220\n",
      "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 589.906494\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 96 [0/60000 (0%)]\tLoss: 589.294800\n",
      "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 588.401611\n",
      "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 588.867310\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 97 [0/60000 (0%)]\tLoss: 589.133362\n",
      "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 591.490784\n",
      "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 587.170288\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 98 [0/60000 (0%)]\tLoss: 590.530884\n",
      "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 588.469238\n",
      "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 587.511169\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 99 [0/60000 (0%)]\tLoss: 587.592773\n",
      "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 588.503479\n",
      "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 589.056763\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 100 [0/60000 (0%)]\tLoss: 587.731750\n",
      "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 588.689697\n",
      "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 588.497681\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 101 [0/60000 (0%)]\tLoss: 589.976196\n",
      "Train Epoch: 101 [25600/60000 (43%)]\tLoss: 589.072510\n",
      "Train Epoch: 101 [51200/60000 (85%)]\tLoss: 589.580322\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 102 [0/60000 (0%)]\tLoss: 589.808350\n",
      "Train Epoch: 102 [25600/60000 (43%)]\tLoss: 589.740845\n",
      "Train Epoch: 102 [51200/60000 (85%)]\tLoss: 588.690674\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 103 [0/60000 (0%)]\tLoss: 590.061218\n",
      "Train Epoch: 103 [25600/60000 (43%)]\tLoss: 589.235840\n",
      "Train Epoch: 103 [51200/60000 (85%)]\tLoss: 589.233276\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 104 [0/60000 (0%)]\tLoss: 590.943054\n",
      "Train Epoch: 104 [25600/60000 (43%)]\tLoss: 588.619385\n",
      "Train Epoch: 104 [51200/60000 (85%)]\tLoss: 589.388367\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 105 [0/60000 (0%)]\tLoss: 588.633118\n",
      "Train Epoch: 105 [25600/60000 (43%)]\tLoss: 588.408875\n",
      "Train Epoch: 105 [51200/60000 (85%)]\tLoss: 588.901978\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 106 [0/60000 (0%)]\tLoss: 588.928894\n",
      "Train Epoch: 106 [25600/60000 (43%)]\tLoss: 590.474487\n",
      "Train Epoch: 106 [51200/60000 (85%)]\tLoss: 586.891479\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 107 [0/60000 (0%)]\tLoss: 588.467285\n",
      "Train Epoch: 107 [25600/60000 (43%)]\tLoss: 589.144592\n",
      "Train Epoch: 107 [51200/60000 (85%)]\tLoss: 590.815247\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 108 [0/60000 (0%)]\tLoss: 588.399536\n",
      "Train Epoch: 108 [25600/60000 (43%)]\tLoss: 589.928040\n",
      "Train Epoch: 108 [51200/60000 (85%)]\tLoss: 588.852783\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 109 [0/60000 (0%)]\tLoss: 590.092346\n",
      "Train Epoch: 109 [25600/60000 (43%)]\tLoss: 589.974487\n",
      "Train Epoch: 109 [51200/60000 (85%)]\tLoss: 588.055786\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 110 [0/60000 (0%)]\tLoss: 590.402161\n",
      "Train Epoch: 110 [25600/60000 (43%)]\tLoss: 588.226013\n",
      "Train Epoch: 110 [51200/60000 (85%)]\tLoss: 589.182922\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 111 [0/60000 (0%)]\tLoss: 588.255249\n",
      "Train Epoch: 111 [25600/60000 (43%)]\tLoss: 589.716614\n",
      "Train Epoch: 111 [51200/60000 (85%)]\tLoss: 590.276489\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 112 [0/60000 (0%)]\tLoss: 590.264648\n",
      "Train Epoch: 112 [25600/60000 (43%)]\tLoss: 588.306946\n",
      "Train Epoch: 112 [51200/60000 (85%)]\tLoss: 589.120911\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 113 [0/60000 (0%)]\tLoss: 589.528015\n",
      "Train Epoch: 113 [25600/60000 (43%)]\tLoss: 590.419067\n",
      "Train Epoch: 113 [51200/60000 (85%)]\tLoss: 589.699890\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 114 [0/60000 (0%)]\tLoss: 588.718201\n",
      "Train Epoch: 114 [25600/60000 (43%)]\tLoss: 589.173340\n",
      "Train Epoch: 114 [51200/60000 (85%)]\tLoss: 589.316101\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 115 [0/60000 (0%)]\tLoss: 588.559875\n",
      "Train Epoch: 115 [25600/60000 (43%)]\tLoss: 588.928894\n",
      "Train Epoch: 115 [51200/60000 (85%)]\tLoss: 588.364319\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 116 [0/60000 (0%)]\tLoss: 590.109192\n",
      "Train Epoch: 116 [25600/60000 (43%)]\tLoss: 588.949158\n",
      "Train Epoch: 116 [51200/60000 (85%)]\tLoss: 589.484131\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 117 [0/60000 (0%)]\tLoss: 589.121887\n",
      "Train Epoch: 117 [25600/60000 (43%)]\tLoss: 589.061646\n",
      "Train Epoch: 117 [51200/60000 (85%)]\tLoss: 589.793091\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 118 [0/60000 (0%)]\tLoss: 588.844666\n",
      "Train Epoch: 118 [25600/60000 (43%)]\tLoss: 589.944946\n",
      "Train Epoch: 118 [51200/60000 (85%)]\tLoss: 588.046326\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 119 [0/60000 (0%)]\tLoss: 587.539917\n",
      "Train Epoch: 119 [25600/60000 (43%)]\tLoss: 590.489319\n",
      "Train Epoch: 119 [51200/60000 (85%)]\tLoss: 590.173767\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 120 [0/60000 (0%)]\tLoss: 590.015320\n",
      "Train Epoch: 120 [25600/60000 (43%)]\tLoss: 589.170166\n",
      "Train Epoch: 120 [51200/60000 (85%)]\tLoss: 589.148560\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 121 [0/60000 (0%)]\tLoss: 589.831604\n",
      "Train Epoch: 121 [25600/60000 (43%)]\tLoss: 589.706787\n",
      "Train Epoch: 121 [51200/60000 (85%)]\tLoss: 587.893677\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 122 [0/60000 (0%)]\tLoss: 589.261108\n",
      "Train Epoch: 122 [25600/60000 (43%)]\tLoss: 588.555664\n",
      "Train Epoch: 122 [51200/60000 (85%)]\tLoss: 589.916870\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 123 [0/60000 (0%)]\tLoss: 588.777222\n",
      "Train Epoch: 123 [25600/60000 (43%)]\tLoss: 590.534424\n",
      "Train Epoch: 123 [51200/60000 (85%)]\tLoss: 590.942566\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 124 [0/60000 (0%)]\tLoss: 589.353455\n",
      "Train Epoch: 124 [25600/60000 (43%)]\tLoss: 588.597290\n",
      "Train Epoch: 124 [51200/60000 (85%)]\tLoss: 587.872742\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 125 [0/60000 (0%)]\tLoss: 590.133057\n",
      "Train Epoch: 125 [25600/60000 (43%)]\tLoss: 589.002380\n",
      "Train Epoch: 125 [51200/60000 (85%)]\tLoss: 588.459534\n",
      "\n",
      "Test set: Average loss: 2.3017, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 126 [0/60000 (0%)]\tLoss: 589.650818\n",
      "Train Epoch: 126 [25600/60000 (43%)]\tLoss: 589.805115\n",
      "Train Epoch: 126 [51200/60000 (85%)]\tLoss: 588.616455\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 127 [0/60000 (0%)]\tLoss: 589.601379\n",
      "Train Epoch: 127 [25600/60000 (43%)]\tLoss: 589.353088\n",
      "Train Epoch: 127 [51200/60000 (85%)]\tLoss: 589.598511\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 128 [0/60000 (0%)]\tLoss: 588.378235\n",
      "Train Epoch: 128 [25600/60000 (43%)]\tLoss: 590.392761\n",
      "Train Epoch: 128 [51200/60000 (85%)]\tLoss: 589.349243\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 129 [0/60000 (0%)]\tLoss: 590.586487\n",
      "Train Epoch: 129 [25600/60000 (43%)]\tLoss: 588.327026\n",
      "Train Epoch: 129 [51200/60000 (85%)]\tLoss: 588.680908\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 130 [0/60000 (0%)]\tLoss: 589.587769\n",
      "Train Epoch: 130 [25600/60000 (43%)]\tLoss: 589.376343\n",
      "Train Epoch: 130 [51200/60000 (85%)]\tLoss: 587.780701\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 131 [0/60000 (0%)]\tLoss: 590.406799\n",
      "Train Epoch: 131 [25600/60000 (43%)]\tLoss: 588.565125\n",
      "Train Epoch: 131 [51200/60000 (85%)]\tLoss: 589.238342\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 132 [0/60000 (0%)]\tLoss: 589.458435\n",
      "Train Epoch: 132 [25600/60000 (43%)]\tLoss: 586.816162\n",
      "Train Epoch: 132 [51200/60000 (85%)]\tLoss: 590.000610\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 133 [0/60000 (0%)]\tLoss: 588.932800\n",
      "Train Epoch: 133 [25600/60000 (43%)]\tLoss: 588.211853\n",
      "Train Epoch: 133 [51200/60000 (85%)]\tLoss: 591.311462\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 134 [0/60000 (0%)]\tLoss: 589.139526\n",
      "Train Epoch: 134 [25600/60000 (43%)]\tLoss: 590.138489\n",
      "Train Epoch: 134 [51200/60000 (85%)]\tLoss: 589.586487\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 135 [0/60000 (0%)]\tLoss: 586.792603\n",
      "Train Epoch: 135 [25600/60000 (43%)]\tLoss: 590.274231\n",
      "Train Epoch: 135 [51200/60000 (85%)]\tLoss: 591.265625\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 136 [0/60000 (0%)]\tLoss: 589.134033\n",
      "Train Epoch: 136 [25600/60000 (43%)]\tLoss: 589.508423\n",
      "Train Epoch: 136 [51200/60000 (85%)]\tLoss: 589.910950\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 137 [0/60000 (0%)]\tLoss: 589.491455\n",
      "Train Epoch: 137 [25600/60000 (43%)]\tLoss: 588.840942\n",
      "Train Epoch: 137 [51200/60000 (85%)]\tLoss: 590.631531\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 138 [0/60000 (0%)]\tLoss: 590.036438\n",
      "Train Epoch: 138 [25600/60000 (43%)]\tLoss: 591.302368\n",
      "Train Epoch: 138 [51200/60000 (85%)]\tLoss: 588.132812\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 139 [0/60000 (0%)]\tLoss: 590.788635\n",
      "Train Epoch: 139 [25600/60000 (43%)]\tLoss: 590.093140\n",
      "Train Epoch: 139 [51200/60000 (85%)]\tLoss: 588.723083\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 140 [0/60000 (0%)]\tLoss: 588.304626\n",
      "Train Epoch: 140 [25600/60000 (43%)]\tLoss: 590.074646\n",
      "Train Epoch: 140 [51200/60000 (85%)]\tLoss: 589.127686\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 141 [0/60000 (0%)]\tLoss: 589.199585\n",
      "Train Epoch: 141 [25600/60000 (43%)]\tLoss: 587.195801\n",
      "Train Epoch: 141 [51200/60000 (85%)]\tLoss: 590.585144\n",
      "\n",
      "Test set: Average loss: 2.3009, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 142 [0/60000 (0%)]\tLoss: 589.372314\n",
      "Train Epoch: 142 [25600/60000 (43%)]\tLoss: 588.385559\n",
      "Train Epoch: 142 [51200/60000 (85%)]\tLoss: 588.295227\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 143 [0/60000 (0%)]\tLoss: 589.145752\n",
      "Train Epoch: 143 [25600/60000 (43%)]\tLoss: 589.666809\n",
      "Train Epoch: 143 [51200/60000 (85%)]\tLoss: 588.590576\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 144 [0/60000 (0%)]\tLoss: 589.122314\n",
      "Train Epoch: 144 [25600/60000 (43%)]\tLoss: 589.229492\n",
      "Train Epoch: 144 [51200/60000 (85%)]\tLoss: 588.346375\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 145 [0/60000 (0%)]\tLoss: 586.939148\n",
      "Train Epoch: 145 [25600/60000 (43%)]\tLoss: 588.324951\n",
      "Train Epoch: 145 [51200/60000 (85%)]\tLoss: 589.261658\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 146 [0/60000 (0%)]\tLoss: 588.623840\n",
      "Train Epoch: 146 [25600/60000 (43%)]\tLoss: 589.454529\n",
      "Train Epoch: 146 [51200/60000 (85%)]\tLoss: 589.459595\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 147 [0/60000 (0%)]\tLoss: 588.005493\n",
      "Train Epoch: 147 [25600/60000 (43%)]\tLoss: 590.408569\n",
      "Train Epoch: 147 [51200/60000 (85%)]\tLoss: 589.080627\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 148 [0/60000 (0%)]\tLoss: 589.186401\n",
      "Train Epoch: 148 [25600/60000 (43%)]\tLoss: 588.775085\n",
      "Train Epoch: 148 [51200/60000 (85%)]\tLoss: 590.576050\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 149 [0/60000 (0%)]\tLoss: 587.895569\n",
      "Train Epoch: 149 [25600/60000 (43%)]\tLoss: 588.051208\n",
      "Train Epoch: 149 [51200/60000 (85%)]\tLoss: 590.148926\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 150 [0/60000 (0%)]\tLoss: 589.642151\n",
      "Train Epoch: 150 [25600/60000 (43%)]\tLoss: 590.556213\n",
      "Train Epoch: 150 [51200/60000 (85%)]\tLoss: 588.470398\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 151 [0/60000 (0%)]\tLoss: 588.532959\n",
      "Train Epoch: 151 [25600/60000 (43%)]\tLoss: 589.939941\n",
      "Train Epoch: 151 [51200/60000 (85%)]\tLoss: 588.389343\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 152 [0/60000 (0%)]\tLoss: 590.179504\n",
      "Train Epoch: 152 [25600/60000 (43%)]\tLoss: 590.427551\n",
      "Train Epoch: 152 [51200/60000 (85%)]\tLoss: 590.516907\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 153 [0/60000 (0%)]\tLoss: 589.345032\n",
      "Train Epoch: 153 [25600/60000 (43%)]\tLoss: 591.200134\n",
      "Train Epoch: 153 [51200/60000 (85%)]\tLoss: 589.281189\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 154 [0/60000 (0%)]\tLoss: 589.793945\n",
      "Train Epoch: 154 [25600/60000 (43%)]\tLoss: 588.300110\n",
      "Train Epoch: 154 [51200/60000 (85%)]\tLoss: 590.414673\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 155 [0/60000 (0%)]\tLoss: 588.881714\n",
      "Train Epoch: 155 [25600/60000 (43%)]\tLoss: 590.435303\n",
      "Train Epoch: 155 [51200/60000 (85%)]\tLoss: 589.312378\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 156 [0/60000 (0%)]\tLoss: 590.465881\n",
      "Train Epoch: 156 [25600/60000 (43%)]\tLoss: 587.836792\n",
      "Train Epoch: 156 [51200/60000 (85%)]\tLoss: 589.387756\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 157 [0/60000 (0%)]\tLoss: 589.944153\n",
      "Train Epoch: 157 [25600/60000 (43%)]\tLoss: 588.142822\n",
      "Train Epoch: 157 [51200/60000 (85%)]\tLoss: 589.578674\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 158 [0/60000 (0%)]\tLoss: 589.406616\n",
      "Train Epoch: 158 [25600/60000 (43%)]\tLoss: 591.890869\n",
      "Train Epoch: 158 [51200/60000 (85%)]\tLoss: 588.969849\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 159 [0/60000 (0%)]\tLoss: 588.185486\n",
      "Train Epoch: 159 [25600/60000 (43%)]\tLoss: 589.011108\n",
      "Train Epoch: 159 [51200/60000 (85%)]\tLoss: 589.727478\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 160 [0/60000 (0%)]\tLoss: 589.617859\n",
      "Train Epoch: 160 [25600/60000 (43%)]\tLoss: 588.989197\n",
      "Train Epoch: 160 [51200/60000 (85%)]\tLoss: 589.324402\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 161 [0/60000 (0%)]\tLoss: 591.287415\n",
      "Train Epoch: 161 [25600/60000 (43%)]\tLoss: 589.489014\n",
      "Train Epoch: 161 [51200/60000 (85%)]\tLoss: 590.507141\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 162 [0/60000 (0%)]\tLoss: 588.587646\n",
      "Train Epoch: 162 [25600/60000 (43%)]\tLoss: 590.653931\n",
      "Train Epoch: 162 [51200/60000 (85%)]\tLoss: 590.695251\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 163 [0/60000 (0%)]\tLoss: 588.984924\n",
      "Train Epoch: 163 [25600/60000 (43%)]\tLoss: 589.849365\n",
      "Train Epoch: 163 [51200/60000 (85%)]\tLoss: 589.744934\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 164 [0/60000 (0%)]\tLoss: 589.588501\n",
      "Train Epoch: 164 [25600/60000 (43%)]\tLoss: 589.406555\n",
      "Train Epoch: 164 [51200/60000 (85%)]\tLoss: 588.687195\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 165 [0/60000 (0%)]\tLoss: 588.225098\n",
      "Train Epoch: 165 [25600/60000 (43%)]\tLoss: 589.764648\n",
      "Train Epoch: 165 [51200/60000 (85%)]\tLoss: 589.030579\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 166 [0/60000 (0%)]\tLoss: 590.502563\n",
      "Train Epoch: 166 [25600/60000 (43%)]\tLoss: 590.978577\n",
      "Train Epoch: 166 [51200/60000 (85%)]\tLoss: 589.794312\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 167 [0/60000 (0%)]\tLoss: 588.643433\n",
      "Train Epoch: 167 [25600/60000 (43%)]\tLoss: 589.285828\n",
      "Train Epoch: 167 [51200/60000 (85%)]\tLoss: 590.572144\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 168 [0/60000 (0%)]\tLoss: 589.749023\n",
      "Train Epoch: 168 [25600/60000 (43%)]\tLoss: 587.297729\n",
      "Train Epoch: 168 [51200/60000 (85%)]\tLoss: 589.596069\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 169 [0/60000 (0%)]\tLoss: 587.363953\n",
      "Train Epoch: 169 [25600/60000 (43%)]\tLoss: 588.934448\n",
      "Train Epoch: 169 [51200/60000 (85%)]\tLoss: 589.217529\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 170 [0/60000 (0%)]\tLoss: 588.812134\n",
      "Train Epoch: 170 [25600/60000 (43%)]\tLoss: 588.227356\n",
      "Train Epoch: 170 [51200/60000 (85%)]\tLoss: 588.400452\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 171 [0/60000 (0%)]\tLoss: 590.183105\n",
      "Train Epoch: 171 [25600/60000 (43%)]\tLoss: 588.637939\n",
      "Train Epoch: 171 [51200/60000 (85%)]\tLoss: 588.601440\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 172 [0/60000 (0%)]\tLoss: 589.013428\n",
      "Train Epoch: 172 [25600/60000 (43%)]\tLoss: 590.561523\n",
      "Train Epoch: 172 [51200/60000 (85%)]\tLoss: 586.210754\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 173 [0/60000 (0%)]\tLoss: 589.036621\n",
      "Train Epoch: 173 [25600/60000 (43%)]\tLoss: 589.819946\n",
      "Train Epoch: 173 [51200/60000 (85%)]\tLoss: 590.747314\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 174 [0/60000 (0%)]\tLoss: 590.299194\n",
      "Train Epoch: 174 [25600/60000 (43%)]\tLoss: 590.192932\n",
      "Train Epoch: 174 [51200/60000 (85%)]\tLoss: 589.492371\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 175 [0/60000 (0%)]\tLoss: 589.360901\n",
      "Train Epoch: 175 [25600/60000 (43%)]\tLoss: 587.572510\n",
      "Train Epoch: 175 [51200/60000 (85%)]\tLoss: 588.589722\n",
      "\n",
      "Test set: Average loss: 2.3009, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 176 [0/60000 (0%)]\tLoss: 587.181946\n",
      "Train Epoch: 176 [25600/60000 (43%)]\tLoss: 589.642395\n",
      "Train Epoch: 176 [51200/60000 (85%)]\tLoss: 590.684814\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 177 [0/60000 (0%)]\tLoss: 589.482666\n",
      "Train Epoch: 177 [25600/60000 (43%)]\tLoss: 589.724731\n",
      "Train Epoch: 177 [51200/60000 (85%)]\tLoss: 589.611694\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 178 [0/60000 (0%)]\tLoss: 587.830505\n",
      "Train Epoch: 178 [25600/60000 (43%)]\tLoss: 587.751709\n",
      "Train Epoch: 178 [51200/60000 (85%)]\tLoss: 588.149048\n",
      "\n",
      "Test set: Average loss: 2.3015, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 179 [0/60000 (0%)]\tLoss: 588.190796\n",
      "Train Epoch: 179 [25600/60000 (43%)]\tLoss: 588.494690\n",
      "Train Epoch: 179 [51200/60000 (85%)]\tLoss: 588.585510\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 180 [0/60000 (0%)]\tLoss: 588.102905\n",
      "Train Epoch: 180 [25600/60000 (43%)]\tLoss: 589.025330\n",
      "Train Epoch: 180 [51200/60000 (85%)]\tLoss: 590.296387\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 181 [0/60000 (0%)]\tLoss: 588.933594\n",
      "Train Epoch: 181 [25600/60000 (43%)]\tLoss: 589.182678\n",
      "Train Epoch: 181 [51200/60000 (85%)]\tLoss: 588.747375\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 182 [0/60000 (0%)]\tLoss: 589.281189\n",
      "Train Epoch: 182 [25600/60000 (43%)]\tLoss: 588.171814\n",
      "Train Epoch: 182 [51200/60000 (85%)]\tLoss: 589.180969\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 183 [0/60000 (0%)]\tLoss: 590.482727\n",
      "Train Epoch: 183 [25600/60000 (43%)]\tLoss: 589.470520\n",
      "Train Epoch: 183 [51200/60000 (85%)]\tLoss: 589.464172\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 184 [0/60000 (0%)]\tLoss: 590.960815\n",
      "Train Epoch: 184 [25600/60000 (43%)]\tLoss: 588.030579\n",
      "Train Epoch: 184 [51200/60000 (85%)]\tLoss: 589.111328\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1028/10000 (10.28%)\n",
      "\n",
      "Train Epoch: 185 [0/60000 (0%)]\tLoss: 588.447754\n",
      "Train Epoch: 185 [25600/60000 (43%)]\tLoss: 588.662964\n",
      "Train Epoch: 185 [51200/60000 (85%)]\tLoss: 590.457703\n",
      "\n",
      "Test set: Average loss: 2.3009, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 186 [0/60000 (0%)]\tLoss: 591.017700\n",
      "Train Epoch: 186 [25600/60000 (43%)]\tLoss: 587.486572\n",
      "Train Epoch: 186 [51200/60000 (85%)]\tLoss: 589.935120\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 187 [0/60000 (0%)]\tLoss: 587.112610\n",
      "Train Epoch: 187 [25600/60000 (43%)]\tLoss: 589.298035\n",
      "Train Epoch: 187 [51200/60000 (85%)]\tLoss: 589.074036\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 188 [0/60000 (0%)]\tLoss: 589.928467\n",
      "Train Epoch: 188 [25600/60000 (43%)]\tLoss: 589.096436\n",
      "Train Epoch: 188 [51200/60000 (85%)]\tLoss: 588.727966\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 189 [0/60000 (0%)]\tLoss: 589.015686\n",
      "Train Epoch: 189 [25600/60000 (43%)]\tLoss: 590.105591\n",
      "Train Epoch: 189 [51200/60000 (85%)]\tLoss: 589.123352\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 190 [0/60000 (0%)]\tLoss: 589.824280\n",
      "Train Epoch: 190 [25600/60000 (43%)]\tLoss: 589.258728\n",
      "Train Epoch: 190 [51200/60000 (85%)]\tLoss: 589.481567\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 191 [0/60000 (0%)]\tLoss: 589.714172\n",
      "Train Epoch: 191 [25600/60000 (43%)]\tLoss: 588.757263\n",
      "Train Epoch: 191 [51200/60000 (85%)]\tLoss: 590.094727\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 192 [0/60000 (0%)]\tLoss: 588.990906\n",
      "Train Epoch: 192 [25600/60000 (43%)]\tLoss: 589.406616\n",
      "Train Epoch: 192 [51200/60000 (85%)]\tLoss: 589.629639\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 193 [0/60000 (0%)]\tLoss: 588.318604\n",
      "Train Epoch: 193 [25600/60000 (43%)]\tLoss: 589.769653\n",
      "Train Epoch: 193 [51200/60000 (85%)]\tLoss: 589.339478\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 194 [0/60000 (0%)]\tLoss: 588.601074\n",
      "Train Epoch: 194 [25600/60000 (43%)]\tLoss: 588.423401\n",
      "Train Epoch: 194 [51200/60000 (85%)]\tLoss: 589.590576\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 195 [0/60000 (0%)]\tLoss: 588.099304\n",
      "Train Epoch: 195 [25600/60000 (43%)]\tLoss: 589.321777\n",
      "Train Epoch: 195 [51200/60000 (85%)]\tLoss: 590.014343\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 196 [0/60000 (0%)]\tLoss: 590.167725\n",
      "Train Epoch: 196 [25600/60000 (43%)]\tLoss: 588.424072\n",
      "Train Epoch: 196 [51200/60000 (85%)]\tLoss: 589.863037\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 197 [0/60000 (0%)]\tLoss: 589.977356\n",
      "Train Epoch: 197 [25600/60000 (43%)]\tLoss: 587.562622\n",
      "Train Epoch: 197 [51200/60000 (85%)]\tLoss: 589.660767\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 198 [0/60000 (0%)]\tLoss: 589.074158\n",
      "Train Epoch: 198 [25600/60000 (43%)]\tLoss: 589.713867\n",
      "Train Epoch: 198 [51200/60000 (85%)]\tLoss: 588.039307\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 199 [0/60000 (0%)]\tLoss: 590.079468\n",
      "Train Epoch: 199 [25600/60000 (43%)]\tLoss: 590.831055\n",
      "Train Epoch: 199 [51200/60000 (85%)]\tLoss: 590.173645\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 200 [0/60000 (0%)]\tLoss: 590.154419\n",
      "Train Epoch: 200 [25600/60000 (43%)]\tLoss: 589.315063\n",
      "Train Epoch: 200 [51200/60000 (85%)]\tLoss: 592.162048\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 201 [0/60000 (0%)]\tLoss: 589.688904\n",
      "Train Epoch: 201 [25600/60000 (43%)]\tLoss: 589.520142\n",
      "Train Epoch: 201 [51200/60000 (85%)]\tLoss: 589.685303\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 202 [0/60000 (0%)]\tLoss: 588.620850\n",
      "Train Epoch: 202 [25600/60000 (43%)]\tLoss: 588.227356\n",
      "Train Epoch: 202 [51200/60000 (85%)]\tLoss: 589.490234\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 203 [0/60000 (0%)]\tLoss: 589.117126\n",
      "Train Epoch: 203 [25600/60000 (43%)]\tLoss: 588.523071\n",
      "Train Epoch: 203 [51200/60000 (85%)]\tLoss: 587.412598\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 204 [0/60000 (0%)]\tLoss: 589.070374\n",
      "Train Epoch: 204 [25600/60000 (43%)]\tLoss: 589.186829\n",
      "Train Epoch: 204 [51200/60000 (85%)]\tLoss: 589.716187\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 205 [0/60000 (0%)]\tLoss: 588.427124\n",
      "Train Epoch: 205 [25600/60000 (43%)]\tLoss: 589.772522\n",
      "Train Epoch: 205 [51200/60000 (85%)]\tLoss: 586.786499\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 206 [0/60000 (0%)]\tLoss: 590.042114\n",
      "Train Epoch: 206 [25600/60000 (43%)]\tLoss: 589.005615\n",
      "Train Epoch: 206 [51200/60000 (85%)]\tLoss: 588.152710\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 207 [0/60000 (0%)]\tLoss: 590.398010\n",
      "Train Epoch: 207 [25600/60000 (43%)]\tLoss: 587.864197\n",
      "Train Epoch: 207 [51200/60000 (85%)]\tLoss: 588.136414\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 208 [0/60000 (0%)]\tLoss: 587.859863\n",
      "Train Epoch: 208 [25600/60000 (43%)]\tLoss: 590.453369\n",
      "Train Epoch: 208 [51200/60000 (85%)]\tLoss: 590.193604\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 209 [0/60000 (0%)]\tLoss: 589.524536\n",
      "Train Epoch: 209 [25600/60000 (43%)]\tLoss: 590.359680\n",
      "Train Epoch: 209 [51200/60000 (85%)]\tLoss: 588.746155\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 210 [0/60000 (0%)]\tLoss: 589.884338\n",
      "Train Epoch: 210 [25600/60000 (43%)]\tLoss: 587.741699\n",
      "Train Epoch: 210 [51200/60000 (85%)]\tLoss: 588.622864\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 211 [0/60000 (0%)]\tLoss: 586.898987\n",
      "Train Epoch: 211 [25600/60000 (43%)]\tLoss: 589.293457\n",
      "Train Epoch: 211 [51200/60000 (85%)]\tLoss: 588.107605\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 212 [0/60000 (0%)]\tLoss: 588.162476\n",
      "Train Epoch: 212 [25600/60000 (43%)]\tLoss: 590.718445\n",
      "Train Epoch: 212 [51200/60000 (85%)]\tLoss: 588.902222\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 213 [0/60000 (0%)]\tLoss: 588.893494\n",
      "Train Epoch: 213 [25600/60000 (43%)]\tLoss: 588.464844\n",
      "Train Epoch: 213 [51200/60000 (85%)]\tLoss: 588.984680\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 214 [0/60000 (0%)]\tLoss: 587.125854\n",
      "Train Epoch: 214 [25600/60000 (43%)]\tLoss: 590.244812\n",
      "Train Epoch: 214 [51200/60000 (85%)]\tLoss: 587.745605\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 215 [0/60000 (0%)]\tLoss: 589.324585\n",
      "Train Epoch: 215 [25600/60000 (43%)]\tLoss: 589.444702\n",
      "Train Epoch: 215 [51200/60000 (85%)]\tLoss: 590.079834\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 216 [0/60000 (0%)]\tLoss: 588.272888\n",
      "Train Epoch: 216 [25600/60000 (43%)]\tLoss: 587.931458\n",
      "Train Epoch: 216 [51200/60000 (85%)]\tLoss: 588.290161\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 217 [0/60000 (0%)]\tLoss: 589.058289\n",
      "Train Epoch: 217 [25600/60000 (43%)]\tLoss: 589.634155\n",
      "Train Epoch: 217 [51200/60000 (85%)]\tLoss: 589.182251\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 218 [0/60000 (0%)]\tLoss: 588.815063\n",
      "Train Epoch: 218 [25600/60000 (43%)]\tLoss: 589.084106\n",
      "Train Epoch: 218 [51200/60000 (85%)]\tLoss: 587.443420\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 219 [0/60000 (0%)]\tLoss: 587.880493\n",
      "Train Epoch: 219 [25600/60000 (43%)]\tLoss: 590.328979\n",
      "Train Epoch: 219 [51200/60000 (85%)]\tLoss: 589.899597\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 220 [0/60000 (0%)]\tLoss: 590.297729\n",
      "Train Epoch: 220 [25600/60000 (43%)]\tLoss: 588.593018\n",
      "Train Epoch: 220 [51200/60000 (85%)]\tLoss: 590.076538\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 221 [0/60000 (0%)]\tLoss: 590.392029\n",
      "Train Epoch: 221 [25600/60000 (43%)]\tLoss: 589.025146\n",
      "Train Epoch: 221 [51200/60000 (85%)]\tLoss: 589.246704\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 222 [0/60000 (0%)]\tLoss: 588.532349\n",
      "Train Epoch: 222 [25600/60000 (43%)]\tLoss: 590.996033\n",
      "Train Epoch: 222 [51200/60000 (85%)]\tLoss: 589.560974\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 223 [0/60000 (0%)]\tLoss: 589.592224\n",
      "Train Epoch: 223 [25600/60000 (43%)]\tLoss: 588.926331\n",
      "Train Epoch: 223 [51200/60000 (85%)]\tLoss: 591.258118\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 224 [0/60000 (0%)]\tLoss: 587.379211\n",
      "Train Epoch: 224 [25600/60000 (43%)]\tLoss: 589.203064\n",
      "Train Epoch: 224 [51200/60000 (85%)]\tLoss: 588.942993\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 225 [0/60000 (0%)]\tLoss: 589.709106\n",
      "Train Epoch: 225 [25600/60000 (43%)]\tLoss: 588.815186\n",
      "Train Epoch: 225 [51200/60000 (85%)]\tLoss: 588.817200\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 226 [0/60000 (0%)]\tLoss: 589.451050\n",
      "Train Epoch: 226 [25600/60000 (43%)]\tLoss: 589.098267\n",
      "Train Epoch: 226 [51200/60000 (85%)]\tLoss: 589.207581\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 227 [0/60000 (0%)]\tLoss: 588.544739\n",
      "Train Epoch: 227 [25600/60000 (43%)]\tLoss: 589.418457\n",
      "Train Epoch: 227 [51200/60000 (85%)]\tLoss: 589.206909\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 228 [0/60000 (0%)]\tLoss: 590.388428\n",
      "Train Epoch: 228 [25600/60000 (43%)]\tLoss: 589.259216\n",
      "Train Epoch: 228 [51200/60000 (85%)]\tLoss: 589.740112\n",
      "\n",
      "Test set: Average loss: 2.3015, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 229 [0/60000 (0%)]\tLoss: 589.742493\n",
      "Train Epoch: 229 [25600/60000 (43%)]\tLoss: 588.750244\n",
      "Train Epoch: 229 [51200/60000 (85%)]\tLoss: 590.124756\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 230 [0/60000 (0%)]\tLoss: 589.012146\n",
      "Train Epoch: 230 [25600/60000 (43%)]\tLoss: 588.529663\n",
      "Train Epoch: 230 [51200/60000 (85%)]\tLoss: 588.617188\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 231 [0/60000 (0%)]\tLoss: 589.135803\n",
      "Train Epoch: 231 [25600/60000 (43%)]\tLoss: 590.132019\n",
      "Train Epoch: 231 [51200/60000 (85%)]\tLoss: 588.923401\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 232 [0/60000 (0%)]\tLoss: 589.971863\n",
      "Train Epoch: 232 [25600/60000 (43%)]\tLoss: 588.926086\n",
      "Train Epoch: 232 [51200/60000 (85%)]\tLoss: 589.715820\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 233 [0/60000 (0%)]\tLoss: 588.615295\n",
      "Train Epoch: 233 [25600/60000 (43%)]\tLoss: 589.041260\n",
      "Train Epoch: 233 [51200/60000 (85%)]\tLoss: 589.574402\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 234 [0/60000 (0%)]\tLoss: 588.862000\n",
      "Train Epoch: 234 [25600/60000 (43%)]\tLoss: 588.745605\n",
      "Train Epoch: 234 [51200/60000 (85%)]\tLoss: 589.199829\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 235 [0/60000 (0%)]\tLoss: 589.221497\n",
      "Train Epoch: 235 [25600/60000 (43%)]\tLoss: 589.299194\n",
      "Train Epoch: 235 [51200/60000 (85%)]\tLoss: 590.545044\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 236 [0/60000 (0%)]\tLoss: 589.833191\n",
      "Train Epoch: 236 [25600/60000 (43%)]\tLoss: 588.173340\n",
      "Train Epoch: 236 [51200/60000 (85%)]\tLoss: 588.313049\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 237 [0/60000 (0%)]\tLoss: 589.770203\n",
      "Train Epoch: 237 [25600/60000 (43%)]\tLoss: 590.047546\n",
      "Train Epoch: 237 [51200/60000 (85%)]\tLoss: 590.207764\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 238 [0/60000 (0%)]\tLoss: 587.871033\n",
      "Train Epoch: 238 [25600/60000 (43%)]\tLoss: 588.547791\n",
      "Train Epoch: 238 [51200/60000 (85%)]\tLoss: 589.705383\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 239 [0/60000 (0%)]\tLoss: 588.815247\n",
      "Train Epoch: 239 [25600/60000 (43%)]\tLoss: 589.252441\n",
      "Train Epoch: 239 [51200/60000 (85%)]\tLoss: 588.958862\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 240 [0/60000 (0%)]\tLoss: 590.738647\n",
      "Train Epoch: 240 [25600/60000 (43%)]\tLoss: 589.487366\n",
      "Train Epoch: 240 [51200/60000 (85%)]\tLoss: 589.354309\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 241 [0/60000 (0%)]\tLoss: 588.678894\n",
      "Train Epoch: 241 [25600/60000 (43%)]\tLoss: 587.975220\n",
      "Train Epoch: 241 [51200/60000 (85%)]\tLoss: 590.205200\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 242 [0/60000 (0%)]\tLoss: 590.194458\n",
      "Train Epoch: 242 [25600/60000 (43%)]\tLoss: 587.861877\n",
      "Train Epoch: 242 [51200/60000 (85%)]\tLoss: 590.009949\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 243 [0/60000 (0%)]\tLoss: 589.254150\n",
      "Train Epoch: 243 [25600/60000 (43%)]\tLoss: 588.942932\n",
      "Train Epoch: 243 [51200/60000 (85%)]\tLoss: 588.694824\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 244 [0/60000 (0%)]\tLoss: 588.066956\n",
      "Train Epoch: 244 [25600/60000 (43%)]\tLoss: 588.040588\n",
      "Train Epoch: 244 [51200/60000 (85%)]\tLoss: 589.611084\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 245 [0/60000 (0%)]\tLoss: 589.879578\n",
      "Train Epoch: 245 [25600/60000 (43%)]\tLoss: 589.817139\n",
      "Train Epoch: 245 [51200/60000 (85%)]\tLoss: 589.475708\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 246 [0/60000 (0%)]\tLoss: 588.350098\n",
      "Train Epoch: 246 [25600/60000 (43%)]\tLoss: 589.960693\n",
      "Train Epoch: 246 [51200/60000 (85%)]\tLoss: 588.913208\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 247 [0/60000 (0%)]\tLoss: 589.096863\n",
      "Train Epoch: 247 [25600/60000 (43%)]\tLoss: 589.486816\n",
      "Train Epoch: 247 [51200/60000 (85%)]\tLoss: 589.551453\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 248 [0/60000 (0%)]\tLoss: 589.134583\n",
      "Train Epoch: 248 [25600/60000 (43%)]\tLoss: 590.778259\n",
      "Train Epoch: 248 [51200/60000 (85%)]\tLoss: 589.069031\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 249 [0/60000 (0%)]\tLoss: 589.081238\n",
      "Train Epoch: 249 [25600/60000 (43%)]\tLoss: 588.033569\n",
      "Train Epoch: 249 [51200/60000 (85%)]\tLoss: 589.720581\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 250 [0/60000 (0%)]\tLoss: 588.997620\n",
      "Train Epoch: 250 [25600/60000 (43%)]\tLoss: 589.632812\n",
      "Train Epoch: 250 [51200/60000 (85%)]\tLoss: 589.610229\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 251 [0/60000 (0%)]\tLoss: 587.865417\n",
      "Train Epoch: 251 [25600/60000 (43%)]\tLoss: 589.730103\n",
      "Train Epoch: 251 [51200/60000 (85%)]\tLoss: 587.668152\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 252 [0/60000 (0%)]\tLoss: 589.542542\n",
      "Train Epoch: 252 [25600/60000 (43%)]\tLoss: 588.754272\n",
      "Train Epoch: 252 [51200/60000 (85%)]\tLoss: 588.858093\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 253 [0/60000 (0%)]\tLoss: 587.579407\n",
      "Train Epoch: 253 [25600/60000 (43%)]\tLoss: 589.402283\n",
      "Train Epoch: 253 [51200/60000 (85%)]\tLoss: 589.800842\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 254 [0/60000 (0%)]\tLoss: 588.786621\n",
      "Train Epoch: 254 [25600/60000 (43%)]\tLoss: 588.840088\n",
      "Train Epoch: 254 [51200/60000 (85%)]\tLoss: 589.482788\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 255 [0/60000 (0%)]\tLoss: 588.934265\n",
      "Train Epoch: 255 [25600/60000 (43%)]\tLoss: 587.487183\n",
      "Train Epoch: 255 [51200/60000 (85%)]\tLoss: 587.965698\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 256 [0/60000 (0%)]\tLoss: 585.614441\n",
      "Train Epoch: 256 [25600/60000 (43%)]\tLoss: 587.511963\n",
      "Train Epoch: 256 [51200/60000 (85%)]\tLoss: 588.723511\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 257 [0/60000 (0%)]\tLoss: 589.008667\n",
      "Train Epoch: 257 [25600/60000 (43%)]\tLoss: 589.152283\n",
      "Train Epoch: 257 [51200/60000 (85%)]\tLoss: 589.188049\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 258 [0/60000 (0%)]\tLoss: 587.841675\n",
      "Train Epoch: 258 [25600/60000 (43%)]\tLoss: 588.715698\n",
      "Train Epoch: 258 [51200/60000 (85%)]\tLoss: 589.101685\n",
      "\n",
      "Test set: Average loss: 2.3009, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 259 [0/60000 (0%)]\tLoss: 590.121704\n",
      "Train Epoch: 259 [25600/60000 (43%)]\tLoss: 589.040771\n",
      "Train Epoch: 259 [51200/60000 (85%)]\tLoss: 589.618652\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 260 [0/60000 (0%)]\tLoss: 589.446594\n",
      "Train Epoch: 260 [25600/60000 (43%)]\tLoss: 589.619568\n",
      "Train Epoch: 260 [51200/60000 (85%)]\tLoss: 588.655701\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 261 [0/60000 (0%)]\tLoss: 587.933289\n",
      "Train Epoch: 261 [25600/60000 (43%)]\tLoss: 588.898743\n",
      "Train Epoch: 261 [51200/60000 (85%)]\tLoss: 588.921753\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 262 [0/60000 (0%)]\tLoss: 589.908936\n",
      "Train Epoch: 262 [25600/60000 (43%)]\tLoss: 588.663818\n",
      "Train Epoch: 262 [51200/60000 (85%)]\tLoss: 590.396667\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 263 [0/60000 (0%)]\tLoss: 590.107300\n",
      "Train Epoch: 263 [25600/60000 (43%)]\tLoss: 589.560242\n",
      "Train Epoch: 263 [51200/60000 (85%)]\tLoss: 587.374939\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 264 [0/60000 (0%)]\tLoss: 589.175293\n",
      "Train Epoch: 264 [25600/60000 (43%)]\tLoss: 589.122375\n",
      "Train Epoch: 264 [51200/60000 (85%)]\tLoss: 590.139954\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 265 [0/60000 (0%)]\tLoss: 588.575500\n",
      "Train Epoch: 265 [25600/60000 (43%)]\tLoss: 589.257996\n",
      "Train Epoch: 265 [51200/60000 (85%)]\tLoss: 589.888000\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 266 [0/60000 (0%)]\tLoss: 589.477539\n",
      "Train Epoch: 266 [25600/60000 (43%)]\tLoss: 589.491882\n",
      "Train Epoch: 266 [51200/60000 (85%)]\tLoss: 588.378357\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 267 [0/60000 (0%)]\tLoss: 587.322632\n",
      "Train Epoch: 267 [25600/60000 (43%)]\tLoss: 586.980286\n",
      "Train Epoch: 267 [51200/60000 (85%)]\tLoss: 588.463013\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 268 [0/60000 (0%)]\tLoss: 589.015686\n",
      "Train Epoch: 268 [25600/60000 (43%)]\tLoss: 588.557739\n",
      "Train Epoch: 268 [51200/60000 (85%)]\tLoss: 588.097168\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 269 [0/60000 (0%)]\tLoss: 589.690735\n",
      "Train Epoch: 269 [25600/60000 (43%)]\tLoss: 587.878540\n",
      "Train Epoch: 269 [51200/60000 (85%)]\tLoss: 590.603516\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 270 [0/60000 (0%)]\tLoss: 590.923462\n",
      "Train Epoch: 270 [25600/60000 (43%)]\tLoss: 589.674683\n",
      "Train Epoch: 270 [51200/60000 (85%)]\tLoss: 588.854797\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 271 [0/60000 (0%)]\tLoss: 590.018799\n",
      "Train Epoch: 271 [25600/60000 (43%)]\tLoss: 590.987488\n",
      "Train Epoch: 271 [51200/60000 (85%)]\tLoss: 588.721130\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 272 [0/60000 (0%)]\tLoss: 588.734131\n",
      "Train Epoch: 272 [25600/60000 (43%)]\tLoss: 588.605591\n",
      "Train Epoch: 272 [51200/60000 (85%)]\tLoss: 589.991760\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 273 [0/60000 (0%)]\tLoss: 588.684326\n",
      "Train Epoch: 273 [25600/60000 (43%)]\tLoss: 591.836365\n",
      "Train Epoch: 273 [51200/60000 (85%)]\tLoss: 589.728333\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 274 [0/60000 (0%)]\tLoss: 590.021606\n",
      "Train Epoch: 274 [25600/60000 (43%)]\tLoss: 589.268188\n",
      "Train Epoch: 274 [51200/60000 (85%)]\tLoss: 589.082336\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 275 [0/60000 (0%)]\tLoss: 588.261414\n",
      "Train Epoch: 275 [25600/60000 (43%)]\tLoss: 590.411316\n",
      "Train Epoch: 275 [51200/60000 (85%)]\tLoss: 588.846130\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 276 [0/60000 (0%)]\tLoss: 587.323792\n",
      "Train Epoch: 276 [25600/60000 (43%)]\tLoss: 589.580261\n",
      "Train Epoch: 276 [51200/60000 (85%)]\tLoss: 588.878540\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 277 [0/60000 (0%)]\tLoss: 590.222656\n",
      "Train Epoch: 277 [25600/60000 (43%)]\tLoss: 589.694153\n",
      "Train Epoch: 277 [51200/60000 (85%)]\tLoss: 590.411316\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 278 [0/60000 (0%)]\tLoss: 587.909363\n",
      "Train Epoch: 278 [25600/60000 (43%)]\tLoss: 589.625977\n",
      "Train Epoch: 278 [51200/60000 (85%)]\tLoss: 588.207397\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 279 [0/60000 (0%)]\tLoss: 589.389038\n",
      "Train Epoch: 279 [25600/60000 (43%)]\tLoss: 589.275635\n",
      "Train Epoch: 279 [51200/60000 (85%)]\tLoss: 590.887756\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 280 [0/60000 (0%)]\tLoss: 589.915283\n",
      "Train Epoch: 280 [25600/60000 (43%)]\tLoss: 590.126038\n",
      "Train Epoch: 280 [51200/60000 (85%)]\tLoss: 589.492859\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 281 [0/60000 (0%)]\tLoss: 587.889526\n",
      "Train Epoch: 281 [25600/60000 (43%)]\tLoss: 587.765015\n",
      "Train Epoch: 281 [51200/60000 (85%)]\tLoss: 587.906921\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 282 [0/60000 (0%)]\tLoss: 589.773132\n",
      "Train Epoch: 282 [25600/60000 (43%)]\tLoss: 589.292908\n",
      "Train Epoch: 282 [51200/60000 (85%)]\tLoss: 588.347717\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 283 [0/60000 (0%)]\tLoss: 588.827515\n",
      "Train Epoch: 283 [25600/60000 (43%)]\tLoss: 588.756836\n",
      "Train Epoch: 283 [51200/60000 (85%)]\tLoss: 589.732239\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 284 [0/60000 (0%)]\tLoss: 589.446655\n",
      "Train Epoch: 284 [25600/60000 (43%)]\tLoss: 588.728455\n",
      "Train Epoch: 284 [51200/60000 (85%)]\tLoss: 589.749390\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 285 [0/60000 (0%)]\tLoss: 589.444275\n",
      "Train Epoch: 285 [25600/60000 (43%)]\tLoss: 589.356628\n",
      "Train Epoch: 285 [51200/60000 (85%)]\tLoss: 591.020752\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 286 [0/60000 (0%)]\tLoss: 589.978638\n",
      "Train Epoch: 286 [25600/60000 (43%)]\tLoss: 588.793274\n",
      "Train Epoch: 286 [51200/60000 (85%)]\tLoss: 589.090149\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 287 [0/60000 (0%)]\tLoss: 587.849731\n",
      "Train Epoch: 287 [25600/60000 (43%)]\tLoss: 587.983459\n",
      "Train Epoch: 287 [51200/60000 (85%)]\tLoss: 589.038574\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 288 [0/60000 (0%)]\tLoss: 589.037354\n",
      "Train Epoch: 288 [25600/60000 (43%)]\tLoss: 589.900513\n",
      "Train Epoch: 288 [51200/60000 (85%)]\tLoss: 589.862061\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 289 [0/60000 (0%)]\tLoss: 590.193420\n",
      "Train Epoch: 289 [25600/60000 (43%)]\tLoss: 590.457947\n",
      "Train Epoch: 289 [51200/60000 (85%)]\tLoss: 588.414062\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 290 [0/60000 (0%)]\tLoss: 590.371338\n",
      "Train Epoch: 290 [25600/60000 (43%)]\tLoss: 589.235596\n",
      "Train Epoch: 290 [51200/60000 (85%)]\tLoss: 587.758972\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 291 [0/60000 (0%)]\tLoss: 589.749390\n",
      "Train Epoch: 291 [25600/60000 (43%)]\tLoss: 589.109009\n",
      "Train Epoch: 291 [51200/60000 (85%)]\tLoss: 590.298523\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 292 [0/60000 (0%)]\tLoss: 589.585938\n",
      "Train Epoch: 292 [25600/60000 (43%)]\tLoss: 590.482422\n",
      "Train Epoch: 292 [51200/60000 (85%)]\tLoss: 589.770996\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 293 [0/60000 (0%)]\tLoss: 587.870911\n",
      "Train Epoch: 293 [25600/60000 (43%)]\tLoss: 589.218689\n",
      "Train Epoch: 293 [51200/60000 (85%)]\tLoss: 589.027100\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 294 [0/60000 (0%)]\tLoss: 589.992676\n",
      "Train Epoch: 294 [25600/60000 (43%)]\tLoss: 591.092163\n",
      "Train Epoch: 294 [51200/60000 (85%)]\tLoss: 587.688293\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 295 [0/60000 (0%)]\tLoss: 588.230835\n",
      "Train Epoch: 295 [25600/60000 (43%)]\tLoss: 589.196350\n",
      "Train Epoch: 295 [51200/60000 (85%)]\tLoss: 589.532654\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 296 [0/60000 (0%)]\tLoss: 587.900940\n",
      "Train Epoch: 296 [25600/60000 (43%)]\tLoss: 590.612183\n",
      "Train Epoch: 296 [51200/60000 (85%)]\tLoss: 589.452454\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 297 [0/60000 (0%)]\tLoss: 590.192383\n",
      "Train Epoch: 297 [25600/60000 (43%)]\tLoss: 589.758545\n",
      "Train Epoch: 297 [51200/60000 (85%)]\tLoss: 588.664978\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 298 [0/60000 (0%)]\tLoss: 589.148254\n",
      "Train Epoch: 298 [25600/60000 (43%)]\tLoss: 590.627808\n",
      "Train Epoch: 298 [51200/60000 (85%)]\tLoss: 588.634399\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 299 [0/60000 (0%)]\tLoss: 588.696899\n",
      "Train Epoch: 299 [25600/60000 (43%)]\tLoss: 589.150269\n",
      "Train Epoch: 299 [51200/60000 (85%)]\tLoss: 589.403137\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 300 [0/60000 (0%)]\tLoss: 589.002747\n",
      "Train Epoch: 300 [25600/60000 (43%)]\tLoss: 589.449768\n",
      "Train Epoch: 300 [51200/60000 (85%)]\tLoss: 588.719360\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 301 [0/60000 (0%)]\tLoss: 589.651550\n",
      "Train Epoch: 301 [25600/60000 (43%)]\tLoss: 588.317688\n",
      "Train Epoch: 301 [51200/60000 (85%)]\tLoss: 589.154297\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 302 [0/60000 (0%)]\tLoss: 590.389832\n",
      "Train Epoch: 302 [25600/60000 (43%)]\tLoss: 588.409119\n",
      "Train Epoch: 302 [51200/60000 (85%)]\tLoss: 590.103027\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 303 [0/60000 (0%)]\tLoss: 588.361084\n",
      "Train Epoch: 303 [25600/60000 (43%)]\tLoss: 589.110657\n",
      "Train Epoch: 303 [51200/60000 (85%)]\tLoss: 589.877808\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 304 [0/60000 (0%)]\tLoss: 588.781128\n",
      "Train Epoch: 304 [25600/60000 (43%)]\tLoss: 590.043762\n",
      "Train Epoch: 304 [51200/60000 (85%)]\tLoss: 590.680176\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 305 [0/60000 (0%)]\tLoss: 588.413635\n",
      "Train Epoch: 305 [25600/60000 (43%)]\tLoss: 588.397400\n",
      "Train Epoch: 305 [51200/60000 (85%)]\tLoss: 590.044556\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 306 [0/60000 (0%)]\tLoss: 589.278564\n",
      "Train Epoch: 306 [25600/60000 (43%)]\tLoss: 588.561340\n",
      "Train Epoch: 306 [51200/60000 (85%)]\tLoss: 588.316284\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 307 [0/60000 (0%)]\tLoss: 590.148987\n",
      "Train Epoch: 307 [25600/60000 (43%)]\tLoss: 589.258423\n",
      "Train Epoch: 307 [51200/60000 (85%)]\tLoss: 588.193665\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 308 [0/60000 (0%)]\tLoss: 589.179016\n",
      "Train Epoch: 308 [25600/60000 (43%)]\tLoss: 589.854065\n",
      "Train Epoch: 308 [51200/60000 (85%)]\tLoss: 590.041809\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 309 [0/60000 (0%)]\tLoss: 587.962646\n",
      "Train Epoch: 309 [25600/60000 (43%)]\tLoss: 589.376953\n",
      "Train Epoch: 309 [51200/60000 (85%)]\tLoss: 587.947021\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 310 [0/60000 (0%)]\tLoss: 588.527771\n",
      "Train Epoch: 310 [25600/60000 (43%)]\tLoss: 589.844482\n",
      "Train Epoch: 310 [51200/60000 (85%)]\tLoss: 590.093262\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 311 [0/60000 (0%)]\tLoss: 588.896057\n",
      "Train Epoch: 311 [25600/60000 (43%)]\tLoss: 588.093811\n",
      "Train Epoch: 311 [51200/60000 (85%)]\tLoss: 589.939941\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 312 [0/60000 (0%)]\tLoss: 588.883057\n",
      "Train Epoch: 312 [25600/60000 (43%)]\tLoss: 587.355530\n",
      "Train Epoch: 312 [51200/60000 (85%)]\tLoss: 589.000854\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 313 [0/60000 (0%)]\tLoss: 590.024353\n",
      "Train Epoch: 313 [25600/60000 (43%)]\tLoss: 589.313416\n",
      "Train Epoch: 313 [51200/60000 (85%)]\tLoss: 588.608643\n",
      "\n",
      "Test set: Average loss: 2.3016, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 314 [0/60000 (0%)]\tLoss: 589.617249\n",
      "Train Epoch: 314 [25600/60000 (43%)]\tLoss: 589.384888\n",
      "Train Epoch: 314 [51200/60000 (85%)]\tLoss: 589.317078\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 315 [0/60000 (0%)]\tLoss: 588.789124\n",
      "Train Epoch: 315 [25600/60000 (43%)]\tLoss: 589.267456\n",
      "Train Epoch: 315 [51200/60000 (85%)]\tLoss: 588.567322\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 316 [0/60000 (0%)]\tLoss: 589.066223\n",
      "Train Epoch: 316 [25600/60000 (43%)]\tLoss: 588.474487\n",
      "Train Epoch: 316 [51200/60000 (85%)]\tLoss: 588.931396\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 317 [0/60000 (0%)]\tLoss: 589.577881\n",
      "Train Epoch: 317 [25600/60000 (43%)]\tLoss: 589.730286\n",
      "Train Epoch: 317 [51200/60000 (85%)]\tLoss: 588.714966\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 318 [0/60000 (0%)]\tLoss: 589.133362\n",
      "Train Epoch: 318 [25600/60000 (43%)]\tLoss: 587.741272\n",
      "Train Epoch: 318 [51200/60000 (85%)]\tLoss: 589.358704\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 319 [0/60000 (0%)]\tLoss: 589.193420\n",
      "Train Epoch: 319 [25600/60000 (43%)]\tLoss: 589.328979\n",
      "Train Epoch: 319 [51200/60000 (85%)]\tLoss: 588.790344\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 320 [0/60000 (0%)]\tLoss: 589.984436\n",
      "Train Epoch: 320 [25600/60000 (43%)]\tLoss: 590.258362\n",
      "Train Epoch: 320 [51200/60000 (85%)]\tLoss: 588.352173\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 321 [0/60000 (0%)]\tLoss: 589.043091\n",
      "Train Epoch: 321 [25600/60000 (43%)]\tLoss: 589.319153\n",
      "Train Epoch: 321 [51200/60000 (85%)]\tLoss: 589.618286\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 322 [0/60000 (0%)]\tLoss: 588.210754\n",
      "Train Epoch: 322 [25600/60000 (43%)]\tLoss: 589.062256\n",
      "Train Epoch: 322 [51200/60000 (85%)]\tLoss: 589.606384\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 323 [0/60000 (0%)]\tLoss: 588.648010\n",
      "Train Epoch: 323 [25600/60000 (43%)]\tLoss: 588.462952\n",
      "Train Epoch: 323 [51200/60000 (85%)]\tLoss: 589.514954\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 324 [0/60000 (0%)]\tLoss: 589.262390\n",
      "Train Epoch: 324 [25600/60000 (43%)]\tLoss: 588.210693\n",
      "Train Epoch: 324 [51200/60000 (85%)]\tLoss: 589.158447\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 325 [0/60000 (0%)]\tLoss: 589.149658\n",
      "Train Epoch: 325 [25600/60000 (43%)]\tLoss: 589.929688\n",
      "Train Epoch: 325 [51200/60000 (85%)]\tLoss: 588.433777\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 326 [0/60000 (0%)]\tLoss: 587.607544\n",
      "Train Epoch: 326 [25600/60000 (43%)]\tLoss: 589.536804\n",
      "Train Epoch: 326 [51200/60000 (85%)]\tLoss: 589.429565\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 327 [0/60000 (0%)]\tLoss: 587.783752\n",
      "Train Epoch: 327 [25600/60000 (43%)]\tLoss: 588.506714\n",
      "Train Epoch: 327 [51200/60000 (85%)]\tLoss: 590.674133\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 328 [0/60000 (0%)]\tLoss: 589.336853\n",
      "Train Epoch: 328 [25600/60000 (43%)]\tLoss: 589.580261\n",
      "Train Epoch: 328 [51200/60000 (85%)]\tLoss: 589.848022\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 329 [0/60000 (0%)]\tLoss: 589.339844\n",
      "Train Epoch: 329 [25600/60000 (43%)]\tLoss: 589.365479\n",
      "Train Epoch: 329 [51200/60000 (85%)]\tLoss: 589.318237\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 330 [0/60000 (0%)]\tLoss: 589.183167\n",
      "Train Epoch: 330 [25600/60000 (43%)]\tLoss: 589.012512\n",
      "Train Epoch: 330 [51200/60000 (85%)]\tLoss: 589.277344\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 331 [0/60000 (0%)]\tLoss: 591.204834\n",
      "Train Epoch: 331 [25600/60000 (43%)]\tLoss: 586.221130\n",
      "Train Epoch: 331 [51200/60000 (85%)]\tLoss: 588.500488\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 332 [0/60000 (0%)]\tLoss: 587.445557\n",
      "Train Epoch: 332 [25600/60000 (43%)]\tLoss: 587.715942\n",
      "Train Epoch: 332 [51200/60000 (85%)]\tLoss: 588.691406\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 333 [0/60000 (0%)]\tLoss: 587.632263\n",
      "Train Epoch: 333 [25600/60000 (43%)]\tLoss: 589.438477\n",
      "Train Epoch: 333 [51200/60000 (85%)]\tLoss: 589.165466\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 334 [0/60000 (0%)]\tLoss: 589.176636\n",
      "Train Epoch: 334 [25600/60000 (43%)]\tLoss: 588.733032\n",
      "Train Epoch: 334 [51200/60000 (85%)]\tLoss: 589.819397\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 335 [0/60000 (0%)]\tLoss: 592.041199\n",
      "Train Epoch: 335 [25600/60000 (43%)]\tLoss: 588.961243\n",
      "Train Epoch: 335 [51200/60000 (85%)]\tLoss: 589.723083\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 336 [0/60000 (0%)]\tLoss: 588.534363\n",
      "Train Epoch: 336 [25600/60000 (43%)]\tLoss: 588.252441\n",
      "Train Epoch: 336 [51200/60000 (85%)]\tLoss: 588.500244\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 337 [0/60000 (0%)]\tLoss: 587.688965\n",
      "Train Epoch: 337 [25600/60000 (43%)]\tLoss: 588.844177\n",
      "Train Epoch: 337 [51200/60000 (85%)]\tLoss: 589.145142\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 338 [0/60000 (0%)]\tLoss: 589.064087\n",
      "Train Epoch: 338 [25600/60000 (43%)]\tLoss: 587.782043\n",
      "Train Epoch: 338 [51200/60000 (85%)]\tLoss: 589.711609\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 339 [0/60000 (0%)]\tLoss: 588.356262\n",
      "Train Epoch: 339 [25600/60000 (43%)]\tLoss: 588.310730\n",
      "Train Epoch: 339 [51200/60000 (85%)]\tLoss: 590.381104\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 340 [0/60000 (0%)]\tLoss: 588.408691\n",
      "Train Epoch: 340 [25600/60000 (43%)]\tLoss: 588.327087\n",
      "Train Epoch: 340 [51200/60000 (85%)]\tLoss: 588.257690\n",
      "\n",
      "Test set: Average loss: 2.3009, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 341 [0/60000 (0%)]\tLoss: 589.720947\n",
      "Train Epoch: 341 [25600/60000 (43%)]\tLoss: 588.034241\n",
      "Train Epoch: 341 [51200/60000 (85%)]\tLoss: 588.416321\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 342 [0/60000 (0%)]\tLoss: 589.083191\n",
      "Train Epoch: 342 [25600/60000 (43%)]\tLoss: 589.734314\n",
      "Train Epoch: 342 [51200/60000 (85%)]\tLoss: 587.761902\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 343 [0/60000 (0%)]\tLoss: 588.464844\n",
      "Train Epoch: 343 [25600/60000 (43%)]\tLoss: 588.056335\n",
      "Train Epoch: 343 [51200/60000 (85%)]\tLoss: 589.498535\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 344 [0/60000 (0%)]\tLoss: 589.075378\n",
      "Train Epoch: 344 [25600/60000 (43%)]\tLoss: 588.649353\n",
      "Train Epoch: 344 [51200/60000 (85%)]\tLoss: 588.466309\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 345 [0/60000 (0%)]\tLoss: 589.465820\n",
      "Train Epoch: 345 [25600/60000 (43%)]\tLoss: 588.131653\n",
      "Train Epoch: 345 [51200/60000 (85%)]\tLoss: 590.630981\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 346 [0/60000 (0%)]\tLoss: 589.004517\n",
      "Train Epoch: 346 [25600/60000 (43%)]\tLoss: 587.951599\n",
      "Train Epoch: 346 [51200/60000 (85%)]\tLoss: 589.423340\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 347 [0/60000 (0%)]\tLoss: 588.685852\n",
      "Train Epoch: 347 [25600/60000 (43%)]\tLoss: 588.947571\n",
      "Train Epoch: 347 [51200/60000 (85%)]\tLoss: 588.930298\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 348 [0/60000 (0%)]\tLoss: 588.757568\n",
      "Train Epoch: 348 [25600/60000 (43%)]\tLoss: 589.694214\n",
      "Train Epoch: 348 [51200/60000 (85%)]\tLoss: 590.110962\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 349 [0/60000 (0%)]\tLoss: 588.247681\n",
      "Train Epoch: 349 [25600/60000 (43%)]\tLoss: 589.067627\n",
      "Train Epoch: 349 [51200/60000 (85%)]\tLoss: 588.915222\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 350 [0/60000 (0%)]\tLoss: 588.976807\n",
      "Train Epoch: 350 [25600/60000 (43%)]\tLoss: 589.217407\n",
      "Train Epoch: 350 [51200/60000 (85%)]\tLoss: 589.523499\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 351 [0/60000 (0%)]\tLoss: 590.007629\n",
      "Train Epoch: 351 [25600/60000 (43%)]\tLoss: 588.959595\n",
      "Train Epoch: 351 [51200/60000 (85%)]\tLoss: 589.531677\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 352 [0/60000 (0%)]\tLoss: 587.661499\n",
      "Train Epoch: 352 [25600/60000 (43%)]\tLoss: 590.126038\n",
      "Train Epoch: 352 [51200/60000 (85%)]\tLoss: 589.091187\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 353 [0/60000 (0%)]\tLoss: 587.975342\n",
      "Train Epoch: 353 [25600/60000 (43%)]\tLoss: 589.453491\n",
      "Train Epoch: 353 [51200/60000 (85%)]\tLoss: 588.906372\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 354 [0/60000 (0%)]\tLoss: 590.316711\n",
      "Train Epoch: 354 [25600/60000 (43%)]\tLoss: 587.013550\n",
      "Train Epoch: 354 [51200/60000 (85%)]\tLoss: 587.543945\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 355 [0/60000 (0%)]\tLoss: 589.207825\n",
      "Train Epoch: 355 [25600/60000 (43%)]\tLoss: 589.415161\n",
      "Train Epoch: 355 [51200/60000 (85%)]\tLoss: 590.617310\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 356 [0/60000 (0%)]\tLoss: 589.207458\n",
      "Train Epoch: 356 [25600/60000 (43%)]\tLoss: 589.121521\n",
      "Train Epoch: 356 [51200/60000 (85%)]\tLoss: 588.838684\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 357 [0/60000 (0%)]\tLoss: 589.546631\n",
      "Train Epoch: 357 [25600/60000 (43%)]\tLoss: 589.188538\n",
      "Train Epoch: 357 [51200/60000 (85%)]\tLoss: 587.213623\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 358 [0/60000 (0%)]\tLoss: 590.473877\n",
      "Train Epoch: 358 [25600/60000 (43%)]\tLoss: 588.474609\n",
      "Train Epoch: 358 [51200/60000 (85%)]\tLoss: 589.042053\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 359 [0/60000 (0%)]\tLoss: 589.569214\n",
      "Train Epoch: 359 [25600/60000 (43%)]\tLoss: 588.821289\n",
      "Train Epoch: 359 [51200/60000 (85%)]\tLoss: 590.341492\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 360 [0/60000 (0%)]\tLoss: 590.444458\n",
      "Train Epoch: 360 [25600/60000 (43%)]\tLoss: 589.934021\n",
      "Train Epoch: 360 [51200/60000 (85%)]\tLoss: 589.382446\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 361 [0/60000 (0%)]\tLoss: 588.975952\n",
      "Train Epoch: 361 [25600/60000 (43%)]\tLoss: 589.135010\n",
      "Train Epoch: 361 [51200/60000 (85%)]\tLoss: 588.294678\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 362 [0/60000 (0%)]\tLoss: 589.776978\n",
      "Train Epoch: 362 [25600/60000 (43%)]\tLoss: 588.835632\n",
      "Train Epoch: 362 [51200/60000 (85%)]\tLoss: 589.362671\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 363 [0/60000 (0%)]\tLoss: 589.498413\n",
      "Train Epoch: 363 [25600/60000 (43%)]\tLoss: 588.875244\n",
      "Train Epoch: 363 [51200/60000 (85%)]\tLoss: 589.116333\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 364 [0/60000 (0%)]\tLoss: 588.419189\n",
      "Train Epoch: 364 [25600/60000 (43%)]\tLoss: 590.919434\n",
      "Train Epoch: 364 [51200/60000 (85%)]\tLoss: 588.935913\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 365 [0/60000 (0%)]\tLoss: 588.453430\n",
      "Train Epoch: 365 [25600/60000 (43%)]\tLoss: 589.069153\n",
      "Train Epoch: 365 [51200/60000 (85%)]\tLoss: 589.776733\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 366 [0/60000 (0%)]\tLoss: 589.084839\n",
      "Train Epoch: 366 [25600/60000 (43%)]\tLoss: 589.448914\n",
      "Train Epoch: 366 [51200/60000 (85%)]\tLoss: 589.662720\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 367 [0/60000 (0%)]\tLoss: 588.648560\n",
      "Train Epoch: 367 [25600/60000 (43%)]\tLoss: 590.687073\n",
      "Train Epoch: 367 [51200/60000 (85%)]\tLoss: 588.144470\n",
      "\n",
      "Test set: Average loss: 2.3009, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 368 [0/60000 (0%)]\tLoss: 590.265198\n",
      "Train Epoch: 368 [25600/60000 (43%)]\tLoss: 589.013550\n",
      "Train Epoch: 368 [51200/60000 (85%)]\tLoss: 588.598389\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 369 [0/60000 (0%)]\tLoss: 588.965698\n",
      "Train Epoch: 369 [25600/60000 (43%)]\tLoss: 588.417480\n",
      "Train Epoch: 369 [51200/60000 (85%)]\tLoss: 589.271729\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 370 [0/60000 (0%)]\tLoss: 588.617615\n",
      "Train Epoch: 370 [25600/60000 (43%)]\tLoss: 588.468689\n",
      "Train Epoch: 370 [51200/60000 (85%)]\tLoss: 590.212097\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 371 [0/60000 (0%)]\tLoss: 588.704285\n",
      "Train Epoch: 371 [25600/60000 (43%)]\tLoss: 589.699280\n",
      "Train Epoch: 371 [51200/60000 (85%)]\tLoss: 590.461548\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 372 [0/60000 (0%)]\tLoss: 589.674683\n",
      "Train Epoch: 372 [25600/60000 (43%)]\tLoss: 590.064575\n",
      "Train Epoch: 372 [51200/60000 (85%)]\tLoss: 590.090027\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 373 [0/60000 (0%)]\tLoss: 589.443298\n",
      "Train Epoch: 373 [25600/60000 (43%)]\tLoss: 590.535828\n",
      "Train Epoch: 373 [51200/60000 (85%)]\tLoss: 590.398865\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 374 [0/60000 (0%)]\tLoss: 591.025879\n",
      "Train Epoch: 374 [25600/60000 (43%)]\tLoss: 590.586670\n",
      "Train Epoch: 374 [51200/60000 (85%)]\tLoss: 589.708679\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 375 [0/60000 (0%)]\tLoss: 590.282227\n",
      "Train Epoch: 375 [25600/60000 (43%)]\tLoss: 588.540161\n",
      "Train Epoch: 375 [51200/60000 (85%)]\tLoss: 590.091675\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 376 [0/60000 (0%)]\tLoss: 590.219910\n",
      "Train Epoch: 376 [25600/60000 (43%)]\tLoss: 590.021545\n",
      "Train Epoch: 376 [51200/60000 (85%)]\tLoss: 589.194153\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 377 [0/60000 (0%)]\tLoss: 586.994568\n",
      "Train Epoch: 377 [25600/60000 (43%)]\tLoss: 590.353271\n",
      "Train Epoch: 377 [51200/60000 (85%)]\tLoss: 587.960693\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 378 [0/60000 (0%)]\tLoss: 589.281433\n",
      "Train Epoch: 378 [25600/60000 (43%)]\tLoss: 589.495422\n",
      "Train Epoch: 378 [51200/60000 (85%)]\tLoss: 590.213257\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 379 [0/60000 (0%)]\tLoss: 588.570374\n",
      "Train Epoch: 379 [25600/60000 (43%)]\tLoss: 588.240845\n",
      "Train Epoch: 379 [51200/60000 (85%)]\tLoss: 589.622559\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 380 [0/60000 (0%)]\tLoss: 588.776367\n",
      "Train Epoch: 380 [25600/60000 (43%)]\tLoss: 589.462769\n",
      "Train Epoch: 380 [51200/60000 (85%)]\tLoss: 587.991577\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 381 [0/60000 (0%)]\tLoss: 588.085266\n",
      "Train Epoch: 381 [25600/60000 (43%)]\tLoss: 588.011108\n",
      "Train Epoch: 381 [51200/60000 (85%)]\tLoss: 589.047180\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 382 [0/60000 (0%)]\tLoss: 588.157043\n",
      "Train Epoch: 382 [25600/60000 (43%)]\tLoss: 589.763733\n",
      "Train Epoch: 382 [51200/60000 (85%)]\tLoss: 589.723999\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 383 [0/60000 (0%)]\tLoss: 589.286377\n",
      "Train Epoch: 383 [25600/60000 (43%)]\tLoss: 589.034302\n",
      "Train Epoch: 383 [51200/60000 (85%)]\tLoss: 590.231079\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 384 [0/60000 (0%)]\tLoss: 590.504333\n",
      "Train Epoch: 384 [25600/60000 (43%)]\tLoss: 588.445374\n",
      "Train Epoch: 384 [51200/60000 (85%)]\tLoss: 589.619934\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 385 [0/60000 (0%)]\tLoss: 589.122437\n",
      "Train Epoch: 385 [25600/60000 (43%)]\tLoss: 589.649109\n",
      "Train Epoch: 385 [51200/60000 (85%)]\tLoss: 588.224670\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 386 [0/60000 (0%)]\tLoss: 590.416077\n",
      "Train Epoch: 386 [25600/60000 (43%)]\tLoss: 589.823975\n",
      "Train Epoch: 386 [51200/60000 (85%)]\tLoss: 589.375916\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 387 [0/60000 (0%)]\tLoss: 588.903320\n",
      "Train Epoch: 387 [25600/60000 (43%)]\tLoss: 589.086182\n",
      "Train Epoch: 387 [51200/60000 (85%)]\tLoss: 589.226990\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 388 [0/60000 (0%)]\tLoss: 589.854553\n",
      "Train Epoch: 388 [25600/60000 (43%)]\tLoss: 587.952515\n",
      "Train Epoch: 388 [51200/60000 (85%)]\tLoss: 589.723694\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 389 [0/60000 (0%)]\tLoss: 589.306824\n",
      "Train Epoch: 389 [25600/60000 (43%)]\tLoss: 589.035278\n",
      "Train Epoch: 389 [51200/60000 (85%)]\tLoss: 590.076355\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 390 [0/60000 (0%)]\tLoss: 588.653931\n",
      "Train Epoch: 390 [25600/60000 (43%)]\tLoss: 589.781555\n",
      "Train Epoch: 390 [51200/60000 (85%)]\tLoss: 588.000061\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 391 [0/60000 (0%)]\tLoss: 588.803101\n",
      "Train Epoch: 391 [25600/60000 (43%)]\tLoss: 588.792053\n",
      "Train Epoch: 391 [51200/60000 (85%)]\tLoss: 587.856140\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 392 [0/60000 (0%)]\tLoss: 588.762390\n",
      "Train Epoch: 392 [25600/60000 (43%)]\tLoss: 589.875305\n",
      "Train Epoch: 392 [51200/60000 (85%)]\tLoss: 590.864136\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 393 [0/60000 (0%)]\tLoss: 589.546509\n",
      "Train Epoch: 393 [25600/60000 (43%)]\tLoss: 588.742188\n",
      "Train Epoch: 393 [51200/60000 (85%)]\tLoss: 586.743958\n",
      "\n",
      "Test set: Average loss: 2.3013, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 394 [0/60000 (0%)]\tLoss: 589.939880\n",
      "Train Epoch: 394 [25600/60000 (43%)]\tLoss: 589.334656\n",
      "Train Epoch: 394 [51200/60000 (85%)]\tLoss: 588.772400\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 395 [0/60000 (0%)]\tLoss: 590.039734\n",
      "Train Epoch: 395 [25600/60000 (43%)]\tLoss: 589.035156\n",
      "Train Epoch: 395 [51200/60000 (85%)]\tLoss: 588.739502\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 396 [0/60000 (0%)]\tLoss: 589.539429\n",
      "Train Epoch: 396 [25600/60000 (43%)]\tLoss: 588.725525\n",
      "Train Epoch: 396 [51200/60000 (85%)]\tLoss: 588.976440\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 397 [0/60000 (0%)]\tLoss: 590.369507\n",
      "Train Epoch: 397 [25600/60000 (43%)]\tLoss: 589.457520\n",
      "Train Epoch: 397 [51200/60000 (85%)]\tLoss: 589.283630\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 398 [0/60000 (0%)]\tLoss: 588.830078\n",
      "Train Epoch: 398 [25600/60000 (43%)]\tLoss: 588.202148\n",
      "Train Epoch: 398 [51200/60000 (85%)]\tLoss: 588.997314\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 399 [0/60000 (0%)]\tLoss: 588.253418\n",
      "Train Epoch: 399 [25600/60000 (43%)]\tLoss: 589.904114\n",
      "Train Epoch: 399 [51200/60000 (85%)]\tLoss: 588.314148\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 400 [0/60000 (0%)]\tLoss: 588.758911\n",
      "Train Epoch: 400 [25600/60000 (43%)]\tLoss: 590.864502\n",
      "Train Epoch: 400 [51200/60000 (85%)]\tLoss: 589.840576\n",
      "\n",
      "Test set: Average loss: 2.3012, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 401 [0/60000 (0%)]\tLoss: 587.659058\n",
      "Train Epoch: 401 [25600/60000 (43%)]\tLoss: 590.080872\n",
      "Train Epoch: 401 [51200/60000 (85%)]\tLoss: 588.537170\n",
      "\n",
      "Test set: Average loss: 2.3015, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 402 [0/60000 (0%)]\tLoss: 588.569214\n",
      "Train Epoch: 402 [25600/60000 (43%)]\tLoss: 590.609924\n",
      "Train Epoch: 402 [51200/60000 (85%)]\tLoss: 588.636719\n",
      "\n",
      "Test set: Average loss: 2.3010, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 403 [0/60000 (0%)]\tLoss: 589.524292\n",
      "Train Epoch: 403 [25600/60000 (43%)]\tLoss: 588.595825\n",
      "Train Epoch: 403 [51200/60000 (85%)]\tLoss: 589.763184\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 404 [0/60000 (0%)]\tLoss: 590.213562\n",
      "Train Epoch: 404 [25600/60000 (43%)]\tLoss: 590.312988\n",
      "Train Epoch: 404 [51200/60000 (85%)]\tLoss: 589.365906\n",
      "\n",
      "Test set: Average loss: 2.3011, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 405 [0/60000 (0%)]\tLoss: 591.192383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1618:\n",
      "Process Process-1617:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lx/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lx/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lx/anaconda3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/lx/anaconda3/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/lx/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/lx/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/lx/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lx/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lx/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lx/anaconda3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 44, in _worker_loop\n",
      "    data_queue.put((idx, samples))\n",
      "  File \"/home/lx/anaconda3/lib/python3.5/multiprocessing/queues.py\", line 349, in put\n",
      "    obj = ForkingPickler.dumps(obj)\n",
      "  File \"/home/lx/anaconda3/lib/python3.5/multiprocessing/reduction.py\", line 50, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/home/lx/anaconda3/lib/python3.5/copyreg.py\", line 96, in _slotnames\n",
      "    def _slotnames(cls):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 405 [25600/60000 (43%)]\tLoss: 590.585815\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cef4d3e37508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m501\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-cef4d3e37508>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lx/anaconda3/lib/python3.5/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#使用pytorch封装的dataloader进行训练和预测\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def custom_normalization(data, std, mean):\n",
    "    return (data - mean) / std\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "batch_size = 256\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if use_gpu else {}\n",
    "\n",
    "X, y, Xt, yt = get_data()\n",
    "#主要进行标准化处理\n",
    "mean, std = X.mean(), X.std()\n",
    "X = custom_normlization(X, mean, std)\n",
    "Xt = custom_normlization(Xt, mean, std)\n",
    "\n",
    "train_x, train_y = torch.from_numpy(X.reshape(-1, 1, 28, 28)).float(), torch.from_numpy(y.astype(int))\n",
    "test_x, test_y = [\n",
    "    torch.from_numpy(Xt.reshape(-1, 1, 28, 28)).float(),\n",
    "    torch.from_numpy(yt.astype(int))\n",
    "    ]\n",
    "\n",
    "train_dataset = TensorDataset(data_tensor=train_x, target_tensor=train_y)\n",
    "test_dataset = TensorDataset(data_tensor=test_x, target_tensor=test_y)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size, **kwargs)\n",
    "test_loader = DataLoader(dataset=test_dataset, shuffle=True, batch_size=batch_size, **kwargs)\n",
    "\n",
    "model = LeNet5()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    print('USE GPU')\n",
    "else:\n",
    "    print('USE CPU')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "def weight_init(m):\n",
    "# 使用isinstance来判断m属于什么类型\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        import math\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "# m中的weight，bias其实都是Variable，为了能学习参数以及后向传播\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "model.apply(weight_init)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, 501):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#自定义训练预测\n",
    "\n",
    "print('Loading data')\n",
    "X, y, Xt, yt = get_data()\n",
    "X, Xt = torch.from_numpy(X.reshape(-1, 1, 28, 28)), torch.from_numpy(Xt.reshape(-1, 1, 28, 28))\n",
    "y, yt = torch.from_numpy(y.astype(float)), torch.from_numpy(yt.astype(float))\n",
    "\n",
    "print(X.size(), y.size())\n",
    "\n",
    "model = LeNet5()\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    print('USE GPU')\n",
    "else:\n",
    "    print('USE CPU')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    batch_size = 256\n",
    "    \n",
    "    for inx in range(int(X.shape[0]/batch_size)):\n",
    "        start_inx = inx * batch_size\n",
    "        end_inx = min((inx+1)*batch_size, X.shape[0])\n",
    "        mini_data = Variable(X[start_inx:end_inx].clone())\n",
    "        mini_label = Variable(y[start_inx:end_inx].clone())\n",
    "        mini_data = mini_data.type(torch.FloatTensor)\n",
    "        mini_label = mini_label.type(torch.LongTensor)\n",
    "        if use_gpu:\n",
    "            mini_data = mini_data.cuda()\n",
    "            mini_label = mini_label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        mini_out = model(mini_data)\n",
    "        mini_label = mini_label.view(end_inx-start_inx)\n",
    "#         print(mini_out.size(), mini_label.size())\n",
    "        mini_loss = criterion(mini_out, mini_label)\n",
    "        mini_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if inx % 50 == 0:\n",
    "            print('Train Epoch: {}/{}*256 loss is {:.4f}'.format(epoch, inx, mini_loss.data[0]))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "\n",
    "    correct = 0.\n",
    "    nb_test = Xt.shape[0]\n",
    "    for each_sample in range(nb_test):\n",
    "        sample_data = Variable(Xt[each_sample:each_sample+1].clone(), volatile=True)\n",
    "        sample_data = sample_data.type(torch.FloatTensor)\n",
    "        sample_label = Variable(yt[each_sample:each_sample+1].clone())\n",
    "        sample_label = sample_label.type(torch.LongTensor)\n",
    "        if use_gpu:\n",
    "            sample_data = sample_data.cuda()\n",
    "            sample_label = sample_label.cuda()\n",
    "            \n",
    "        sample_out = model(sample_data)\n",
    "        \n",
    "        test_loss += criterion(sample_out, sample_label)\n",
    "        \n",
    "        pred = sample_out.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(sample_label.data.view_as(pred)).cpu().sum()\n",
    "    loss =  (test_loss / nb_test).data[0]\n",
    "    acc = 100. * correct / nb_test\n",
    "    print('Test set: Avg Loss: {:.4f}, Accuracy: {}/{}({:.2f}%)'.format(loss, correct, nb_test, acc))\n",
    "    \n",
    "for epoch in range(2):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.utils.data.DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
