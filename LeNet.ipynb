{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip, struct\n",
    "import numpy as np\n",
    "\n",
    "def _read(image,label):\n",
    "    minist_dir = './data/'\n",
    "    with gzip.open(minist_dir+label) as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        label = np.fromstring(flbl.read(), dtype=np.int8)\n",
    "    with gzip.open(minist_dir+image, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)\n",
    "    return image,label\n",
    "\n",
    "def get_data():\n",
    "    train_img,train_label = _read(\n",
    "            'train-images-idx3-ubyte.gz', \n",
    "            'train-labels-idx1-ubyte.gz')\n",
    "    test_img,test_label = _read(\n",
    "            't10k-images-idx3-ubyte.gz', \n",
    "            't10k-labels-idx1-ubyte.gz')\n",
    "    return [train_img,train_label,test_img,test_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFyCAYAAAAkvWviAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d716f1eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X, y, Xt, yt = get_data()\n",
    "def imshow(img, label):\n",
    "    plt.imshow(img.reshape((28,28)))\n",
    "    plt.title(label)\n",
    "\n",
    "imshow(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE GPU\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 4127.210938\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 63.870522\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 36.791313\n",
      "\n",
      "Test set: Average loss: 0.1106, Accuracy: 9655/10000 (96.55%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 35.386135\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 22.772774\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 20.898764\n",
      "\n",
      "Test set: Average loss: 0.0770, Accuracy: 9761/10000 (97.61%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 6.149921\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 24.014883\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 10.355116\n",
      "\n",
      "Test set: Average loss: 0.0798, Accuracy: 9738/10000 (97.38%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 19.891045\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 11.729932\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 20.167507\n",
      "\n",
      "Test set: Average loss: 0.0629, Accuracy: 9806/10000 (98.06%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 7.828769\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 20.521906\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 10.705379\n",
      "\n",
      "Test set: Average loss: 0.0489, Accuracy: 9846/10000 (98.46%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 5.028975\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 17.325775\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 8.355356\n",
      "\n",
      "Test set: Average loss: 0.0456, Accuracy: 9866/10000 (98.66%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 6.473750\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 9.713346\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 5.274086\n",
      "\n",
      "Test set: Average loss: 0.0686, Accuracy: 9807/10000 (98.07%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 11.731788\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 3.906816\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 2.929698\n",
      "\n",
      "Test set: Average loss: 0.0489, Accuracy: 9853/10000 (98.53%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 7.094282\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 2.629207\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 6.858539\n",
      "\n",
      "Test set: Average loss: 0.0540, Accuracy: 9852/10000 (98.52%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.436391\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.560111\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 13.812416\n",
      "\n",
      "Test set: Average loss: 0.0530, Accuracy: 9854/10000 (98.54%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 4.713007\n",
      "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 0.512374\n",
      "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 11.012466\n",
      "\n",
      "Test set: Average loss: 0.0588, Accuracy: 9856/10000 (98.56%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 4.683085\n",
      "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 6.225711\n",
      "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 5.505061\n",
      "\n",
      "Test set: Average loss: 0.0592, Accuracy: 9863/10000 (98.63%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 2.133179\n",
      "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 0.275669\n",
      "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 7.941129\n",
      "\n",
      "Test set: Average loss: 0.0513, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.377829\n",
      "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 1.619674\n",
      "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.386870\n",
      "\n",
      "Test set: Average loss: 0.0603, Accuracy: 9854/10000 (98.54%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 1.659332\n",
      "Train Epoch: 15 [23040/60000 (38%)]\tLoss: 0.091094\n",
      "Train Epoch: 15 [46080/60000 (77%)]\tLoss: 3.255062\n",
      "\n",
      "Test set: Average loss: 0.0692, Accuracy: 9857/10000 (98.57%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 3.142441\n",
      "Train Epoch: 16 [23040/60000 (38%)]\tLoss: 0.682133\n",
      "Train Epoch: 16 [46080/60000 (77%)]\tLoss: 3.988318\n",
      "\n",
      "Test set: Average loss: 0.0682, Accuracy: 9863/10000 (98.63%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 2.036969\n",
      "Train Epoch: 17 [23040/60000 (38%)]\tLoss: 0.123426\n",
      "Train Epoch: 17 [46080/60000 (77%)]\tLoss: 0.119294\n",
      "\n",
      "Test set: Average loss: 0.0628, Accuracy: 9869/10000 (98.69%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 1.156393\n",
      "Train Epoch: 18 [23040/60000 (38%)]\tLoss: 0.212501\n",
      "Train Epoch: 18 [46080/60000 (77%)]\tLoss: 0.262414\n",
      "\n",
      "Test set: Average loss: 0.0635, Accuracy: 9880/10000 (98.80%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.338986\n",
      "Train Epoch: 19 [23040/60000 (38%)]\tLoss: 6.336810\n",
      "Train Epoch: 19 [46080/60000 (77%)]\tLoss: 0.402376\n",
      "\n",
      "Test set: Average loss: 0.0585, Accuracy: 9876/10000 (98.76%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.264740\n",
      "Train Epoch: 20 [23040/60000 (38%)]\tLoss: 3.343546\n",
      "Train Epoch: 20 [46080/60000 (77%)]\tLoss: 0.517933\n",
      "\n",
      "Test set: Average loss: 0.0531, Accuracy: 9875/10000 (98.75%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 2.123381\n",
      "Train Epoch: 21 [23040/60000 (38%)]\tLoss: 0.534062\n",
      "Train Epoch: 21 [46080/60000 (77%)]\tLoss: 0.100225\n",
      "\n",
      "Test set: Average loss: 0.0634, Accuracy: 9871/10000 (98.71%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 2.151620\n",
      "Train Epoch: 22 [23040/60000 (38%)]\tLoss: 0.818804\n",
      "Train Epoch: 22 [46080/60000 (77%)]\tLoss: 5.362047\n",
      "\n",
      "Test set: Average loss: 0.0859, Accuracy: 9851/10000 (98.51%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.362835\n",
      "Train Epoch: 23 [23040/60000 (38%)]\tLoss: 0.318786\n",
      "Train Epoch: 23 [46080/60000 (77%)]\tLoss: 0.823126\n",
      "\n",
      "Test set: Average loss: 0.0687, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 1.992530\n",
      "Train Epoch: 24 [23040/60000 (38%)]\tLoss: 0.229685\n",
      "Train Epoch: 24 [46080/60000 (77%)]\tLoss: 0.164112\n",
      "\n",
      "Test set: Average loss: 0.0887, Accuracy: 9853/10000 (98.53%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 1.178957\n",
      "Train Epoch: 25 [23040/60000 (38%)]\tLoss: 9.106397\n",
      "Train Epoch: 25 [46080/60000 (77%)]\tLoss: 3.124748\n",
      "\n",
      "Test set: Average loss: 0.0576, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.633591\n",
      "Train Epoch: 26 [23040/60000 (38%)]\tLoss: 0.990268\n",
      "Train Epoch: 26 [46080/60000 (77%)]\tLoss: 0.342319\n",
      "\n",
      "Test set: Average loss: 0.0730, Accuracy: 9866/10000 (98.66%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.013228\n",
      "Train Epoch: 27 [23040/60000 (38%)]\tLoss: 5.993859\n",
      "Train Epoch: 27 [46080/60000 (77%)]\tLoss: 0.051201\n",
      "\n",
      "Test set: Average loss: 0.0740, Accuracy: 9873/10000 (98.73%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.277920\n",
      "Train Epoch: 28 [23040/60000 (38%)]\tLoss: 1.228629\n",
      "Train Epoch: 28 [46080/60000 (77%)]\tLoss: 0.001974\n",
      "\n",
      "Test set: Average loss: 0.0655, Accuracy: 9876/10000 (98.76%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 5.189684\n",
      "Train Epoch: 29 [23040/60000 (38%)]\tLoss: 0.008667\n",
      "Train Epoch: 29 [46080/60000 (77%)]\tLoss: 3.544548\n",
      "\n",
      "Test set: Average loss: 0.0684, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.134315\n",
      "Train Epoch: 30 [23040/60000 (38%)]\tLoss: 1.583858\n",
      "Train Epoch: 30 [46080/60000 (77%)]\tLoss: 0.426960\n",
      "\n",
      "Test set: Average loss: 0.0730, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 5.655636\n",
      "Train Epoch: 31 [23040/60000 (38%)]\tLoss: 0.133623\n",
      "Train Epoch: 31 [46080/60000 (77%)]\tLoss: 0.671481\n",
      "\n",
      "Test set: Average loss: 0.0879, Accuracy: 9874/10000 (98.74%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.874710\n",
      "Train Epoch: 32 [23040/60000 (38%)]\tLoss: 1.212021\n",
      "Train Epoch: 32 [46080/60000 (77%)]\tLoss: 1.187538\n",
      "\n",
      "Test set: Average loss: 0.0705, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.032066\n",
      "Train Epoch: 33 [23040/60000 (38%)]\tLoss: 0.361233\n",
      "Train Epoch: 33 [46080/60000 (77%)]\tLoss: 4.179685\n",
      "\n",
      "Test set: Average loss: 0.0802, Accuracy: 9871/10000 (98.71%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.214134\n",
      "Train Epoch: 34 [23040/60000 (38%)]\tLoss: 0.362101\n",
      "Train Epoch: 34 [46080/60000 (77%)]\tLoss: 0.273243\n",
      "\n",
      "Test set: Average loss: 0.0800, Accuracy: 9878/10000 (98.78%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 3.635143\n",
      "Train Epoch: 35 [23040/60000 (38%)]\tLoss: 0.230288\n",
      "Train Epoch: 35 [46080/60000 (77%)]\tLoss: 0.009339\n",
      "\n",
      "Test set: Average loss: 0.0917, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.012641\n",
      "Train Epoch: 36 [23040/60000 (38%)]\tLoss: 15.744657\n",
      "Train Epoch: 36 [46080/60000 (77%)]\tLoss: 5.449926\n",
      "\n",
      "Test set: Average loss: 0.0817, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.016824\n",
      "Train Epoch: 37 [23040/60000 (38%)]\tLoss: 0.630241\n",
      "Train Epoch: 37 [46080/60000 (77%)]\tLoss: 0.949772\n",
      "\n",
      "Test set: Average loss: 0.0910, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.797684\n",
      "Train Epoch: 38 [23040/60000 (38%)]\tLoss: 0.388655\n",
      "Train Epoch: 38 [46080/60000 (77%)]\tLoss: 0.479096\n",
      "\n",
      "Test set: Average loss: 0.0928, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 2.669061\n",
      "Train Epoch: 39 [23040/60000 (38%)]\tLoss: 1.968828\n",
      "Train Epoch: 39 [46080/60000 (77%)]\tLoss: 3.914385\n",
      "\n",
      "Test set: Average loss: 0.0969, Accuracy: 9874/10000 (98.74%)\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 1.384108\n",
      "Train Epoch: 40 [23040/60000 (38%)]\tLoss: 4.913291\n",
      "Train Epoch: 40 [46080/60000 (77%)]\tLoss: 0.025640\n",
      "\n",
      "Test set: Average loss: 0.0922, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.568205\n",
      "Train Epoch: 41 [23040/60000 (38%)]\tLoss: 0.094482\n",
      "Train Epoch: 41 [46080/60000 (77%)]\tLoss: 4.203765\n",
      "\n",
      "Test set: Average loss: 0.0957, Accuracy: 9869/10000 (98.69%)\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 15.253247\n",
      "Train Epoch: 42 [23040/60000 (38%)]\tLoss: 0.007498\n",
      "Train Epoch: 42 [46080/60000 (77%)]\tLoss: 2.490419\n",
      "\n",
      "Test set: Average loss: 0.0767, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.050724\n",
      "Train Epoch: 43 [23040/60000 (38%)]\tLoss: 0.768255\n",
      "Train Epoch: 43 [46080/60000 (77%)]\tLoss: 0.095283\n",
      "\n",
      "Test set: Average loss: 0.0926, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.321723\n",
      "Train Epoch: 44 [23040/60000 (38%)]\tLoss: 0.007942\n",
      "Train Epoch: 44 [46080/60000 (77%)]\tLoss: 2.654390\n",
      "\n",
      "Test set: Average loss: 0.0922, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 6.931801\n",
      "Train Epoch: 45 [23040/60000 (38%)]\tLoss: 0.007739\n",
      "Train Epoch: 45 [46080/60000 (77%)]\tLoss: 0.033394\n",
      "\n",
      "Test set: Average loss: 0.1169, Accuracy: 9856/10000 (98.56%)\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.045341\n",
      "Train Epoch: 46 [23040/60000 (38%)]\tLoss: 0.008446\n",
      "Train Epoch: 46 [46080/60000 (77%)]\tLoss: 1.444957\n",
      "\n",
      "Test set: Average loss: 0.1140, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.000326\n",
      "Train Epoch: 47 [23040/60000 (38%)]\tLoss: 0.005007\n",
      "Train Epoch: 47 [46080/60000 (77%)]\tLoss: 0.171345\n",
      "\n",
      "Test set: Average loss: 0.1011, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.003987\n",
      "Train Epoch: 48 [23040/60000 (38%)]\tLoss: 0.324226\n",
      "Train Epoch: 48 [46080/60000 (77%)]\tLoss: 0.003738\n",
      "\n",
      "Test set: Average loss: 0.0865, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.111758\n",
      "Train Epoch: 49 [23040/60000 (38%)]\tLoss: 1.285741\n",
      "Train Epoch: 49 [46080/60000 (77%)]\tLoss: 0.059108\n",
      "\n",
      "Test set: Average loss: 0.1214, Accuracy: 9870/10000 (98.70%)\n",
      "\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 6.293393\n",
      "Train Epoch: 50 [23040/60000 (38%)]\tLoss: 0.001423\n",
      "Train Epoch: 50 [46080/60000 (77%)]\tLoss: 0.001078\n",
      "\n",
      "Test set: Average loss: 0.0997, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.062795\n",
      "Train Epoch: 51 [23040/60000 (38%)]\tLoss: 0.006798\n",
      "Train Epoch: 51 [46080/60000 (77%)]\tLoss: 0.021758\n",
      "\n",
      "Test set: Average loss: 0.0998, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.022027\n",
      "Train Epoch: 52 [23040/60000 (38%)]\tLoss: 2.309676\n",
      "Train Epoch: 52 [46080/60000 (77%)]\tLoss: 0.000248\n",
      "\n",
      "Test set: Average loss: 0.1058, Accuracy: 9876/10000 (98.76%)\n",
      "\n",
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.006579\n",
      "Train Epoch: 53 [23040/60000 (38%)]\tLoss: 0.063307\n",
      "Train Epoch: 53 [46080/60000 (77%)]\tLoss: 0.002514\n",
      "\n",
      "Test set: Average loss: 0.1032, Accuracy: 9880/10000 (98.80%)\n",
      "\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.698743\n",
      "Train Epoch: 54 [23040/60000 (38%)]\tLoss: 0.025471\n",
      "Train Epoch: 54 [46080/60000 (77%)]\tLoss: 0.010111\n",
      "\n",
      "Test set: Average loss: 0.0974, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.016163\n",
      "Train Epoch: 55 [23040/60000 (38%)]\tLoss: 0.107477\n",
      "Train Epoch: 55 [46080/60000 (77%)]\tLoss: 0.004803\n",
      "\n",
      "Test set: Average loss: 0.1017, Accuracy: 9868/10000 (98.68%)\n",
      "\n",
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 1.225368\n",
      "Train Epoch: 56 [23040/60000 (38%)]\tLoss: 0.028683\n",
      "Train Epoch: 56 [46080/60000 (77%)]\tLoss: 0.150797\n",
      "\n",
      "Test set: Average loss: 0.1034, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.000103\n",
      "Train Epoch: 57 [23040/60000 (38%)]\tLoss: 0.019474\n",
      "Train Epoch: 57 [46080/60000 (77%)]\tLoss: 0.029681\n",
      "\n",
      "Test set: Average loss: 0.1036, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.012784\n",
      "Train Epoch: 58 [23040/60000 (38%)]\tLoss: 3.046383\n",
      "Train Epoch: 58 [46080/60000 (77%)]\tLoss: 3.857064\n",
      "\n",
      "Test set: Average loss: 0.1102, Accuracy: 9883/10000 (98.83%)\n",
      "\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.147837\n",
      "Train Epoch: 59 [23040/60000 (38%)]\tLoss: 0.813969\n",
      "Train Epoch: 59 [46080/60000 (77%)]\tLoss: 1.388144\n",
      "\n",
      "Test set: Average loss: 0.1061, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.024036\n",
      "Train Epoch: 60 [23040/60000 (38%)]\tLoss: 0.008360\n",
      "Train Epoch: 60 [46080/60000 (77%)]\tLoss: 0.132812\n",
      "\n",
      "Test set: Average loss: 0.1315, Accuracy: 9873/10000 (98.73%)\n",
      "\n",
      "Train Epoch: 61 [0/60000 (0%)]\tLoss: 0.000146\n",
      "Train Epoch: 61 [23040/60000 (38%)]\tLoss: 0.000127\n",
      "Train Epoch: 61 [46080/60000 (77%)]\tLoss: 0.004984\n",
      "\n",
      "Test set: Average loss: 0.1409, Accuracy: 9864/10000 (98.64%)\n",
      "\n",
      "Train Epoch: 62 [0/60000 (0%)]\tLoss: 0.069610\n",
      "Train Epoch: 62 [23040/60000 (38%)]\tLoss: 1.259058\n",
      "Train Epoch: 62 [46080/60000 (77%)]\tLoss: 0.008391\n",
      "\n",
      "Test set: Average loss: 0.1111, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 63 [0/60000 (0%)]\tLoss: 1.231482\n",
      "Train Epoch: 63 [23040/60000 (38%)]\tLoss: 0.014835\n",
      "Train Epoch: 63 [46080/60000 (77%)]\tLoss: 0.054787\n",
      "\n",
      "Test set: Average loss: 0.1236, Accuracy: 9880/10000 (98.80%)\n",
      "\n",
      "Train Epoch: 64 [0/60000 (0%)]\tLoss: 4.023617\n",
      "Train Epoch: 64 [23040/60000 (38%)]\tLoss: 1.591599\n",
      "Train Epoch: 64 [46080/60000 (77%)]\tLoss: 5.463704\n",
      "\n",
      "Test set: Average loss: 0.1247, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 65 [0/60000 (0%)]\tLoss: 4.807964\n",
      "Train Epoch: 65 [23040/60000 (38%)]\tLoss: 4.829681\n",
      "Train Epoch: 65 [46080/60000 (77%)]\tLoss: 6.408978\n",
      "\n",
      "Test set: Average loss: 0.1413, Accuracy: 9875/10000 (98.75%)\n",
      "\n",
      "Train Epoch: 66 [0/60000 (0%)]\tLoss: 0.017394\n",
      "Train Epoch: 66 [23040/60000 (38%)]\tLoss: 3.768135\n",
      "Train Epoch: 66 [46080/60000 (77%)]\tLoss: 10.460539\n",
      "\n",
      "Test set: Average loss: 0.1270, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 67 [0/60000 (0%)]\tLoss: 1.203478\n",
      "Train Epoch: 67 [23040/60000 (38%)]\tLoss: 0.005019\n",
      "Train Epoch: 67 [46080/60000 (77%)]\tLoss: 0.000533\n",
      "\n",
      "Test set: Average loss: 0.1450, Accuracy: 9873/10000 (98.73%)\n",
      "\n",
      "Train Epoch: 68 [0/60000 (0%)]\tLoss: 5.892666\n",
      "Train Epoch: 68 [23040/60000 (38%)]\tLoss: 0.009649\n",
      "Train Epoch: 68 [46080/60000 (77%)]\tLoss: 0.131160\n",
      "\n",
      "Test set: Average loss: 0.1292, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 69 [0/60000 (0%)]\tLoss: 1.157116\n",
      "Train Epoch: 69 [23040/60000 (38%)]\tLoss: 0.015481\n",
      "Train Epoch: 69 [46080/60000 (77%)]\tLoss: 0.118884\n",
      "\n",
      "Test set: Average loss: 0.1481, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 70 [0/60000 (0%)]\tLoss: 0.002745\n",
      "Train Epoch: 70 [23040/60000 (38%)]\tLoss: 1.357240\n",
      "Train Epoch: 70 [46080/60000 (77%)]\tLoss: 0.016357\n",
      "\n",
      "Test set: Average loss: 0.1466, Accuracy: 9871/10000 (98.71%)\n",
      "\n",
      "Train Epoch: 71 [0/60000 (0%)]\tLoss: 10.317493\n",
      "Train Epoch: 71 [23040/60000 (38%)]\tLoss: 0.305263\n",
      "Train Epoch: 71 [46080/60000 (77%)]\tLoss: 0.004725\n",
      "\n",
      "Test set: Average loss: 0.1514, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 72 [0/60000 (0%)]\tLoss: 0.003636\n",
      "Train Epoch: 72 [23040/60000 (38%)]\tLoss: 0.013094\n",
      "Train Epoch: 72 [46080/60000 (77%)]\tLoss: 0.032477\n",
      "\n",
      "Test set: Average loss: 0.1346, Accuracy: 9897/10000 (98.97%)\n",
      "\n",
      "Train Epoch: 73 [0/60000 (0%)]\tLoss: 1.800394\n",
      "Train Epoch: 73 [23040/60000 (38%)]\tLoss: 0.356592\n",
      "Train Epoch: 73 [46080/60000 (77%)]\tLoss: 0.023690\n",
      "\n",
      "Test set: Average loss: 0.1227, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch: 74 [0/60000 (0%)]\tLoss: 0.017008\n",
      "Train Epoch: 74 [23040/60000 (38%)]\tLoss: 0.829794\n",
      "Train Epoch: 74 [46080/60000 (77%)]\tLoss: 2.666967\n",
      "\n",
      "Test set: Average loss: 0.1330, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 75 [0/60000 (0%)]\tLoss: 0.001033\n",
      "Train Epoch: 75 [23040/60000 (38%)]\tLoss: 8.033222\n",
      "Train Epoch: 75 [46080/60000 (77%)]\tLoss: 0.000878\n",
      "\n",
      "Test set: Average loss: 0.1379, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 76 [0/60000 (0%)]\tLoss: 0.017723\n",
      "Train Epoch: 76 [23040/60000 (38%)]\tLoss: 0.000458\n",
      "Train Epoch: 76 [46080/60000 (77%)]\tLoss: 0.001426\n",
      "\n",
      "Test set: Average loss: 0.1357, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 77 [0/60000 (0%)]\tLoss: 0.169115\n",
      "Train Epoch: 77 [23040/60000 (38%)]\tLoss: 0.001568\n",
      "Train Epoch: 77 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.1790, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 78 [0/60000 (0%)]\tLoss: 0.000735\n",
      "Train Epoch: 78 [23040/60000 (38%)]\tLoss: 2.550270\n",
      "Train Epoch: 78 [46080/60000 (77%)]\tLoss: 8.151745\n",
      "\n",
      "Test set: Average loss: 0.1457, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 79 [0/60000 (0%)]\tLoss: 0.004137\n",
      "Train Epoch: 79 [23040/60000 (38%)]\tLoss: 0.002170\n",
      "Train Epoch: 79 [46080/60000 (77%)]\tLoss: 0.001917\n",
      "\n",
      "Test set: Average loss: 0.1470, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 80 [0/60000 (0%)]\tLoss: 3.310493\n",
      "Train Epoch: 80 [23040/60000 (38%)]\tLoss: 0.596748\n",
      "Train Epoch: 80 [46080/60000 (77%)]\tLoss: 0.000002\n",
      "\n",
      "Test set: Average loss: 0.1321, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 81 [0/60000 (0%)]\tLoss: 0.000222\n",
      "Train Epoch: 81 [23040/60000 (38%)]\tLoss: 0.000012\n",
      "Train Epoch: 81 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.1617, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 82 [0/60000 (0%)]\tLoss: 0.000041\n",
      "Train Epoch: 82 [23040/60000 (38%)]\tLoss: 0.026873\n",
      "Train Epoch: 82 [46080/60000 (77%)]\tLoss: 0.102178\n",
      "\n",
      "Test set: Average loss: 0.1584, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 83 [0/60000 (0%)]\tLoss: 1.822319\n",
      "Train Epoch: 83 [23040/60000 (38%)]\tLoss: 0.074124\n",
      "Train Epoch: 83 [46080/60000 (77%)]\tLoss: 5.949557\n",
      "\n",
      "Test set: Average loss: 0.1824, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 84 [0/60000 (0%)]\tLoss: 0.253710\n",
      "Train Epoch: 84 [23040/60000 (38%)]\tLoss: 0.052259\n",
      "Train Epoch: 84 [46080/60000 (77%)]\tLoss: 12.245751\n",
      "\n",
      "Test set: Average loss: 0.1526, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 85 [0/60000 (0%)]\tLoss: 0.000028\n",
      "Train Epoch: 85 [23040/60000 (38%)]\tLoss: 0.002142\n",
      "Train Epoch: 85 [46080/60000 (77%)]\tLoss: 0.001370\n",
      "\n",
      "Test set: Average loss: 0.1494, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 86 [0/60000 (0%)]\tLoss: 0.000010\n",
      "Train Epoch: 86 [23040/60000 (38%)]\tLoss: 0.000888\n",
      "Train Epoch: 86 [46080/60000 (77%)]\tLoss: 0.010431\n",
      "\n",
      "Test set: Average loss: 0.1663, Accuracy: 9866/10000 (98.66%)\n",
      "\n",
      "Train Epoch: 87 [0/60000 (0%)]\tLoss: 0.096644\n",
      "Train Epoch: 87 [23040/60000 (38%)]\tLoss: 0.000039\n",
      "Train Epoch: 87 [46080/60000 (77%)]\tLoss: 0.011743\n",
      "\n",
      "Test set: Average loss: 0.1491, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 88 [0/60000 (0%)]\tLoss: 0.000021\n",
      "Train Epoch: 88 [23040/60000 (38%)]\tLoss: 0.002473\n",
      "Train Epoch: 88 [46080/60000 (77%)]\tLoss: 0.011744\n",
      "\n",
      "Test set: Average loss: 0.1718, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 89 [0/60000 (0%)]\tLoss: 0.000005\n",
      "Train Epoch: 89 [23040/60000 (38%)]\tLoss: 6.664964\n",
      "Train Epoch: 89 [46080/60000 (77%)]\tLoss: 0.000872\n",
      "\n",
      "Test set: Average loss: 0.1685, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 90 [0/60000 (0%)]\tLoss: 0.006362\n",
      "Train Epoch: 90 [23040/60000 (38%)]\tLoss: 0.000547\n",
      "Train Epoch: 90 [46080/60000 (77%)]\tLoss: 1.396505\n",
      "\n",
      "Test set: Average loss: 0.1673, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 91 [0/60000 (0%)]\tLoss: 2.431539\n",
      "Train Epoch: 91 [23040/60000 (38%)]\tLoss: 8.867603\n",
      "Train Epoch: 91 [46080/60000 (77%)]\tLoss: 0.000526\n",
      "\n",
      "Test set: Average loss: 0.1529, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 92 [0/60000 (0%)]\tLoss: 0.008875\n",
      "Train Epoch: 92 [23040/60000 (38%)]\tLoss: 0.767366\n",
      "Train Epoch: 92 [46080/60000 (77%)]\tLoss: 0.170989\n",
      "\n",
      "Test set: Average loss: 0.1499, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 93 [0/60000 (0%)]\tLoss: 1.457658\n",
      "Train Epoch: 93 [23040/60000 (38%)]\tLoss: 0.002626\n",
      "Train Epoch: 93 [46080/60000 (77%)]\tLoss: 0.000687\n",
      "\n",
      "Test set: Average loss: 0.1604, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 94 [0/60000 (0%)]\tLoss: 2.121451\n",
      "Train Epoch: 94 [23040/60000 (38%)]\tLoss: 0.301337\n",
      "Train Epoch: 94 [46080/60000 (77%)]\tLoss: 0.201747\n",
      "\n",
      "Test set: Average loss: 0.1722, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch: 95 [0/60000 (0%)]\tLoss: 0.000174\n",
      "Train Epoch: 95 [23040/60000 (38%)]\tLoss: 0.000009\n",
      "Train Epoch: 95 [46080/60000 (77%)]\tLoss: 0.016434\n",
      "\n",
      "Test set: Average loss: 0.1650, Accuracy: 9872/10000 (98.72%)\n",
      "\n",
      "Train Epoch: 96 [0/60000 (0%)]\tLoss: 17.780003\n",
      "Train Epoch: 96 [23040/60000 (38%)]\tLoss: 0.017282\n",
      "Train Epoch: 96 [46080/60000 (77%)]\tLoss: 0.041686\n",
      "\n",
      "Test set: Average loss: 0.1788, Accuracy: 9879/10000 (98.79%)\n",
      "\n",
      "Train Epoch: 97 [0/60000 (0%)]\tLoss: 0.274937\n",
      "Train Epoch: 97 [23040/60000 (38%)]\tLoss: 0.000235\n",
      "Train Epoch: 97 [46080/60000 (77%)]\tLoss: 0.001968\n",
      "\n",
      "Test set: Average loss: 0.1500, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 98 [0/60000 (0%)]\tLoss: 0.003749\n",
      "Train Epoch: 98 [23040/60000 (38%)]\tLoss: 0.905060\n",
      "Train Epoch: 98 [46080/60000 (77%)]\tLoss: 0.000286\n",
      "\n",
      "Test set: Average loss: 0.1464, Accuracy: 9902/10000 (99.02%)\n",
      "\n",
      "Train Epoch: 99 [0/60000 (0%)]\tLoss: 0.000120\n",
      "Train Epoch: 99 [23040/60000 (38%)]\tLoss: 4.452101\n",
      "Train Epoch: 99 [46080/60000 (77%)]\tLoss: 0.003266\n",
      "\n",
      "Test set: Average loss: 0.1748, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 100 [0/60000 (0%)]\tLoss: 0.819401\n",
      "Train Epoch: 100 [23040/60000 (38%)]\tLoss: 0.001172\n",
      "Train Epoch: 100 [46080/60000 (77%)]\tLoss: 0.005463\n",
      "\n",
      "Test set: Average loss: 0.1768, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 101 [0/60000 (0%)]\tLoss: 0.014654\n",
      "Train Epoch: 101 [23040/60000 (38%)]\tLoss: 0.160879\n",
      "Train Epoch: 101 [46080/60000 (77%)]\tLoss: 0.000002\n",
      "\n",
      "Test set: Average loss: 0.1956, Accuracy: 9883/10000 (98.83%)\n",
      "\n",
      "Train Epoch: 102 [0/60000 (0%)]\tLoss: 0.941123\n",
      "Train Epoch: 102 [23040/60000 (38%)]\tLoss: 0.000694\n",
      "Train Epoch: 102 [46080/60000 (77%)]\tLoss: 1.860166\n",
      "\n",
      "Test set: Average loss: 0.1854, Accuracy: 9883/10000 (98.83%)\n",
      "\n",
      "Train Epoch: 103 [0/60000 (0%)]\tLoss: 0.002869\n",
      "Train Epoch: 103 [23040/60000 (38%)]\tLoss: 0.000981\n",
      "Train Epoch: 103 [46080/60000 (77%)]\tLoss: 0.001971\n",
      "\n",
      "Test set: Average loss: 0.2467, Accuracy: 9880/10000 (98.80%)\n",
      "\n",
      "Train Epoch: 104 [0/60000 (0%)]\tLoss: 0.000006\n",
      "Train Epoch: 104 [23040/60000 (38%)]\tLoss: 0.019812\n",
      "Train Epoch: 104 [46080/60000 (77%)]\tLoss: 0.082697\n",
      "\n",
      "Test set: Average loss: 0.1927, Accuracy: 9878/10000 (98.78%)\n",
      "\n",
      "Train Epoch: 105 [0/60000 (0%)]\tLoss: 0.000045\n",
      "Train Epoch: 105 [23040/60000 (38%)]\tLoss: 1.387121\n",
      "Train Epoch: 105 [46080/60000 (77%)]\tLoss: 0.001231\n",
      "\n",
      "Test set: Average loss: 0.1897, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 106 [0/60000 (0%)]\tLoss: 2.187911\n",
      "Train Epoch: 106 [23040/60000 (38%)]\tLoss: 0.000682\n",
      "Train Epoch: 106 [46080/60000 (77%)]\tLoss: 0.000353\n",
      "\n",
      "Test set: Average loss: 0.2165, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 107 [0/60000 (0%)]\tLoss: 0.002716\n",
      "Train Epoch: 107 [23040/60000 (38%)]\tLoss: 0.000327\n",
      "Train Epoch: 107 [46080/60000 (77%)]\tLoss: 0.000001\n",
      "\n",
      "Test set: Average loss: 0.1915, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 108 [0/60000 (0%)]\tLoss: 0.000014\n",
      "Train Epoch: 108 [23040/60000 (38%)]\tLoss: 0.000002\n",
      "Train Epoch: 108 [46080/60000 (77%)]\tLoss: 21.559540\n",
      "\n",
      "Test set: Average loss: 0.2056, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 109 [0/60000 (0%)]\tLoss: 0.000037\n",
      "Train Epoch: 109 [23040/60000 (38%)]\tLoss: 0.000504\n",
      "Train Epoch: 109 [46080/60000 (77%)]\tLoss: 0.000001\n",
      "\n",
      "Test set: Average loss: 0.1831, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 110 [0/60000 (0%)]\tLoss: 0.000227\n",
      "Train Epoch: 110 [23040/60000 (38%)]\tLoss: 0.000502\n",
      "Train Epoch: 110 [46080/60000 (77%)]\tLoss: 0.000484\n",
      "\n",
      "Test set: Average loss: 0.1942, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 111 [0/60000 (0%)]\tLoss: 0.002591\n",
      "Train Epoch: 111 [23040/60000 (38%)]\tLoss: 0.258126\n",
      "Train Epoch: 111 [46080/60000 (77%)]\tLoss: 0.001266\n",
      "\n",
      "Test set: Average loss: 0.2002, Accuracy: 9878/10000 (98.78%)\n",
      "\n",
      "Train Epoch: 112 [0/60000 (0%)]\tLoss: 0.000153\n",
      "Train Epoch: 112 [23040/60000 (38%)]\tLoss: 0.002259\n",
      "Train Epoch: 112 [46080/60000 (77%)]\tLoss: 2.474641\n",
      "\n",
      "Test set: Average loss: 0.1857, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 113 [0/60000 (0%)]\tLoss: 0.002433\n",
      "Train Epoch: 113 [23040/60000 (38%)]\tLoss: 0.060294\n",
      "Train Epoch: 113 [46080/60000 (77%)]\tLoss: 0.001245\n",
      "\n",
      "Test set: Average loss: 0.2105, Accuracy: 9864/10000 (98.64%)\n",
      "\n",
      "Train Epoch: 114 [0/60000 (0%)]\tLoss: 0.000886\n",
      "Train Epoch: 114 [23040/60000 (38%)]\tLoss: 0.000101\n",
      "Train Epoch: 114 [46080/60000 (77%)]\tLoss: 8.012959\n",
      "\n",
      "Test set: Average loss: 0.2290, Accuracy: 9868/10000 (98.68%)\n",
      "\n",
      "Train Epoch: 115 [0/60000 (0%)]\tLoss: 0.007919\n",
      "Train Epoch: 115 [23040/60000 (38%)]\tLoss: 0.000052\n",
      "Train Epoch: 115 [46080/60000 (77%)]\tLoss: 0.000427\n",
      "\n",
      "Test set: Average loss: 0.1756, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 116 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 116 [23040/60000 (38%)]\tLoss: 0.000004\n",
      "Train Epoch: 116 [46080/60000 (77%)]\tLoss: 19.592234\n",
      "\n",
      "Test set: Average loss: 0.2128, Accuracy: 9874/10000 (98.74%)\n",
      "\n",
      "Train Epoch: 117 [0/60000 (0%)]\tLoss: 0.269340\n",
      "Train Epoch: 117 [23040/60000 (38%)]\tLoss: 0.035672\n",
      "Train Epoch: 117 [46080/60000 (77%)]\tLoss: 5.272902\n",
      "\n",
      "Test set: Average loss: 0.1876, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 118 [0/60000 (0%)]\tLoss: 0.000042\n",
      "Train Epoch: 118 [23040/60000 (38%)]\tLoss: 2.597849\n",
      "Train Epoch: 118 [46080/60000 (77%)]\tLoss: 0.008125\n",
      "\n",
      "Test set: Average loss: 0.2095, Accuracy: 9876/10000 (98.76%)\n",
      "\n",
      "Train Epoch: 119 [0/60000 (0%)]\tLoss: 0.013828\n",
      "Train Epoch: 119 [23040/60000 (38%)]\tLoss: 10.312392\n",
      "Train Epoch: 119 [46080/60000 (77%)]\tLoss: 0.014579\n",
      "\n",
      "Test set: Average loss: 0.2360, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 120 [0/60000 (0%)]\tLoss: 0.001564\n",
      "Train Epoch: 120 [23040/60000 (38%)]\tLoss: 0.015965\n",
      "Train Epoch: 120 [46080/60000 (77%)]\tLoss: 0.000005\n",
      "\n",
      "Test set: Average loss: 0.2213, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 121 [0/60000 (0%)]\tLoss: 0.001169\n",
      "Train Epoch: 121 [23040/60000 (38%)]\tLoss: 0.000164\n",
      "Train Epoch: 121 [46080/60000 (77%)]\tLoss: 0.000029\n",
      "\n",
      "Test set: Average loss: 0.1949, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 122 [0/60000 (0%)]\tLoss: 2.311373\n",
      "Train Epoch: 122 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 122 [46080/60000 (77%)]\tLoss: 0.000107\n",
      "\n",
      "Test set: Average loss: 0.2087, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 123 [0/60000 (0%)]\tLoss: 0.000963\n",
      "Train Epoch: 123 [23040/60000 (38%)]\tLoss: 0.000002\n",
      "Train Epoch: 123 [46080/60000 (77%)]\tLoss: 0.002997\n",
      "\n",
      "Test set: Average loss: 0.2678, Accuracy: 9879/10000 (98.79%)\n",
      "\n",
      "Train Epoch: 124 [0/60000 (0%)]\tLoss: 0.000010\n",
      "Train Epoch: 124 [23040/60000 (38%)]\tLoss: 6.343144\n",
      "Train Epoch: 124 [46080/60000 (77%)]\tLoss: 0.639295\n",
      "\n",
      "Test set: Average loss: 0.2202, Accuracy: 9876/10000 (98.76%)\n",
      "\n",
      "Train Epoch: 125 [0/60000 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 125 [23040/60000 (38%)]\tLoss: 0.001903\n",
      "Train Epoch: 125 [46080/60000 (77%)]\tLoss: 0.000054\n",
      "\n",
      "Test set: Average loss: 0.2040, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 126 [0/60000 (0%)]\tLoss: 0.000042\n",
      "Train Epoch: 126 [23040/60000 (38%)]\tLoss: 0.000065\n",
      "Train Epoch: 126 [46080/60000 (77%)]\tLoss: 0.001044\n",
      "\n",
      "Test set: Average loss: 0.2082, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 127 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 127 [23040/60000 (38%)]\tLoss: 0.059498\n",
      "Train Epoch: 127 [46080/60000 (77%)]\tLoss: 0.019098\n",
      "\n",
      "Test set: Average loss: 0.2499, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 128 [0/60000 (0%)]\tLoss: 0.000036\n",
      "Train Epoch: 128 [23040/60000 (38%)]\tLoss: 3.760666\n",
      "Train Epoch: 128 [46080/60000 (77%)]\tLoss: 0.001157\n",
      "\n",
      "Test set: Average loss: 0.2245, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 129 [0/60000 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 129 [23040/60000 (38%)]\tLoss: 0.000324\n",
      "Train Epoch: 129 [46080/60000 (77%)]\tLoss: 0.000001\n",
      "\n",
      "Test set: Average loss: 0.2175, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 130 [0/60000 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 130 [23040/60000 (38%)]\tLoss: 0.000781\n",
      "Train Epoch: 130 [46080/60000 (77%)]\tLoss: 0.431947\n",
      "\n",
      "Test set: Average loss: 0.2635, Accuracy: 9879/10000 (98.79%)\n",
      "\n",
      "Train Epoch: 131 [0/60000 (0%)]\tLoss: 0.005130\n",
      "Train Epoch: 131 [23040/60000 (38%)]\tLoss: 0.003070\n",
      "Train Epoch: 131 [46080/60000 (77%)]\tLoss: 0.005242\n",
      "\n",
      "Test set: Average loss: 0.2524, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 132 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 132 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 132 [46080/60000 (77%)]\tLoss: 0.000040\n",
      "\n",
      "Test set: Average loss: 0.2740, Accuracy: 9883/10000 (98.83%)\n",
      "\n",
      "Train Epoch: 133 [0/60000 (0%)]\tLoss: 0.080534\n",
      "Train Epoch: 133 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 133 [46080/60000 (77%)]\tLoss: 0.000009\n",
      "\n",
      "Test set: Average loss: 0.2345, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 134 [0/60000 (0%)]\tLoss: 0.000704\n",
      "Train Epoch: 134 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 134 [46080/60000 (77%)]\tLoss: 0.000127\n",
      "\n",
      "Test set: Average loss: 0.2428, Accuracy: 9880/10000 (98.80%)\n",
      "\n",
      "Train Epoch: 135 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 135 [23040/60000 (38%)]\tLoss: 0.001640\n",
      "Train Epoch: 135 [46080/60000 (77%)]\tLoss: 0.001827\n",
      "\n",
      "Test set: Average loss: 0.1956, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 136 [0/60000 (0%)]\tLoss: 0.004641\n",
      "Train Epoch: 136 [23040/60000 (38%)]\tLoss: 0.000073\n",
      "Train Epoch: 136 [46080/60000 (77%)]\tLoss: 0.000687\n",
      "\n",
      "Test set: Average loss: 0.2704, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 137 [0/60000 (0%)]\tLoss: 0.029020\n",
      "Train Epoch: 137 [23040/60000 (38%)]\tLoss: 0.000030\n",
      "Train Epoch: 137 [46080/60000 (77%)]\tLoss: 0.000118\n",
      "\n",
      "Test set: Average loss: 0.2420, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 138 [0/60000 (0%)]\tLoss: 0.000019\n",
      "Train Epoch: 138 [23040/60000 (38%)]\tLoss: 4.027377\n",
      "Train Epoch: 138 [46080/60000 (77%)]\tLoss: 0.000132\n",
      "\n",
      "Test set: Average loss: 0.2743, Accuracy: 9868/10000 (98.68%)\n",
      "\n",
      "Train Epoch: 139 [0/60000 (0%)]\tLoss: 0.000034\n",
      "Train Epoch: 139 [23040/60000 (38%)]\tLoss: 0.000379\n",
      "Train Epoch: 139 [46080/60000 (77%)]\tLoss: 0.000033\n",
      "\n",
      "Test set: Average loss: 0.2515, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 140 [0/60000 (0%)]\tLoss: 0.011815\n",
      "Train Epoch: 140 [23040/60000 (38%)]\tLoss: 0.359544\n",
      "Train Epoch: 140 [46080/60000 (77%)]\tLoss: 0.000034\n",
      "\n",
      "Test set: Average loss: 0.2756, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 141 [0/60000 (0%)]\tLoss: 0.000008\n",
      "Train Epoch: 141 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 141 [46080/60000 (77%)]\tLoss: 1.467913\n",
      "\n",
      "Test set: Average loss: 0.2942, Accuracy: 9879/10000 (98.79%)\n",
      "\n",
      "Train Epoch: 142 [0/60000 (0%)]\tLoss: 0.000002\n",
      "Train Epoch: 142 [23040/60000 (38%)]\tLoss: 0.052460\n",
      "Train Epoch: 142 [46080/60000 (77%)]\tLoss: 25.474060\n",
      "\n",
      "Test set: Average loss: 0.2719, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 143 [0/60000 (0%)]\tLoss: 0.000072\n",
      "Train Epoch: 143 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 143 [46080/60000 (77%)]\tLoss: 0.000087\n",
      "\n",
      "Test set: Average loss: 0.2830, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 144 [0/60000 (0%)]\tLoss: 0.004771\n",
      "Train Epoch: 144 [23040/60000 (38%)]\tLoss: 7.326644\n",
      "Train Epoch: 144 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.2378, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      "Train Epoch: 145 [0/60000 (0%)]\tLoss: 0.000013\n",
      "Train Epoch: 145 [23040/60000 (38%)]\tLoss: 0.000136\n",
      "Train Epoch: 145 [46080/60000 (77%)]\tLoss: 0.000001\n",
      "\n",
      "Test set: Average loss: 0.2553, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      "Train Epoch: 146 [0/60000 (0%)]\tLoss: 0.014817\n",
      "Train Epoch: 146 [23040/60000 (38%)]\tLoss: 0.000001\n",
      "Train Epoch: 146 [46080/60000 (77%)]\tLoss: 1.821943\n",
      "\n",
      "Test set: Average loss: 0.2458, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      "Train Epoch: 147 [0/60000 (0%)]\tLoss: 0.082983\n",
      "Train Epoch: 147 [23040/60000 (38%)]\tLoss: 0.000030\n",
      "Train Epoch: 147 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.2301, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 148 [0/60000 (0%)]\tLoss: 0.001459\n",
      "Train Epoch: 148 [23040/60000 (38%)]\tLoss: 0.248858\n",
      "Train Epoch: 148 [46080/60000 (77%)]\tLoss: 0.000008\n",
      "\n",
      "Test set: Average loss: 0.2470, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 149 [0/60000 (0%)]\tLoss: 0.006993\n",
      "Train Epoch: 149 [23040/60000 (38%)]\tLoss: 4.053028\n",
      "Train Epoch: 149 [46080/60000 (77%)]\tLoss: 0.001460\n",
      "\n",
      "Test set: Average loss: 0.2138, Accuracy: 9903/10000 (99.03%)\n",
      "\n",
      "Train Epoch: 150 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 150 [23040/60000 (38%)]\tLoss: 0.008324\n",
      "Train Epoch: 150 [46080/60000 (77%)]\tLoss: 0.003787\n",
      "\n",
      "Test set: Average loss: 0.2957, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 151 [0/60000 (0%)]\tLoss: 0.005967\n",
      "Train Epoch: 151 [23040/60000 (38%)]\tLoss: 0.004106\n",
      "Train Epoch: 151 [46080/60000 (77%)]\tLoss: 0.009913\n",
      "\n",
      "Test set: Average loss: 0.2756, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 152 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 152 [23040/60000 (38%)]\tLoss: 0.067595\n",
      "Train Epoch: 152 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.2486, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "Train Epoch: 153 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 153 [23040/60000 (38%)]\tLoss: 4.501696\n",
      "Train Epoch: 153 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.2725, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 154 [0/60000 (0%)]\tLoss: 0.000306\n",
      "Train Epoch: 154 [23040/60000 (38%)]\tLoss: 3.431772\n",
      "Train Epoch: 154 [46080/60000 (77%)]\tLoss: 18.292229\n",
      "\n",
      "Test set: Average loss: 0.2193, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 155 [0/60000 (0%)]\tLoss: 2.486029\n",
      "Train Epoch: 155 [23040/60000 (38%)]\tLoss: 0.000025\n",
      "Train Epoch: 155 [46080/60000 (77%)]\tLoss: 0.423198\n",
      "\n",
      "Test set: Average loss: 0.2307, Accuracy: 9907/10000 (99.07%)\n",
      "\n",
      "Train Epoch: 156 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 156 [23040/60000 (38%)]\tLoss: 0.000006\n",
      "Train Epoch: 156 [46080/60000 (77%)]\tLoss: 0.031685\n",
      "\n",
      "Test set: Average loss: 0.2940, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 157 [0/60000 (0%)]\tLoss: 1.977871\n",
      "Train Epoch: 157 [23040/60000 (38%)]\tLoss: 26.106403\n",
      "Train Epoch: 157 [46080/60000 (77%)]\tLoss: 0.254482\n",
      "\n",
      "Test set: Average loss: 0.2654, Accuracy: 9908/10000 (99.08%)\n",
      "\n",
      "Train Epoch: 158 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 158 [23040/60000 (38%)]\tLoss: 2.719079\n",
      "Train Epoch: 158 [46080/60000 (77%)]\tLoss: 63.636940\n",
      "\n",
      "Test set: Average loss: 0.2810, Accuracy: 9878/10000 (98.78%)\n",
      "\n",
      "Train Epoch: 159 [0/60000 (0%)]\tLoss: 0.000199\n",
      "Train Epoch: 159 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 159 [46080/60000 (77%)]\tLoss: 0.000009\n",
      "\n",
      "Test set: Average loss: 0.2981, Accuracy: 9880/10000 (98.80%)\n",
      "\n",
      "Train Epoch: 160 [0/60000 (0%)]\tLoss: 2.721706\n",
      "Train Epoch: 160 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 160 [46080/60000 (77%)]\tLoss: 0.000170\n",
      "\n",
      "Test set: Average loss: 0.2356, Accuracy: 9908/10000 (99.08%)\n",
      "\n",
      "Train Epoch: 161 [0/60000 (0%)]\tLoss: 0.000009\n",
      "Train Epoch: 161 [23040/60000 (38%)]\tLoss: 0.000022\n",
      "Train Epoch: 161 [46080/60000 (77%)]\tLoss: 0.002674\n",
      "\n",
      "Test set: Average loss: 0.2320, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 162 [0/60000 (0%)]\tLoss: 0.005515\n",
      "Train Epoch: 162 [23040/60000 (38%)]\tLoss: 0.000010\n",
      "Train Epoch: 162 [46080/60000 (77%)]\tLoss: 0.000135\n",
      "\n",
      "Test set: Average loss: 0.3319, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 163 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 163 [23040/60000 (38%)]\tLoss: 0.102028\n",
      "Train Epoch: 163 [46080/60000 (77%)]\tLoss: 0.000349\n",
      "\n",
      "Test set: Average loss: 0.2656, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 164 [0/60000 (0%)]\tLoss: 0.000002\n",
      "Train Epoch: 164 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 164 [46080/60000 (77%)]\tLoss: 0.000006\n",
      "\n",
      "Test set: Average loss: 0.2547, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 165 [0/60000 (0%)]\tLoss: 0.000293\n",
      "Train Epoch: 165 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 165 [46080/60000 (77%)]\tLoss: 0.014897\n",
      "\n",
      "Test set: Average loss: 0.3193, Accuracy: 9872/10000 (98.72%)\n",
      "\n",
      "Train Epoch: 166 [0/60000 (0%)]\tLoss: 0.028307\n",
      "Train Epoch: 166 [23040/60000 (38%)]\tLoss: 0.003050\n",
      "Train Epoch: 166 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.2987, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch: 167 [0/60000 (0%)]\tLoss: 0.006515\n",
      "Train Epoch: 167 [23040/60000 (38%)]\tLoss: 0.001231\n",
      "Train Epoch: 167 [46080/60000 (77%)]\tLoss: 2.799191\n",
      "\n",
      "Test set: Average loss: 0.2970, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 168 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 168 [23040/60000 (38%)]\tLoss: 0.001074\n",
      "Train Epoch: 168 [46080/60000 (77%)]\tLoss: 0.001081\n",
      "\n",
      "Test set: Average loss: 0.3456, Accuracy: 9860/10000 (98.60%)\n",
      "\n",
      "Train Epoch: 169 [0/60000 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 169 [23040/60000 (38%)]\tLoss: 0.000032\n",
      "Train Epoch: 169 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3159, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 170 [0/60000 (0%)]\tLoss: 0.000016\n",
      "Train Epoch: 170 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 170 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3635, Accuracy: 9883/10000 (98.83%)\n",
      "\n",
      "Train Epoch: 171 [0/60000 (0%)]\tLoss: 0.001436\n",
      "Train Epoch: 171 [23040/60000 (38%)]\tLoss: 0.000008\n",
      "Train Epoch: 171 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3722, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 172 [0/60000 (0%)]\tLoss: 12.373724\n",
      "Train Epoch: 172 [23040/60000 (38%)]\tLoss: 0.262209\n",
      "Train Epoch: 172 [46080/60000 (77%)]\tLoss: 3.828026\n",
      "\n",
      "Test set: Average loss: 0.3401, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 173 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 173 [23040/60000 (38%)]\tLoss: 0.008788\n",
      "Train Epoch: 173 [46080/60000 (77%)]\tLoss: 0.000066\n",
      "\n",
      "Test set: Average loss: 0.3222, Accuracy: 9906/10000 (99.06%)\n",
      "\n",
      "Train Epoch: 174 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 174 [23040/60000 (38%)]\tLoss: 0.000013\n",
      "Train Epoch: 174 [46080/60000 (77%)]\tLoss: 0.002036\n",
      "\n",
      "Test set: Average loss: 0.2914, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 175 [0/60000 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 175 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 175 [46080/60000 (77%)]\tLoss: 0.000002\n",
      "\n",
      "Test set: Average loss: 0.3757, Accuracy: 9877/10000 (98.77%)\n",
      "\n",
      "Train Epoch: 176 [0/60000 (0%)]\tLoss: 0.001202\n",
      "Train Epoch: 176 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 176 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3283, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 177 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 177 [23040/60000 (38%)]\tLoss: 0.000068\n",
      "Train Epoch: 177 [46080/60000 (77%)]\tLoss: 0.000009\n",
      "\n",
      "Test set: Average loss: 0.3658, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 178 [0/60000 (0%)]\tLoss: 0.027990\n",
      "Train Epoch: 178 [23040/60000 (38%)]\tLoss: 0.042282\n",
      "Train Epoch: 178 [46080/60000 (77%)]\tLoss: 0.053929\n",
      "\n",
      "Test set: Average loss: 0.4162, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 179 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 179 [23040/60000 (38%)]\tLoss: 0.000005\n",
      "Train Epoch: 179 [46080/60000 (77%)]\tLoss: 0.071734\n",
      "\n",
      "Test set: Average loss: 0.3404, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 180 [0/60000 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 180 [23040/60000 (38%)]\tLoss: 1.264893\n",
      "Train Epoch: 180 [46080/60000 (77%)]\tLoss: 0.070268\n",
      "\n",
      "Test set: Average loss: 0.3018, Accuracy: 9902/10000 (99.02%)\n",
      "\n",
      "Train Epoch: 181 [0/60000 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 181 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 181 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4247, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 182 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 182 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 182 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3372, Accuracy: 9902/10000 (99.02%)\n",
      "\n",
      "Train Epoch: 183 [0/60000 (0%)]\tLoss: 0.355418\n",
      "Train Epoch: 183 [23040/60000 (38%)]\tLoss: 0.000001\n",
      "Train Epoch: 183 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3279, Accuracy: 9904/10000 (99.04%)\n",
      "\n",
      "Train Epoch: 184 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 184 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 184 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3624, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 185 [0/60000 (0%)]\tLoss: 0.166032\n",
      "Train Epoch: 185 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 185 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3330, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 186 [0/60000 (0%)]\tLoss: 4.210304\n",
      "Train Epoch: 186 [23040/60000 (38%)]\tLoss: 0.069644\n",
      "Train Epoch: 186 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.5023, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 187 [0/60000 (0%)]\tLoss: 0.217582\n",
      "Train Epoch: 187 [23040/60000 (38%)]\tLoss: 0.000004\n",
      "Train Epoch: 187 [46080/60000 (77%)]\tLoss: 0.000017\n",
      "\n",
      "Test set: Average loss: 0.4284, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 188 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 188 [23040/60000 (38%)]\tLoss: 0.000003\n",
      "Train Epoch: 188 [46080/60000 (77%)]\tLoss: 0.000126\n",
      "\n",
      "Test set: Average loss: 0.3686, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 189 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 189 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 189 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3053, Accuracy: 9897/10000 (98.97%)\n",
      "\n",
      "Train Epoch: 190 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 190 [23040/60000 (38%)]\tLoss: 0.187682\n",
      "Train Epoch: 190 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4034, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 191 [0/60000 (0%)]\tLoss: 0.000084\n",
      "Train Epoch: 191 [23040/60000 (38%)]\tLoss: 0.001763\n",
      "Train Epoch: 191 [46080/60000 (77%)]\tLoss: 0.000032\n",
      "\n",
      "Test set: Average loss: 0.3091, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "Train Epoch: 192 [0/60000 (0%)]\tLoss: 0.040400\n",
      "Train Epoch: 192 [23040/60000 (38%)]\tLoss: 0.000391\n",
      "Train Epoch: 192 [46080/60000 (77%)]\tLoss: 0.026628\n",
      "\n",
      "Test set: Average loss: 0.3116, Accuracy: 9904/10000 (99.04%)\n",
      "\n",
      "Train Epoch: 193 [0/60000 (0%)]\tLoss: 0.033053\n",
      "Train Epoch: 193 [23040/60000 (38%)]\tLoss: 0.000002\n",
      "Train Epoch: 193 [46080/60000 (77%)]\tLoss: 7.961144\n",
      "\n",
      "Test set: Average loss: 0.3894, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 194 [0/60000 (0%)]\tLoss: 42.066170\n",
      "Train Epoch: 194 [23040/60000 (38%)]\tLoss: 14.100583\n",
      "Train Epoch: 194 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3354, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 195 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 195 [23040/60000 (38%)]\tLoss: 10.278756\n",
      "Train Epoch: 195 [46080/60000 (77%)]\tLoss: 0.011603\n",
      "\n",
      "Test set: Average loss: 0.3601, Accuracy: 9876/10000 (98.76%)\n",
      "\n",
      "Train Epoch: 196 [0/60000 (0%)]\tLoss: 0.000912\n",
      "Train Epoch: 196 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 196 [46080/60000 (77%)]\tLoss: 0.000002\n",
      "\n",
      "Test set: Average loss: 0.3761, Accuracy: 9898/10000 (98.98%)\n",
      "\n",
      "Train Epoch: 197 [0/60000 (0%)]\tLoss: 0.270112\n",
      "Train Epoch: 197 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 197 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3730, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 198 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 198 [23040/60000 (38%)]\tLoss: 0.017630\n",
      "Train Epoch: 198 [46080/60000 (77%)]\tLoss: 0.004200\n",
      "\n",
      "Test set: Average loss: 0.3524, Accuracy: 9904/10000 (99.04%)\n",
      "\n",
      "Train Epoch: 199 [0/60000 (0%)]\tLoss: 0.028395\n",
      "Train Epoch: 199 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 199 [46080/60000 (77%)]\tLoss: 6.544156\n",
      "\n",
      "Test set: Average loss: 0.3125, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "Train Epoch: 200 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 200 [23040/60000 (38%)]\tLoss: 1.000627\n",
      "Train Epoch: 200 [46080/60000 (77%)]\tLoss: 0.019224\n",
      "\n",
      "Test set: Average loss: 0.4169, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 201 [0/60000 (0%)]\tLoss: 0.009733\n",
      "Train Epoch: 201 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 201 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3425, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 202 [0/60000 (0%)]\tLoss: 0.006373\n",
      "Train Epoch: 202 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 202 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3634, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 203 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 203 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 203 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3297, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 204 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 204 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 204 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4005, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 205 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 205 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 205 [46080/60000 (77%)]\tLoss: 0.042498\n",
      "\n",
      "Test set: Average loss: 0.3598, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      "Train Epoch: 206 [0/60000 (0%)]\tLoss: 0.000048\n",
      "Train Epoch: 206 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 206 [46080/60000 (77%)]\tLoss: 0.000003\n",
      "\n",
      "Test set: Average loss: 0.3330, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "Train Epoch: 207 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 207 [23040/60000 (38%)]\tLoss: 0.001946\n",
      "Train Epoch: 207 [46080/60000 (77%)]\tLoss: 0.000014\n",
      "\n",
      "Test set: Average loss: 0.5795, Accuracy: 9871/10000 (98.71%)\n",
      "\n",
      "Train Epoch: 208 [0/60000 (0%)]\tLoss: 11.065893\n",
      "Train Epoch: 208 [23040/60000 (38%)]\tLoss: 1.819312\n",
      "Train Epoch: 208 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4272, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 209 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 209 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 209 [46080/60000 (77%)]\tLoss: 0.000483\n",
      "\n",
      "Test set: Average loss: 0.5050, Accuracy: 9879/10000 (98.79%)\n",
      "\n",
      "Train Epoch: 210 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 210 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 210 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4194, Accuracy: 9897/10000 (98.97%)\n",
      "\n",
      "Train Epoch: 211 [0/60000 (0%)]\tLoss: 0.000033\n",
      "Train Epoch: 211 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 211 [46080/60000 (77%)]\tLoss: 0.012542\n",
      "\n",
      "Test set: Average loss: 0.4423, Accuracy: 9897/10000 (98.97%)\n",
      "\n",
      "Train Epoch: 212 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 212 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 212 [46080/60000 (77%)]\tLoss: 1.303177\n",
      "\n",
      "Test set: Average loss: 0.4163, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      "Train Epoch: 213 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 213 [23040/60000 (38%)]\tLoss: 0.000007\n",
      "Train Epoch: 213 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3695, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "Train Epoch: 214 [0/60000 (0%)]\tLoss: 0.000049\n",
      "Train Epoch: 214 [23040/60000 (38%)]\tLoss: 0.002086\n",
      "Train Epoch: 214 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3284, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "Train Epoch: 215 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 215 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 215 [46080/60000 (77%)]\tLoss: 0.007489\n",
      "\n",
      "Test set: Average loss: 0.4160, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 216 [0/60000 (0%)]\tLoss: 0.000099\n",
      "Train Epoch: 216 [23040/60000 (38%)]\tLoss: 0.268483\n",
      "Train Epoch: 216 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3311, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 217 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 217 [23040/60000 (38%)]\tLoss: 0.000004\n",
      "Train Epoch: 217 [46080/60000 (77%)]\tLoss: 0.000021\n",
      "\n",
      "Test set: Average loss: 0.4975, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 218 [0/60000 (0%)]\tLoss: 10.236560\n",
      "Train Epoch: 218 [23040/60000 (38%)]\tLoss: 0.039670\n",
      "Train Epoch: 218 [46080/60000 (77%)]\tLoss: 0.003162\n",
      "\n",
      "Test set: Average loss: 0.4754, Accuracy: 9874/10000 (98.74%)\n",
      "\n",
      "Train Epoch: 219 [0/60000 (0%)]\tLoss: 0.001584\n",
      "Train Epoch: 219 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 219 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3718, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 220 [0/60000 (0%)]\tLoss: 0.000022\n",
      "Train Epoch: 220 [23040/60000 (38%)]\tLoss: 0.001047\n",
      "Train Epoch: 220 [46080/60000 (77%)]\tLoss: 5.126067\n",
      "\n",
      "Test set: Average loss: 0.4337, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 221 [0/60000 (0%)]\tLoss: 0.000010\n",
      "Train Epoch: 221 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 221 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4209, Accuracy: 9904/10000 (99.04%)\n",
      "\n",
      "Train Epoch: 222 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 222 [23040/60000 (38%)]\tLoss: 0.000006\n",
      "Train Epoch: 222 [46080/60000 (77%)]\tLoss: 0.000005\n",
      "\n",
      "Test set: Average loss: 0.4085, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "Train Epoch: 223 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 223 [23040/60000 (38%)]\tLoss: 0.000001\n",
      "Train Epoch: 223 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4557, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "Train Epoch: 224 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 224 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 224 [46080/60000 (77%)]\tLoss: 0.004888\n",
      "\n",
      "Test set: Average loss: 0.3682, Accuracy: 9903/10000 (99.03%)\n",
      "\n",
      "Train Epoch: 225 [0/60000 (0%)]\tLoss: 4.025650\n",
      "Train Epoch: 225 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 225 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3582, Accuracy: 9912/10000 (99.12%)\n",
      "\n",
      "Train Epoch: 226 [0/60000 (0%)]\tLoss: 0.000002\n",
      "Train Epoch: 226 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 226 [46080/60000 (77%)]\tLoss: 12.651883\n",
      "\n",
      "Test set: Average loss: 0.4037, Accuracy: 9912/10000 (99.12%)\n",
      "\n",
      "Train Epoch: 227 [0/60000 (0%)]\tLoss: 0.000003\n",
      "Train Epoch: 227 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 227 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.5259, Accuracy: 9878/10000 (98.78%)\n",
      "\n",
      "Train Epoch: 228 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 228 [23040/60000 (38%)]\tLoss: 0.000001\n",
      "Train Epoch: 228 [46080/60000 (77%)]\tLoss: 24.208153\n",
      "\n",
      "Test set: Average loss: 0.5284, Accuracy: 9880/10000 (98.80%)\n",
      "\n",
      "Train Epoch: 229 [0/60000 (0%)]\tLoss: 0.000673\n",
      "Train Epoch: 229 [23040/60000 (38%)]\tLoss: 5.616499\n",
      "Train Epoch: 229 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4314, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      "Train Epoch: 230 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 230 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 230 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3761, Accuracy: 9920/10000 (99.20%)\n",
      "\n",
      "Train Epoch: 231 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 231 [23040/60000 (38%)]\tLoss: 0.000010\n",
      "Train Epoch: 231 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4363, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 232 [0/60000 (0%)]\tLoss: 18.624577\n",
      "Train Epoch: 232 [23040/60000 (38%)]\tLoss: 0.012788\n",
      "Train Epoch: 232 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3847, Accuracy: 9902/10000 (99.02%)\n",
      "\n",
      "Train Epoch: 233 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 233 [23040/60000 (38%)]\tLoss: 0.000816\n",
      "Train Epoch: 233 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4288, Accuracy: 9904/10000 (99.04%)\n",
      "\n",
      "Train Epoch: 234 [0/60000 (0%)]\tLoss: 0.000295\n",
      "Train Epoch: 234 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 234 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4314, Accuracy: 9879/10000 (98.79%)\n",
      "\n",
      "Train Epoch: 235 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 235 [23040/60000 (38%)]\tLoss: 0.000005\n",
      "Train Epoch: 235 [46080/60000 (77%)]\tLoss: 0.000009\n",
      "\n",
      "Test set: Average loss: 0.4472, Accuracy: 9902/10000 (99.02%)\n",
      "\n",
      "Train Epoch: 236 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 236 [23040/60000 (38%)]\tLoss: 6.896466\n",
      "Train Epoch: 236 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4787, Accuracy: 9898/10000 (98.98%)\n",
      "\n",
      "Train Epoch: 237 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 237 [23040/60000 (38%)]\tLoss: 0.000012\n",
      "Train Epoch: 237 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.5144, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 238 [0/60000 (0%)]\tLoss: 0.004512\n",
      "Train Epoch: 238 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 238 [46080/60000 (77%)]\tLoss: 0.000021\n",
      "\n",
      "Test set: Average loss: 0.5779, Accuracy: 9880/10000 (98.80%)\n",
      "\n",
      "Train Epoch: 239 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 239 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 239 [46080/60000 (77%)]\tLoss: 0.014362\n",
      "\n",
      "Test set: Average loss: 0.5435, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 240 [0/60000 (0%)]\tLoss: 0.000853\n",
      "Train Epoch: 240 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 240 [46080/60000 (77%)]\tLoss: 0.028759\n",
      "\n",
      "Test set: Average loss: 0.4167, Accuracy: 9904/10000 (99.04%)\n",
      "\n",
      "Train Epoch: 241 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 241 [23040/60000 (38%)]\tLoss: 0.000001\n",
      "Train Epoch: 241 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4917, Accuracy: 9904/10000 (99.04%)\n",
      "\n",
      "Train Epoch: 242 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 242 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 242 [46080/60000 (77%)]\tLoss: 0.000015\n",
      "\n",
      "Test set: Average loss: 0.5075, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 243 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 243 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 243 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4755, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 244 [0/60000 (0%)]\tLoss: 0.000024\n",
      "Train Epoch: 244 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 244 [46080/60000 (77%)]\tLoss: 5.436176\n",
      "\n",
      "Test set: Average loss: 0.4754, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 245 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 245 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 245 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4826, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 246 [0/60000 (0%)]\tLoss: 0.526268\n",
      "Train Epoch: 246 [23040/60000 (38%)]\tLoss: 38.303070\n",
      "Train Epoch: 246 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4961, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch: 247 [0/60000 (0%)]\tLoss: 37.344601\n",
      "Train Epoch: 247 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 247 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4010, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "Train Epoch: 248 [0/60000 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 248 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 248 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.3983, Accuracy: 9918/10000 (99.18%)\n",
      "\n",
      "Train Epoch: 249 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 249 [23040/60000 (38%)]\tLoss: 0.008409\n",
      "Train Epoch: 249 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4734, Accuracy: 9914/10000 (99.14%)\n",
      "\n",
      "Train Epoch: 250 [0/60000 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 250 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 250 [46080/60000 (77%)]\tLoss: 0.021195\n",
      "\n",
      "Test set: Average loss: 0.4722, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 251 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 251 [23040/60000 (38%)]\tLoss: 2.099178\n",
      "Train Epoch: 251 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4749, Accuracy: 9909/10000 (99.09%)\n",
      "\n",
      "Train Epoch: 252 [0/60000 (0%)]\tLoss: 1.299745\n",
      "Train Epoch: 252 [23040/60000 (38%)]\tLoss: 0.000008\n",
      "Train Epoch: 252 [46080/60000 (77%)]\tLoss: 2.615680\n",
      "\n",
      "Test set: Average loss: 0.4091, Accuracy: 9913/10000 (99.13%)\n",
      "\n",
      "Train Epoch: 253 [0/60000 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 253 [23040/60000 (38%)]\tLoss: 0.699186\n",
      "Train Epoch: 253 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.4286, Accuracy: 9910/10000 (99.10%)\n",
      "\n",
      "Train Epoch: 254 [0/60000 (0%)]\tLoss: 0.000271\n",
      "Train Epoch: 254 [23040/60000 (38%)]\tLoss: 19.083672\n",
      "Train Epoch: 254 [46080/60000 (77%)]\tLoss: 0.000546\n",
      "\n",
      "Test set: Average loss: 0.4231, Accuracy: 9907/10000 (99.07%)\n",
      "\n",
      "Train Epoch: 255 [0/60000 (0%)]\tLoss: 5.758759\n",
      "Train Epoch: 255 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 255 [46080/60000 (77%)]\tLoss: 0.042686\n",
      "\n",
      "Test set: Average loss: 0.5320, Accuracy: 9880/10000 (98.80%)\n",
      "\n",
      "Train Epoch: 256 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 256 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 256 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.5318, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch: 257 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 257 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 257 [46080/60000 (77%)]\tLoss: 0.000078\n",
      "\n",
      "Test set: Average loss: 0.5407, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 258 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 258 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 258 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.5167, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 259 [0/60000 (0%)]\tLoss: 0.000008\n",
      "Train Epoch: 259 [23040/60000 (38%)]\tLoss: 0.000023\n",
      "Train Epoch: 259 [46080/60000 (77%)]\tLoss: 0.000002\n",
      "\n",
      "Test set: Average loss: 0.4972, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 260 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 260 [23040/60000 (38%)]\tLoss: 0.000008\n",
      "Train Epoch: 260 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.5064, Accuracy: 9898/10000 (98.98%)\n",
      "\n",
      "Train Epoch: 261 [0/60000 (0%)]\tLoss: 0.017238\n",
      "Train Epoch: 261 [23040/60000 (38%)]\tLoss: 12.708200\n",
      "Train Epoch: 261 [46080/60000 (77%)]\tLoss: 0.000010\n",
      "\n",
      "Test set: Average loss: 0.6905, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch: 262 [0/60000 (0%)]\tLoss: 0.013071\n",
      "Train Epoch: 262 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 262 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6608, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 263 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 263 [23040/60000 (38%)]\tLoss: 0.000001\n",
      "Train Epoch: 263 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.5982, Accuracy: 9878/10000 (98.78%)\n",
      "\n",
      "Train Epoch: 264 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 264 [23040/60000 (38%)]\tLoss: 0.000855\n",
      "Train Epoch: 264 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.5799, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 265 [0/60000 (0%)]\tLoss: 0.000017\n",
      "Train Epoch: 265 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 265 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6568, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 266 [0/60000 (0%)]\tLoss: 0.000002\n",
      "Train Epoch: 266 [23040/60000 (38%)]\tLoss: 0.001423\n",
      "Train Epoch: 266 [46080/60000 (77%)]\tLoss: 0.096353\n",
      "\n",
      "Test set: Average loss: 0.6183, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 267 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 267 [23040/60000 (38%)]\tLoss: 0.000305\n",
      "Train Epoch: 267 [46080/60000 (77%)]\tLoss: 0.000085\n",
      "\n",
      "Test set: Average loss: 0.5761, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 268 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 268 [23040/60000 (38%)]\tLoss: 1.618157\n",
      "Train Epoch: 268 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.5760, Accuracy: 9902/10000 (99.02%)\n",
      "\n",
      "Train Epoch: 269 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 269 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 269 [46080/60000 (77%)]\tLoss: 0.354897\n",
      "\n",
      "Test set: Average loss: 0.5879, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 270 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 270 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 270 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6809, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 271 [0/60000 (0%)]\tLoss: 2.502748\n",
      "Train Epoch: 271 [23040/60000 (38%)]\tLoss: 0.000082\n",
      "Train Epoch: 271 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6986, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 272 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 272 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 272 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6157, Accuracy: 9897/10000 (98.97%)\n",
      "\n",
      "Train Epoch: 273 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 273 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 273 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.5968, Accuracy: 9903/10000 (99.03%)\n",
      "\n",
      "Train Epoch: 274 [0/60000 (0%)]\tLoss: 0.180545\n",
      "Train Epoch: 274 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 274 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6477, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 275 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 275 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 275 [46080/60000 (77%)]\tLoss: 0.000298\n",
      "\n",
      "Test set: Average loss: 0.5998, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 276 [0/60000 (0%)]\tLoss: 0.000002\n",
      "Train Epoch: 276 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 276 [46080/60000 (77%)]\tLoss: 0.025799\n",
      "\n",
      "Test set: Average loss: 0.6226, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 277 [0/60000 (0%)]\tLoss: 0.000613\n",
      "Train Epoch: 277 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 277 [46080/60000 (77%)]\tLoss: 18.447521\n",
      "\n",
      "Test set: Average loss: 0.6254, Accuracy: 9907/10000 (99.07%)\n",
      "\n",
      "Train Epoch: 278 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 278 [23040/60000 (38%)]\tLoss: 0.000096\n",
      "Train Epoch: 278 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6110, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 279 [0/60000 (0%)]\tLoss: 2.173258\n",
      "Train Epoch: 279 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 279 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6329, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 280 [0/60000 (0%)]\tLoss: 9.268659\n",
      "Train Epoch: 280 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 280 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6348, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch: 281 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 281 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 281 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8250, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 282 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 282 [23040/60000 (38%)]\tLoss: 0.000002\n",
      "Train Epoch: 282 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9642, Accuracy: 9866/10000 (98.66%)\n",
      "\n",
      "Train Epoch: 283 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 283 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 283 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7178, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 284 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 284 [23040/60000 (38%)]\tLoss: 26.417595\n",
      "Train Epoch: 284 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7186, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 285 [0/60000 (0%)]\tLoss: 0.004188\n",
      "Train Epoch: 285 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 285 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6796, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 286 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 286 [23040/60000 (38%)]\tLoss: 0.162677\n",
      "Train Epoch: 286 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7252, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 287 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 287 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 287 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7477, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 288 [0/60000 (0%)]\tLoss: 5.550451\n",
      "Train Epoch: 288 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 288 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6761, Accuracy: 9897/10000 (98.97%)\n",
      "\n",
      "Train Epoch: 289 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 289 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 289 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8473, Accuracy: 9871/10000 (98.71%)\n",
      "\n",
      "Train Epoch: 290 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 290 [23040/60000 (38%)]\tLoss: 0.000001\n",
      "Train Epoch: 290 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7670, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 291 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 291 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 291 [46080/60000 (77%)]\tLoss: 0.000723\n",
      "\n",
      "Test set: Average loss: 0.7795, Accuracy: 9871/10000 (98.71%)\n",
      "\n",
      "Train Epoch: 292 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 292 [23040/60000 (38%)]\tLoss: 0.002888\n",
      "Train Epoch: 292 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8183, Accuracy: 9871/10000 (98.71%)\n",
      "\n",
      "Train Epoch: 293 [0/60000 (0%)]\tLoss: 0.000005\n",
      "Train Epoch: 293 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 293 [46080/60000 (77%)]\tLoss: 36.509571\n",
      "\n",
      "Test set: Average loss: 0.6803, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 294 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 294 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 294 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8929, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 295 [0/60000 (0%)]\tLoss: 0.007114\n",
      "Train Epoch: 295 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 295 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6176, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 296 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 296 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 296 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6625, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch: 297 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 297 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 297 [46080/60000 (77%)]\tLoss: 0.000001\n",
      "\n",
      "Test set: Average loss: 0.6714, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 298 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 298 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 298 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7704, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 299 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 299 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 299 [46080/60000 (77%)]\tLoss: 0.000290\n",
      "\n",
      "Test set: Average loss: 0.6828, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 300 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 300 [23040/60000 (38%)]\tLoss: 0.000107\n",
      "Train Epoch: 300 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6272, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 301 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 301 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 301 [46080/60000 (77%)]\tLoss: 0.002567\n",
      "\n",
      "Test set: Average loss: 0.7288, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 302 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 302 [23040/60000 (38%)]\tLoss: 0.000008\n",
      "Train Epoch: 302 [46080/60000 (77%)]\tLoss: 19.419672\n",
      "\n",
      "Test set: Average loss: 0.8915, Accuracy: 9877/10000 (98.77%)\n",
      "\n",
      "Train Epoch: 303 [0/60000 (0%)]\tLoss: 8.405938\n",
      "Train Epoch: 303 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 303 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6744, Accuracy: 9898/10000 (98.98%)\n",
      "\n",
      "Train Epoch: 304 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 304 [23040/60000 (38%)]\tLoss: 0.022770\n",
      "Train Epoch: 304 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7784, Accuracy: 9883/10000 (98.83%)\n",
      "\n",
      "Train Epoch: 305 [0/60000 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 305 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 305 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7288, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 306 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 306 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 306 [46080/60000 (77%)]\tLoss: 0.000038\n",
      "\n",
      "Test set: Average loss: 0.7559, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 307 [0/60000 (0%)]\tLoss: 0.002621\n",
      "Train Epoch: 307 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 307 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9158, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      "Train Epoch: 308 [0/60000 (0%)]\tLoss: 4.035534\n",
      "Train Epoch: 308 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 308 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8110, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 309 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 309 [23040/60000 (38%)]\tLoss: 0.002796\n",
      "Train Epoch: 309 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7529, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 310 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 310 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 310 [46080/60000 (77%)]\tLoss: 0.381275\n",
      "\n",
      "Test set: Average loss: 0.8333, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 311 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 311 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 311 [46080/60000 (77%)]\tLoss: 0.000004\n",
      "\n",
      "Test set: Average loss: 0.8789, Accuracy: 9903/10000 (99.03%)\n",
      "\n",
      "Train Epoch: 312 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 312 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 312 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9623, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 313 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 313 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 313 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8319, Accuracy: 9903/10000 (99.03%)\n",
      "\n",
      "Train Epoch: 314 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 314 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 314 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8342, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 315 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 315 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 315 [46080/60000 (77%)]\tLoss: 0.000057\n",
      "\n",
      "Test set: Average loss: 0.8595, Accuracy: 9897/10000 (98.97%)\n",
      "\n",
      "Train Epoch: 316 [0/60000 (0%)]\tLoss: 0.000910\n",
      "Train Epoch: 316 [23040/60000 (38%)]\tLoss: 0.000027\n",
      "Train Epoch: 316 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8520, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 317 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 317 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 317 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8470, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 318 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 318 [23040/60000 (38%)]\tLoss: 18.653389\n",
      "Train Epoch: 318 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9916, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 319 [0/60000 (0%)]\tLoss: 24.673748\n",
      "Train Epoch: 319 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 319 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8851, Accuracy: 9902/10000 (99.02%)\n",
      "\n",
      "Train Epoch: 320 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 320 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 320 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7585, Accuracy: 9910/10000 (99.10%)\n",
      "\n",
      "Train Epoch: 321 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 321 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 321 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8819, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 322 [0/60000 (0%)]\tLoss: 0.123835\n",
      "Train Epoch: 322 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 322 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7948, Accuracy: 9897/10000 (98.97%)\n",
      "\n",
      "Train Epoch: 323 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 323 [23040/60000 (38%)]\tLoss: 0.000424\n",
      "Train Epoch: 323 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9248, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      "Train Epoch: 324 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 324 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 324 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8005, Accuracy: 9903/10000 (99.03%)\n",
      "\n",
      "Train Epoch: 325 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 325 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 325 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8334, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 326 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 326 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 326 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7548, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "Train Epoch: 327 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 327 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 327 [46080/60000 (77%)]\tLoss: 0.000177\n",
      "\n",
      "Test set: Average loss: 0.7691, Accuracy: 9910/10000 (99.10%)\n",
      "\n",
      "Train Epoch: 328 [0/60000 (0%)]\tLoss: 0.000002\n",
      "Train Epoch: 328 [23040/60000 (38%)]\tLoss: 0.000002\n",
      "Train Epoch: 328 [46080/60000 (77%)]\tLoss: 0.161831\n",
      "\n",
      "Test set: Average loss: 0.6781, Accuracy: 9898/10000 (98.98%)\n",
      "\n",
      "Train Epoch: 329 [0/60000 (0%)]\tLoss: 0.000005\n",
      "Train Epoch: 329 [23040/60000 (38%)]\tLoss: 0.000115\n",
      "Train Epoch: 329 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.6425, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 330 [0/60000 (0%)]\tLoss: 0.010582\n",
      "Train Epoch: 330 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 330 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7469, Accuracy: 9880/10000 (98.80%)\n",
      "\n",
      "Train Epoch: 331 [0/60000 (0%)]\tLoss: 11.866745\n",
      "Train Epoch: 331 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 331 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7625, Accuracy: 9903/10000 (99.03%)\n",
      "\n",
      "Train Epoch: 332 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 332 [23040/60000 (38%)]\tLoss: 0.000057\n",
      "Train Epoch: 332 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8688, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 333 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 333 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 333 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8001, Accuracy: 9898/10000 (98.98%)\n",
      "\n",
      "Train Epoch: 334 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 334 [23040/60000 (38%)]\tLoss: 0.000002\n",
      "Train Epoch: 334 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8967, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 335 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 335 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 335 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8392, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch: 336 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 336 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 336 [46080/60000 (77%)]\tLoss: 0.000225\n",
      "\n",
      "Test set: Average loss: 0.8204, Accuracy: 9907/10000 (99.07%)\n",
      "\n",
      "Train Epoch: 337 [0/60000 (0%)]\tLoss: 0.220892\n",
      "Train Epoch: 337 [23040/60000 (38%)]\tLoss: 0.029473\n",
      "Train Epoch: 337 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7365, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 338 [0/60000 (0%)]\tLoss: 33.949028\n",
      "Train Epoch: 338 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 338 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7562, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "Train Epoch: 339 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 339 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 339 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8263, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 340 [0/60000 (0%)]\tLoss: 69.585152\n",
      "Train Epoch: 340 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 340 [46080/60000 (77%)]\tLoss: 0.010336\n",
      "\n",
      "Test set: Average loss: 1.0513, Accuracy: 9876/10000 (98.76%)\n",
      "\n",
      "Train Epoch: 341 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 341 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 341 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9183, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 342 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 342 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 342 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8410, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 343 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 343 [23040/60000 (38%)]\tLoss: 0.337824\n",
      "Train Epoch: 343 [46080/60000 (77%)]\tLoss: 0.000004\n",
      "\n",
      "Test set: Average loss: 0.7322, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      "Train Epoch: 344 [0/60000 (0%)]\tLoss: 24.898031\n",
      "Train Epoch: 344 [23040/60000 (38%)]\tLoss: 0.007553\n",
      "Train Epoch: 344 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8899, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 345 [0/60000 (0%)]\tLoss: 0.000010\n",
      "Train Epoch: 345 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 345 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7609, Accuracy: 9902/10000 (99.02%)\n",
      "\n",
      "Train Epoch: 346 [0/60000 (0%)]\tLoss: 0.000011\n",
      "Train Epoch: 346 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 346 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9601, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 347 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 347 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 347 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8679, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "Train Epoch: 348 [0/60000 (0%)]\tLoss: 2.518000\n",
      "Train Epoch: 348 [23040/60000 (38%)]\tLoss: 0.006736\n",
      "Train Epoch: 348 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8717, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 349 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 349 [23040/60000 (38%)]\tLoss: 0.000005\n",
      "Train Epoch: 349 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8357, Accuracy: 9904/10000 (99.04%)\n",
      "\n",
      "Train Epoch: 350 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 350 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 350 [46080/60000 (77%)]\tLoss: 0.020935\n",
      "\n",
      "Test set: Average loss: 0.8956, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 351 [0/60000 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 351 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 351 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8969, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 352 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 352 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 352 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7870, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 353 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 353 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 353 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8002, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 354 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 354 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 354 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.7510, Accuracy: 9908/10000 (99.08%)\n",
      "\n",
      "Train Epoch: 355 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 355 [23040/60000 (38%)]\tLoss: 0.000002\n",
      "Train Epoch: 355 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8934, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 356 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 356 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 356 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9780, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 357 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 357 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 357 [46080/60000 (77%)]\tLoss: 0.000001\n",
      "\n",
      "Test set: Average loss: 0.9252, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 358 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 358 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 358 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9010, Accuracy: 9897/10000 (98.97%)\n",
      "\n",
      "Train Epoch: 359 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 359 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 359 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9928, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 360 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 360 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 360 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9734, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 361 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 361 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 361 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9138, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 362 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 362 [23040/60000 (38%)]\tLoss: 0.000008\n",
      "Train Epoch: 362 [46080/60000 (77%)]\tLoss: 0.000978\n",
      "\n",
      "Test set: Average loss: 0.9212, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 363 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 363 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 363 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9586, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 364 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 364 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 364 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9030, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 365 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 365 [23040/60000 (38%)]\tLoss: 31.206238\n",
      "Train Epoch: 365 [46080/60000 (77%)]\tLoss: 16.680546\n",
      "\n",
      "Test set: Average loss: 0.9432, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 366 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 366 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 366 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9209, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 367 [0/60000 (0%)]\tLoss: 12.143572\n",
      "Train Epoch: 367 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 367 [46080/60000 (77%)]\tLoss: 1.965020\n",
      "\n",
      "Test set: Average loss: 0.8767, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 368 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 368 [23040/60000 (38%)]\tLoss: 0.000021\n",
      "Train Epoch: 368 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9402, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 369 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 369 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 369 [46080/60000 (77%)]\tLoss: 0.001236\n",
      "\n",
      "Test set: Average loss: 1.3292, Accuracy: 9861/10000 (98.61%)\n",
      "\n",
      "Train Epoch: 370 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 370 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 370 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0948, Accuracy: 9879/10000 (98.79%)\n",
      "\n",
      "Train Epoch: 371 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 371 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 371 [46080/60000 (77%)]\tLoss: 0.139977\n",
      "\n",
      "Test set: Average loss: 0.9468, Accuracy: 9902/10000 (99.02%)\n",
      "\n",
      "Train Epoch: 372 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 372 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 372 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0406, Accuracy: 9904/10000 (99.04%)\n",
      "\n",
      "Train Epoch: 373 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 373 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 373 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1038, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 374 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 374 [23040/60000 (38%)]\tLoss: 0.000029\n",
      "Train Epoch: 374 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9577, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 375 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 375 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 375 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1221, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 376 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 376 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 376 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0200, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 377 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 377 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 377 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9861, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch: 378 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 378 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 378 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0521, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 379 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 379 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 379 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8964, Accuracy: 9877/10000 (98.77%)\n",
      "\n",
      "Train Epoch: 380 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 380 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 380 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0821, Accuracy: 9866/10000 (98.66%)\n",
      "\n",
      "Train Epoch: 381 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 381 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 381 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8866, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 382 [0/60000 (0%)]\tLoss: 0.000015\n",
      "Train Epoch: 382 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 382 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9442, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 383 [0/60000 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 383 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 383 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1520, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 384 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 384 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 384 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2236, Accuracy: 9874/10000 (98.74%)\n",
      "\n",
      "Train Epoch: 385 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 385 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 385 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9280, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 386 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 386 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 386 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0150, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 387 [0/60000 (0%)]\tLoss: 1.141429\n",
      "Train Epoch: 387 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 387 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0066, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 388 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 388 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 388 [46080/60000 (77%)]\tLoss: 14.151533\n",
      "\n",
      "Test set: Average loss: 1.0181, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 389 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 389 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 389 [46080/60000 (77%)]\tLoss: 0.138584\n",
      "\n",
      "Test set: Average loss: 1.1040, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 390 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 390 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 390 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8939, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 391 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 391 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 391 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.8926, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 392 [0/60000 (0%)]\tLoss: 0.000828\n",
      "Train Epoch: 392 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 392 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0154, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 393 [0/60000 (0%)]\tLoss: 14.092496\n",
      "Train Epoch: 393 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 393 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1791, Accuracy: 9874/10000 (98.74%)\n",
      "\n",
      "Train Epoch: 394 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 394 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 394 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1254, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 395 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 395 [23040/60000 (38%)]\tLoss: 0.000002\n",
      "Train Epoch: 395 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0935, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 396 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 396 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 396 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1307, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 397 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 397 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 397 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1915, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 398 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 398 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 398 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2908, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 399 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 399 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 399 [46080/60000 (77%)]\tLoss: 9.860199\n",
      "\n",
      "Test set: Average loss: 1.1422, Accuracy: 9903/10000 (99.03%)\n",
      "\n",
      "Train Epoch: 400 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 400 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 400 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1140, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "Train Epoch: 401 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 401 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 401 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1635, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 402 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 402 [23040/60000 (38%)]\tLoss: 0.011383\n",
      "Train Epoch: 402 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1427, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 403 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 403 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 403 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1347, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 404 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 404 [23040/60000 (38%)]\tLoss: 0.070271\n",
      "Train Epoch: 404 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0967, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 405 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 405 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 405 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2833, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 406 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 406 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 406 [46080/60000 (77%)]\tLoss: 4.082733\n",
      "\n",
      "Test set: Average loss: 1.0390, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "Train Epoch: 407 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 407 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 407 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1667, Accuracy: 9903/10000 (99.03%)\n",
      "\n",
      "Train Epoch: 408 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 408 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 408 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1621, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 409 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 409 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 409 [46080/60000 (77%)]\tLoss: 0.463287\n",
      "\n",
      "Test set: Average loss: 1.2659, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 410 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 410 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 410 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3496, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 411 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 411 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 411 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2713, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Train Epoch: 412 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 412 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 412 [46080/60000 (77%)]\tLoss: 0.000034\n",
      "\n",
      "Test set: Average loss: 1.2781, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 413 [0/60000 (0%)]\tLoss: 0.001266\n",
      "Train Epoch: 413 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 413 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2514, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 414 [0/60000 (0%)]\tLoss: 12.125000\n",
      "Train Epoch: 414 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 414 [46080/60000 (77%)]\tLoss: 23.641502\n",
      "\n",
      "Test set: Average loss: 1.1504, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 415 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 415 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 415 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0412, Accuracy: 9903/10000 (99.03%)\n",
      "\n",
      "Train Epoch: 416 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 416 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 416 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2964, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 417 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 417 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 417 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1318, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 418 [0/60000 (0%)]\tLoss: 0.000015\n",
      "Train Epoch: 418 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 418 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2351, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 419 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 419 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 419 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0700, Accuracy: 9898/10000 (98.98%)\n",
      "\n",
      "Train Epoch: 420 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 420 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 420 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2162, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 421 [0/60000 (0%)]\tLoss: 2.947385\n",
      "Train Epoch: 421 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 421 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3046, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 422 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 422 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 422 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0829, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 423 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 423 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 423 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0583, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      "Train Epoch: 424 [0/60000 (0%)]\tLoss: 62.792084\n",
      "Train Epoch: 424 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 424 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2331, Accuracy: 9903/10000 (99.03%)\n",
      "\n",
      "Train Epoch: 425 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 425 [23040/60000 (38%)]\tLoss: 0.000214\n",
      "Train Epoch: 425 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2196, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      "Train Epoch: 426 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 426 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 426 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2200, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 427 [0/60000 (0%)]\tLoss: 0.045194\n",
      "Train Epoch: 427 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 427 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1134, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 428 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 428 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 428 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1982, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 429 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 429 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 429 [46080/60000 (77%)]\tLoss: 3.422730\n",
      "\n",
      "Test set: Average loss: 1.3082, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 430 [0/60000 (0%)]\tLoss: 32.239124\n",
      "Train Epoch: 430 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 430 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0853, Accuracy: 9909/10000 (99.09%)\n",
      "\n",
      "Train Epoch: 431 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 431 [23040/60000 (38%)]\tLoss: 6.013611\n",
      "Train Epoch: 431 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1225, Accuracy: 9906/10000 (99.06%)\n",
      "\n",
      "Train Epoch: 432 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 432 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 432 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3277, Accuracy: 9897/10000 (98.97%)\n",
      "\n",
      "Train Epoch: 433 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 433 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 433 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.9979, Accuracy: 9904/10000 (99.04%)\n",
      "\n",
      "Train Epoch: 434 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 434 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 434 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2029, Accuracy: 9878/10000 (98.78%)\n",
      "\n",
      "Train Epoch: 435 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 435 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 435 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1390, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 436 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 436 [23040/60000 (38%)]\tLoss: 13.284941\n",
      "Train Epoch: 436 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2321, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 437 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 437 [23040/60000 (38%)]\tLoss: 0.000207\n",
      "Train Epoch: 437 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2591, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 438 [0/60000 (0%)]\tLoss: 0.000061\n",
      "Train Epoch: 438 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 438 [46080/60000 (77%)]\tLoss: 6.731783\n",
      "\n",
      "Test set: Average loss: 1.3217, Accuracy: 9877/10000 (98.77%)\n",
      "\n",
      "Train Epoch: 439 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 439 [23040/60000 (38%)]\tLoss: 1.045090\n",
      "Train Epoch: 439 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2673, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 440 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 440 [23040/60000 (38%)]\tLoss: 8.293396\n",
      "Train Epoch: 440 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3624, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 441 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 441 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 441 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2648, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch: 442 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 442 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 442 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3784, Accuracy: 9883/10000 (98.83%)\n",
      "\n",
      "Train Epoch: 443 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 443 [23040/60000 (38%)]\tLoss: 16.975693\n",
      "Train Epoch: 443 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3067, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 444 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 444 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 444 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2899, Accuracy: 9898/10000 (98.98%)\n",
      "\n",
      "Train Epoch: 445 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 445 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 445 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2644, Accuracy: 9879/10000 (98.79%)\n",
      "\n",
      "Train Epoch: 446 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 446 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 446 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2036, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 447 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 447 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 447 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3751, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 448 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 448 [23040/60000 (38%)]\tLoss: 0.119438\n",
      "Train Epoch: 448 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3558, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 449 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 449 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 449 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3800, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 450 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 450 [23040/60000 (38%)]\tLoss: 3.434311\n",
      "Train Epoch: 450 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.5256, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 451 [0/60000 (0%)]\tLoss: 108.876999\n",
      "Train Epoch: 451 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 451 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.4328, Accuracy: 9876/10000 (98.76%)\n",
      "\n",
      "Train Epoch: 452 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 452 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 452 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3594, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 453 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 453 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 453 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.4043, Accuracy: 9883/10000 (98.83%)\n",
      "\n",
      "Train Epoch: 454 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 454 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 454 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.4992, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 455 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 455 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 455 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3534, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 456 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 456 [23040/60000 (38%)]\tLoss: 14.021641\n",
      "Train Epoch: 456 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3722, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 457 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 457 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 457 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.4018, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 458 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 458 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 458 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3596, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 459 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 459 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 459 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.0779, Accuracy: 9908/10000 (99.08%)\n",
      "\n",
      "Train Epoch: 460 [0/60000 (0%)]\tLoss: 0.001280\n",
      "Train Epoch: 460 [23040/60000 (38%)]\tLoss: 33.209770\n",
      "Train Epoch: 460 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2672, Accuracy: 9883/10000 (98.83%)\n",
      "\n",
      "Train Epoch: 461 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 461 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 461 [46080/60000 (77%)]\tLoss: 26.584961\n",
      "\n",
      "Test set: Average loss: 1.1424, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 462 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 462 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 462 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2559, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 463 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 463 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 463 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3636, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 464 [0/60000 (0%)]\tLoss: 5.525131\n",
      "Train Epoch: 464 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 464 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3420, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Train Epoch: 465 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 465 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 465 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2893, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 466 [0/60000 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 466 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 466 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2061, Accuracy: 9895/10000 (98.95%)\n",
      "\n",
      "Train Epoch: 467 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 467 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 467 [46080/60000 (77%)]\tLoss: 22.045990\n",
      "\n",
      "Test set: Average loss: 1.5833, Accuracy: 9881/10000 (98.81%)\n",
      "\n",
      "Train Epoch: 468 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 468 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 468 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.4021, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 469 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 469 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 469 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3707, Accuracy: 9890/10000 (98.90%)\n",
      "\n",
      "Train Epoch: 470 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 470 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 470 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.4073, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 471 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 471 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 471 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2985, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 472 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 472 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 472 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.5655, Accuracy: 9873/10000 (98.73%)\n",
      "\n",
      "Train Epoch: 473 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 473 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 473 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.4585, Accuracy: 9887/10000 (98.87%)\n",
      "\n",
      "Train Epoch: 474 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 474 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 474 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.7304, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 475 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 475 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 475 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.6267, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 476 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 476 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 476 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3223, Accuracy: 9902/10000 (99.02%)\n",
      "\n",
      "Train Epoch: 477 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 477 [23040/60000 (38%)]\tLoss: 35.141548\n",
      "Train Epoch: 477 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2204, Accuracy: 9892/10000 (98.92%)\n",
      "\n",
      "Train Epoch: 478 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 478 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 478 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.1278, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "Train Epoch: 479 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 479 [23040/60000 (38%)]\tLoss: 28.129066\n",
      "Train Epoch: 479 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2679, Accuracy: 9898/10000 (98.98%)\n",
      "\n",
      "Train Epoch: 480 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 480 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 480 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.2047, Accuracy: 9898/10000 (98.98%)\n",
      "\n",
      "Train Epoch: 481 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 481 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 481 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3571, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 482 [0/60000 (0%)]\tLoss: 8.535927\n",
      "Train Epoch: 482 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 482 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.5754, Accuracy: 9870/10000 (98.70%)\n",
      "\n",
      "Train Epoch: 483 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 483 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 483 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.3324, Accuracy: 9909/10000 (99.09%)\n",
      "\n",
      "Train Epoch: 484 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 484 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 484 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.4728, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 485 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 485 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 485 [46080/60000 (77%)]\tLoss: 20.131279\n",
      "\n",
      "Test set: Average loss: 1.3586, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch: 486 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 486 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 486 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.5561, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 487 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 487 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 487 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.6697, Accuracy: 9871/10000 (98.71%)\n",
      "\n",
      "Train Epoch: 488 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 488 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 488 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.5851, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 489 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 489 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 489 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.6498, Accuracy: 9886/10000 (98.86%)\n",
      "\n",
      "Train Epoch: 490 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 490 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 490 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.7935, Accuracy: 9885/10000 (98.85%)\n",
      "\n",
      "Train Epoch: 491 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 491 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 491 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.7751, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 492 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 492 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 492 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.6409, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 493 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 493 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 493 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.6390, Accuracy: 9907/10000 (99.07%)\n",
      "\n",
      "Train Epoch: 494 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 494 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 494 [46080/60000 (77%)]\tLoss: 4.684647\n",
      "\n",
      "Test set: Average loss: 1.9390, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 495 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 495 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 495 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.7024, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch: 496 [0/60000 (0%)]\tLoss: 0.000092\n",
      "Train Epoch: 496 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 496 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.5593, Accuracy: 9918/10000 (99.18%)\n",
      "\n",
      "Train Epoch: 497 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 497 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 497 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.4201, Accuracy: 9902/10000 (99.02%)\n",
      "\n",
      "Train Epoch: 498 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 498 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 498 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.5871, Accuracy: 9899/10000 (98.99%)\n",
      "\n",
      "Train Epoch: 499 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 499 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 499 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.4395, Accuracy: 9920/10000 (99.20%)\n",
      "\n",
      "Train Epoch: 500 [0/60000 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 500 [23040/60000 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 500 [46080/60000 (77%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 1.5391, Accuracy: 9897/10000 (98.97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#使用pytorch封装的dataloader进行训练和预测\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def custom_normalization(data, std, mean):\n",
    "    return (data - mean) / std\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "batch_size = 256\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if use_gpu else {}\n",
    "\n",
    "X, y, Xt, yt = get_data()\n",
    "#主要进行标准化处理a\n",
    "# mean, std = X.mean(), X.std()\n",
    "# X = custom_normalization(X, mean, std)\n",
    "# Xt = custom_normalization(Xt, mean, std)\n",
    "\n",
    "train_x, train_y = torch.from_numpy(X.reshape(-1, 1, 28, 28)).float(), torch.from_numpy(y.astype(int))\n",
    "test_x, test_y = [\n",
    "    torch.from_numpy(Xt.reshape(-1, 1, 28, 28)).float(),\n",
    "    torch.from_numpy(yt.astype(int))\n",
    "    ]\n",
    "\n",
    "train_dataset = TensorDataset(data_tensor=train_x, target_tensor=train_y)\n",
    "test_dataset = TensorDataset(data_tensor=test_x, target_tensor=test_y)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size, **kwargs)\n",
    "test_loader = DataLoader(dataset=test_dataset, shuffle=True, batch_size=batch_size, **kwargs)\n",
    "\n",
    "model = LeNet5()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    print('USE GPU')\n",
    "else:\n",
    "    print('USE CPU')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.99))\n",
    "\n",
    "def weight_init(m):\n",
    "# 使用isinstance来判断m属于什么类型\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        import math\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "# m中的weight，bias其实都是Variable，为了能学习参数以及后向传播\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "model.apply(weight_init)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 90 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if use_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, 501):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "USE GPU\n",
      "Train Epoch: 0/0*256 loss is 1130.0375\n",
      "Train Epoch: 0/50*256 loss is 87.9255\n",
      "Train Epoch: 0/100*256 loss is 57.3120\n",
      "Train Epoch: 0/150*256 loss is 29.7038\n",
      "Train Epoch: 0/200*256 loss is 32.3982\n",
      "Test set: Avg Loss: 0.0892, Accuracy: 9713.0/10000(97.13%)\n",
      "Train Epoch: 1/0*256 loss is 30.8226\n",
      "Train Epoch: 1/50*256 loss is 39.0117\n",
      "Train Epoch: 1/100*256 loss is 18.1474\n",
      "Train Epoch: 1/150*256 loss is 14.9634\n",
      "Train Epoch: 1/200*256 loss is 23.5189\n",
      "Test set: Avg Loss: 0.0601, Accuracy: 9807.0/10000(98.07%)\n"
     ]
    }
   ],
   "source": [
    "#自定义训练预测, 不采用dataloader\n",
    "\n",
    "print('Loading data')\n",
    "X, y, Xt, yt = get_data()\n",
    "X, Xt = torch.from_numpy(X.reshape(-1, 1, 28, 28)), torch.from_numpy(Xt.reshape(-1, 1, 28, 28))\n",
    "y, yt = torch.from_numpy(y.astype(float)), torch.from_numpy(yt.astype(float))\n",
    "\n",
    "model = LeNet5()\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    print('USE GPU')\n",
    "else:\n",
    "    print('USE CPU')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.99))\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    batch_size = 256\n",
    "    \n",
    "    for inx in range(int(X.shape[0]/batch_size)):\n",
    "        start_inx = inx * batch_size\n",
    "        end_inx = min((inx+1)*batch_size, X.shape[0])\n",
    "        mini_data = Variable(X[start_inx:end_inx].clone())\n",
    "        mini_label = Variable(y[start_inx:end_inx].clone())\n",
    "        mini_data = mini_data.type(torch.FloatTensor)\n",
    "        mini_label = mini_label.type(torch.LongTensor)\n",
    "        if use_gpu:\n",
    "            mini_data = mini_data.cuda()\n",
    "            mini_label = mini_label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        mini_out = model(mini_data)\n",
    "        mini_label = mini_label.view(end_inx-start_inx)\n",
    "#         print(mini_out.size(), mini_label.size())\n",
    "        mini_loss = criterion(mini_out, mini_label)\n",
    "        mini_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if inx % 50 == 0:\n",
    "            print('Train Epoch: {}/{}*256 loss is {:.4f}'.format(epoch, inx, mini_loss.data[0]))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "\n",
    "    correct = 0.\n",
    "    nb_test = Xt.shape[0]\n",
    "    for each_sample in range(nb_test):\n",
    "        sample_data = Variable(Xt[each_sample:each_sample+1].clone(), volatile=True)\n",
    "        sample_data = sample_data.type(torch.FloatTensor)\n",
    "        sample_label = Variable(yt[each_sample:each_sample+1].clone())\n",
    "        sample_label = sample_label.type(torch.LongTensor)\n",
    "        if use_gpu:\n",
    "            sample_data = sample_data.cuda()\n",
    "            sample_label = sample_label.cuda()\n",
    "            \n",
    "        sample_out = model(sample_data)\n",
    "        \n",
    "        test_loss += criterion(sample_out, sample_label)\n",
    "        \n",
    "        pred = sample_out.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(sample_label.data.view_as(pred)).cpu().sum()\n",
    "    loss =  (test_loss / nb_test).data[0]\n",
    "    acc = 100. * correct / nb_test\n",
    "    print('Test set: Avg Loss: {:.4f}, Accuracy: {}/{}({:.2f}%)'.format(loss, correct, nb_test, acc))\n",
    "    \n",
    "for epoch in range(2):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
